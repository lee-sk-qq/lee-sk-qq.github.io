{"pages":[{"title":"About","text":"Sungkwon Lee A fresh graduate of the Australian National University Double majored in Statistics and Computer Science in Bsc. Interested In Being a proficient VIM user","link":"/about/index.html"},{"title":"","text":"Packet LossPros/Cons: * Really obvious - 얘만 도착 안하니까 다만 혼잡을 앞서 예측하지는 못함","link":"/image/Congestion%20add6356566344a51ab188da187eac9bf/How%20network%20signal%20the%20sender%20494b8b92a4e24aef8d3cd60d5aa20bcc/Packet%20Loss%20694760483165446c9948787816649fbf.html"},{"title":"","text":"Packet DelaysPros/Cons: * 혼잡을 미리 예상할 수 있음 (조금 늦어지니까 전보다) 물론 이 혼잡은 추론되는것 (사실과 다를수 있음)","link":"/image/Congestion%20add6356566344a51ab188da187eac9bf/How%20network%20signal%20the%20sender%20494b8b92a4e24aef8d3cd60d5aa20bcc/Packet%20Delays%2081479001403648de80deb0f959fd0fe8.html"},{"title":"","text":"Router Explicit Congestion NotificationPros/Cons: * 혼잡을 미리 알 수 있음 (라우터가 알려주니까) 라우터와 호스트간에 협조가 필요함 라우터가 송신자에게 보내는게 아니라 데이타그램에 플래그를 설정해서 수신자에게 전달 수신자는 해당 ACK를 받을때 ECN flag 를 set 해서 보내는거","link":"/image/Congestion%20add6356566344a51ab188da187eac9bf/How%20network%20signal%20the%20sender%20494b8b92a4e24aef8d3cd60d5aa20bcc/Router%20Explicit%20Congestion%20Notification%20c777ddb3fc404866a12ea1c3247a67b2.html"}],"posts":[{"title":"CPP - 1.1","text":"TypesBuild goes through three steps: Preprocess : deals with source code meta data compile: turns source code into machine readable object files Link: Links objects into application :: → scope resolution operator 123456789101112131415161718192021222324252627282930313233343536// Can use namepsace for a particular functionusing std::cout;// C++17 introduced new nested namespace syntaxnamespace a::b::c::{}namespace total = a::b::c; // Namespace alias// literals can be divided into `int bigNum = 23`456`789;// C++ has type casting --&gt; Recommend to use the third one// Type cast may result a coercion (lose decimals from float to int).float myFloat = 3.14f;int i1 = (int) myFloat;int i2 = int (myFloat);int i3 = static_cast&lt;int&gt;(myFloat);// Static cast is not necessary when casting into a broader type eg: short -&gt; long// Strong type - type safeenum class PieceType{king = 1};PieceType piece = PieceType::king; // scope is necessary// C++17 has [[fallthrough]] in switch statementswitch (true){ case A: [[fallthrough]]; case B: break;}// function prototype = function header -&gt; where declare the function// Function signature: function name and its variables// C++14 has auto return type -&gt; compiler takes care of it// auto function should have the same return types alwaysauto addNumbers(int num1, int num2);// __func__ in a function prints the function name ArrayIn CPP, it is better to use std::array as it can… Know the accurate size Can prevent certain bugs due to non-dynamic casting into a pointer Easy to write an iterator. The array size must be defined during compile step, hence size cannot be re-sized. 12345678910111213// C style arrayint myArray[3] = {}; // Initialize as 0int myArray[] = {1,2,3,4}; // Compiler sets array size as 4// C++17 array sizeunsigned int arraySize = std::size(myArray); // &lt;array&gt;// Non C++17 array sizeunsigned int arraySize = sizeof(myArray) / sizeof(myArray[0]);// Arrayarray&lt;int, 3&gt; arr = {9,8,7};cout &lt;&lt; \"Array Size\" &lt;&lt; arr.size() &lt;&lt; endl;cout &lt;&lt; \"2nd element\" &lt;&lt; arr[1] &lt;&lt; endl; VectorCPP library that provides “UNFIXED” size-container —&gt; Dynamic Allocation 12345678// Int vectorvector&lt;int&gt; myVector = {1,2};// Push_back to add elements in a vectormyVector.push_back(33);// Access to an elementcout &lt;&lt; \"1st elemest\" &lt;&lt; myVector[0] &lt;&lt; endl; Vector is a generic container —&gt; can put all kinds of types init. Structured Binding Can initialize into different types when declare multiple variables 12345678910111213// arraystd::array&lt;int,3&gt; values = {11,12,13};// Structured Bindingauto [x,y,z] = values;struct Point {double mX, mY, mZ;};Point point;point.mX = 1.0; point.mY = 2.0, point.mZ = 3.0;auto [x,y,z] = point;// If the data is public-declared and non-static, // it can be used as in structured binding. LoopSkipped While, do-while, for loops due to its similarity to C Range-based for1234567891011121314151617181920std::array &lt;int, 4&gt; arr = {1,2,3,4};for (int i : arr){ // for element i in arr std::cout &lt;&lt; i &lt;&lt; std::endl;}// &lt;Initializer_list&gt;// Easy to make a function that takes multiple inputs -&gt; class template#include &lt;initializer_list&gt;using namespace std;int makeSum (initializer_list &lt;int&gt; lst){ int total = 0; for (int value : lst){ total += value; } return total;}int a = makeSum ({1,2,3});// initializer_list is type-safe --&gt; compiler error for diff type inputs","link":"/2020/07/03/CPP/CPP%201.1/"},{"title":"Dvorak Layout","text":"VIM 유저 유의사항VIM을 쓰는 유저라면 jkhl 이 걱정되실 텐데 사실 빔을 쓸 정도면 세팅 정도는 알아서 할 수 있기 때문에 htns 로 매핑을 다시 하던지, 아니면 jkhl로 쓰던지 하는 두 가지 방법이 있다. 후자의 경우 오른손 한 손으로 평소처럼 사용할 수는 없으나, 왼손은 상하, 오른손은 좌우로 나누어져 있기에 큰 불편함은 없다. 운영체제에서 드보락 배열을 찾아보면 알겠지만, 드보락 배열 (원래 단축키) 혹은 드보락 배열 (드보락 단축키) 식으로 나누어져 있기에 복사 붙여넣기 등을 평소 쓰던 대로 쓰고 싶다면 드보락 (인터내셔널) 을 선택하면 쿼티 단축키 사용하듯 쓸 수 있다. Dvorak?드보락 - 나무위키 대중화된 영어 키보드 레이아웃은 QWERTY (이하 쿼티)라고 부르는데 이는 상단 좌측에 모여있는 여섯 글자를 순서대로 나열한 것입니다. 나라마다 조금씩 달라 QWERTZ 등의 버전이 존재하기도 하지요 (블랙베리 핸드폰을 사용하셨다면 친숙하실 수도…) Dvorak (드보락)의 경우 위 링크에서 알 수 있겠지만, 워싱턴 대학의 드보락 박사가 연구 후 제안한 자판 배열 방식으로, 쿼티와 함께 미국에서 국가적으로 인정하는 배열입니다. 이는, 미국에서 시행되는 모든 컴퓨터를 사용하는 공인 시험 (어학, 자격증 등등)에서 사용 가능하다는 이야기 입니다. 다른 유명한 배열인 콜맥의 경우 국가 공인 배열이 아니기에 영어 키보드 리스트에 존재하지 않으며 (칼리 리눅스 제외) 직접 등록하셔야 합니다 (드보락의 경우 윈도우/맥/우분투 등등 기본으로 이미 깔려있습니다). Why?드보락을 배워야 하는 이유로 많은 분들이 타이핑 속도의 향상이라고 이야기 하는데, 저의 경우에는 손목 통증이 계기였습니다. 바람의나라 체류 시스템을 기억하시나요? 캐릭터가 죽으면 아이템이 깨지거나 바닥에 떨어트려지는데 이를 다시 찾기 위해 돌아오면 꼭 아이템 위에 누가 대기를 하고 있는 그 상황… 제 빠른 한글 타수 지분률 80프로를 차지하고 있는 그 시스템을 너무 어렸을때 경험해 잘못된 습관을 가지고 타자를 치게 되었고, 이 좋지 않은 습관이 영문타자로 이어졌습니다. 쿼티의 경우 너무 왼손 비중이 높았고, 이로 인하여 오랜시간 타이핑을 하면 손목 통증을 겪었습니다. 드보락의 경우 마치 한글을 타이핑 하듯 양손을 번갈아 가며 치는 듯한 느낌을 받으실 수 있습니다. 저는 쿼티 분당 3~400타 정도 였으며 시험기간에 특히 손목 통증이 심해서 (코딩및 에세이) 손목을 마사지 하면서 타이핑을 했습니다. 지금은 드보락 분당 300타 중반정도 인데, 이번 시험기간에 손목 통증이 단 한번도 없었습니다. 배울때는 정말 힘들었는데 배우고 나니 정~말 편해요. How?사실 키캡을 따로 주문하셔서 커스터마이징 하시는게 아니라면, 드보락 배열로 키 프린팅된 키보드는 아마 못구하실겁니다… 드보락 레딧에서도 모두 터치 타이핑 (보지 않고 치는것)을 추천합니다. [연습 사이트][https://learn.dvorak.nl/?lang=en&amp;lesson=5] 다음은 제가 겪었던 단계별 생각울화통 을 정리해 보았습니다. 1 단계 : 0 ~ 130타 혈압이 오릅니다. 농담이 아니라 정말로 타이핑 할 때 목덜미가 뻣뻣해지면서 호흡이 가빠지고 머리가 어지러울 정도로 화가 치밀어 오릅니다. 내 손이 아닌 그 느낌…이 기간동안 절대로 쿼티에 손대시면 안됩니다.사람에 따라 다르지만, 쿼티로 400타 중반 정도 치시던 분들은 2주정도 걸리는것 같습니다.2 단계 : 130~220타 보고 치는것은 부드럽지만, 머슬 메모리 때문에 생각 하시면서 칠때 실수가 자주 나오는 단계입니다.이 단계에 들어오면 가끔 손이 꼬여 답답하지만 1단계와 같이 혈압이 오르지는 않습니다.어느 정도 드보락의 편안함을 인지하는 단계로 연습사이트에서 만큼은 스스로 감탄합니다.쿼티의 머슬 메모리가 언제 지워지느냐가 관건인데 그동안 쿼티를 치지 않고 했다면 3주 정도 걸립니다.쿼티 키보드 치는 걸 꺼리기 시작합니다.3단계 : 220~300타 쿼티 키보드 배열이 기억이 안나는 단계입니다.스스로 생각 없이 타이핑 할 때 쿼티에서 쓰듯 자연스럽게 쓸 수 있으나 덜 쓰는 키들 q,j,k 같은 키들을 쓸 때 꼬이는 단계쿼티 키보드는 이제 쓰고 싶어도 자판을 보고 하나하나 띄엄띄엄 치게 됩니다.이 단계부터는 얼마나 다양한 단어를 쳐보느냐가 중요한것 같습니다.4단계 : 300 ~ 그냥 일반 쿼티처럼 타이핑 가능 하신 단계입니다.","link":"/2020/04/03/Life/dvorak/"},{"title":"Unsupervised Learning Clustering","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html Clustering관측치들을 각 그룹별로 나누는데. 해당 그룹내의 관측치들은 유사하게, 다른 그룹의 관측치와는 상이하게 나누는것. 이 유사/상이 하다를 정의를 domain-specific (도메인 특정) 을 기반으로 한다 클러스터링이 비지도 (unsupervised) 방식인 이유는, 자료를 기반으로한 구조 (structure)를 발견, 그룹을 나누는것인데 비해, 지도 방식의 경우 어떠한 결과를 유추/예측 하고자 하는것. Clustering AND PCA 모두 summary를 통해 데이터를 간단하게 하려 하지만 PCA: 분산의 많은 비율을 설명하는 관측치들을 저차원 표현으로 찾으려 함 Clustering: 관측치들중 같은 서브그룹을 찾으려 함. 즉 클러스터링은 사람들 (관측치)들중 이 제품을 잘 살것같은 그룹을 찾아내는 형식 - market segmentation 이라고도 한다. K - mean clustering미리 지정한 수의 클러스터로 나누는것. 이 k 개의 클러스터간 서로 절대 겹치지 않으며 모든 관측치들은 어느 한 클러스터에 속해있다. 위의 식에서 유추할수 있듯, 한 클러스터 내에서의 변동이 가장 적은 클러스터링을 목표로 하고 있다. 이 변동 W(Ck) 를 정의 하는 방법은 여러가지 이지만 가장 일반적으로 유클리드 거리 제곱 (squared Euclidean distance)를 사용한다. 이를 적용하면 위의 식이 다음과 같이 변한다. Ck = 클러스터내 관측치들의 수. 관측치들 사이의 pairwise한 거리의 제곱의 합을 관측수로 나눈것. 물론 위의 모든 방식을 사용하려면 K ** n 개의 분할 방법이 존재하기에 다음과 같은 알고리즘을 사용한다. 즉 랜덤하게 클러스터를 분배하고, 각 클러스터의 관측치들의 centeroid 를 벡터 중간값으로 정한후, 가까운 클러스터로 다시 재분배, 반복하는것. 해당 재분배가 (클러스터의 변화가) 없을때가지 반복하는것. 물론 이러한 방식은 초기 클러스터가 어떻게 분배 되느냐에 따라 달라지는 국소 최적 (local optimum) 이다 따라서 이를 피하기 위해 랜덤 할당을 다르게 해서 여러번 실행해보고, 위의 식의 값이 가장 작은것을 선택한다 ( = gloabl optimum) K 숫자 선택은 이후에 다뤄진다. Hierarchical clusteringK-mean clustering 이 가지고 있는 단점: K 를 미리 지정해야 한다 이 없는 방식이며, dendrogram 이라고 하는 tree-based 로 표현한다 bottom-up (위로) and agglomerative (융합) 클러스터링을 설명하는데 이들은 가장 보편적인 계층적 클러스터링 ‘방식이다. 해석 밑의 (잎) 이 위로 올라가며 가지로 융합되는 모습이다. 이 융합되는 트리의 높이가 낮을수록 관측치간의 유사성이 더 높음을 뜻한다. 또한 그림으로 한눈에 다른 색 (다른 그룹)이 서로 융합되는 높이를 알수도 있다. . 위의 그래프의 경우 초록 노랑의 융합이 빨강보다 더 빠르기에 초록 노랑이 더 유사함을 알 수 있다. 주의할 점은 이 관측치의 유사성은 수평 (즉 옆에 가까이 있냐) 수준이 아닌 수직 (융합이 언제 일어나느냐) 로 판단해야 한다. 덴드로그램을 절단하는 수평선이 곧 k의 수이다. 위의 그래프는 5에서 절단함으로써 3개의 클러스터링을 얻는다. 다만 덴드로그램은 TREE 이기때문에 2개씩으로 밖에 나눌수가 없음. 즉 프랑스미국영국을 나눌때 프랑스 | 미국영국 이후 프랑스 미국 영국 과 같이 두번에 걸쳐 3번에 나눈다. 결국 각각의 다른 그룹이 2번에 걸쳐 나눠지는 이러한 형태때문에 가끔 k-mean clustering 보다 정확도가 낮은 결과를 나타낼수 있다. 알고리즘각 관측지의 페어마다 비유사성 (dissimilarity)를 정의한다 (유클리드 거리를 가장 많이 사용). 덴드로그램 바닥의 n 개의 관측치에 n 개의 클러스터를 주고, 가장 가까운것끼리 합쳐서 결국 1개의 클러스터가 될때까지 진행한다. 위의 알고리즘은 문제를 가지고 있는데, 여러 관측치를 가지고 있는 클러스터간에 비유사성은 어떻게 정의 하는가 이다. 이를 해결하기 위해 완전연결 평균연결 단일연결 무게중심연결을 사용하는데 보통 평균,완전. 단일을 많이 사용한다. 평균,완전 연결이 균형잡힌 덴드로그램을 제공하는 경향이 있어 더 선호된다. 비유사성 측도현재까지 유클리드 거리를 사용했으나, correlation-based distance 같은 방법은 상관성만 높다면 거리가 떨어져있어도 유사하다고 간주하는 방법이다. 즉 유클리드는 소비자가 구매한 양끼리 묶어서 클러스터링을, 상관 기반 거리는 비슷한 물품을 구매한 소매자끼리 묶는 방식이다. 또한 비유사성의 경우 표준편차가 1이 되도록 스케일링을 고려해야 할 수 있다 (단위차이를 없애기 위해) 이슈클러스터링은 매우 유용하지만 여러 이슈도 존재한다. 큰 결과 작은 결정 (small decision with big consequences) 표준화과 진행되어야 하는가? 평균 = 0, 표준편차 = 1 이 되도록 스케일링 되어야 한다등등 계층적 클러스터링의 경우 어떤 비유사성 측도를 사용할것인가 어떤 연결을 사용해야 하는가 어디서 덴드로그램을 절단해야 하는가 K-평균 클러스터링의 경우 몇개의 클러스터를 사용해야 하는가 이러한 작은 결정들은 결과에 큰 영향을 미친다. 검증찾은 클러스터들이 단지 아웃라이어 (노이즈)의 결과인지 아니면 진정 어느 한 부분그룹을 대표하는 (나타내는) 클러스터인지 검증해야 한다. 이를 위해 p값을 할당하는 기법들이 존재하지만 무엇이 딱 좋다 말할수는 없다 다른 고려사항k-mean clustering and 계층적 클러스터링 모두 각 관측치에 하나의 클러스터를 할당한다. 이러한 행동은 outlier 들의 존재로 클러스터가 심하게 왜곡될수 있다. mixture model 은 이러한 특이점을 수용하는 방법인데 k-mean clustering 의 soft 버전이라고 할 수 있다. 또한 클러스터링 방법은 작은 변동 (perturbations)에 robust 하지 않다. 이는 n개의 관측치에서 몇개를 제외하고 클러스터링을 다시 진행하면 보통 그 전의 클러스터링과 유사하지 않다. 결과 해석및 접근 방법위의 이유들로 인해 여러번 클러스터링을 하고, 지속되는 패턴을 찾는것이 좋다. 클러스터링이 얼마나 robust 한지 감을 잡기 위해 부분관측치에 대해 클러스터링을 수행하는것도 좋다. 중요한점은 분석결과인데, 이러한 결과로 인한 결과는 절대적으로 신뢰해서는 안되며, 단지 가설 개발에 이용되어야 한다.","link":"/2020/06/08/MSL/Ch%2010%20Unsupervised%20Learning%20Clustering%2018eb77352ee34926a8504c6f510b2cdf/"},{"title":"Unsupervised Learning","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://bkshin.tistory.com/ Unsupervised LearningThe challenge이전 챕터들에서 supervised Learning 에 관해서 여러가지들을 배웠다. 만약 이진 결과값을 데이터로 부터 도출하여 추측하여야 한다면, 로지스틱, LDA, classification Trees 등을 이용하여 값을 도출하고, 이 결과값에 대하여 어떻게 접근해야 할지에 대한 명료한 지식들을 배웠다 (CV, validaton…) 반면에 unsupervised learning 의 경우 조금더 어려운데 이는 대부분의 실험들이 주관적이고, 분석 (예측)과 같은 간단한 목표를 가지고 있지 않기 때문이다. 대신 unsupervised learning은 exploratory data analysis 에 대한 부분으로 행해진다. 또한 결과값을 도출하는데도 어려움이 있을수 밖에 없는 이유가 이 모델이 맞는지에 대해 테스트 할 수 있는지에 대한 방식이 존재하지 않기 때문이다 (예를 들어 예측하는데에 대해 예측할 값이 존재하지 않는다던가) PCAcorrelated variables가 많은 데이터를 마주 하였을때 principle component (PC)를 이용하여 더 적은 변수들로 대부분의 variability를 summarize 하여 설명할 수 있게 해준다. 챕터 6에서 이야기 하였듯, PC directions는 본래의 데이터에서 highly varaibla한 방향을 보여줌과 동시에 데이터 클라우드에 대해 가장 가까운 선과 부분 공간을 보여준다. PCR을 사용하기 위해서, 우리는 PC를 예측 변수로 사용한다. 이 PC를 이용해 supervised 한 방법이 (PLS) PCA는 또한 데이터 비율어화에 대한 도구로써 사용되고 한다 Principal Component란 무엇인가2차원의 scatter plot을 이용하여 데이터간의 관계를 보통 확인하는데 p=10일 경우, 그려지는 그래프만 45개에 달한다. 또한 각각의 그래프 또한 딱히 중요하지는 않을텐데 이는 각각의 그래프가 나타내는것이 총 데이터에서 일부분에 지나지 않기 때문이다. 즉 우리가 2차원의 그래프를 그릴때, 해당 변수가 데이터에 대해 가장 영양가 있는 (informative) 상황이라면 우리는 큰 데이터를 더 낮은 차원의 공간에서 관찰할 수 있게 되는것이다. (즉 데이터에 대해 가장 잘 나타내는 변수만 관찰하면 파악하기 쉬우니까) PCA provides a tool to do just this. It finds a low-dimensional representation of a data set that contains as much as possible of the variation. 여러개의 변수중에 흥미로운 변수 (차원들)을 파악하려고 노력하는데 이는 관련 변수의 observations가 각 차원에서 얼마나 vary하는가를 기준으로 한다. 계수로 인한 분산이 무한이 커지는것을 막기위해 합을 1로 제한한다. 기존의 데이터셋에 공분산 행렬을 생성하고 (괄호 안), 고유의 Vector와 값을 계산 (대괄호). 그런 다음에 고유 값이 큰 순서대로 정렬 후 변환해야할 차원의 수 만큼 고유 값을 정한 뒤. 고유 Vector에 투영하여 차원을 축소한다. 머신러닝 - 9. 차원 축소와 PCA (Principal Components Analysis) variance가 maxmized 될때 데이터 클라우드에 가장 가까운 이유가 이 때문. variance가 maxmized 되어야 information loss를 최소화 할 수 있다. 1st Principal Component (PC1) 은 주어진 변수들 중에서 데이터를 강 잘 설명하는 성분이다. 만약 PC1의 기울기가 0.25라면, feature 1 increases 4 then feature 2 increases 1 의 선형 결합이 (Linear Combinaito) 해당 데이터를 가장 잘 설명하는 요소라는 의미가 된다. 위의 그래프에서 PC1은 Rape Assault Murder에 가중치를 더 부여하고, PC2는 UrbanPop에 더 가중치를 주는것을 볼 수 있다. 따라서 UrbanPop은 변수들이 설명하고자 하는 도시화에 대해 roughly corresponding 한다고 볼 수 있다. 전체적으로, 범죄와 관련된 변수들이 서로 가까이 있으며, 인구수는 이들과 동떨어져있다. 이는 범죄와 관련된 변수들은 서로 correlated되어 있음을 의미한다. 위의 그래프로부터 다음과 같이 해석될 수 있다. 버지니아와 인디애나 같은 주들은 평균치에 가까운 범죄율과 도시화를 가지고 있고, 캘리포니아는 높은 범죄율과 높은 도시율을 가지고 있다고 본다. 이에 비해 하와이는 낮은 범죄율을 가지면서 높은 도시율을 가졌다. Another Interpretation of Principal Components위 섹션에서는 PCA를 이용한 시각화 그래프에 대해 variance 최대화에 초점을 맞추었는데. PC1의 로딩 벡터는 또다른 특별한 특징을 가지고 있다: p 차원의 공간에서 n개의 관측점에 대해 가장 가까운 선이라는것. 이 해석이 말하고자 하는것은 매우 분명한데 이는 “모든 데이터에 대해 가장 가깝게 그려진 일 차원 데이터를 찾는데, 이는 이 선이 모든 데이터에 대해 좋은 요약을 해줄것이기 때문” 물론 반드시 일 차원 데이터를 찾는것은 아니다 (적을수록 좋다는것) 90개의 샘플에 대하여 왼쪽은 삼차원, 오른쪽은 이차원으로 나타낸것이다. 즉 오른쪽에 대해 한 차원을 더 포함한 (third PC) 상태. More on PCA변수들 스케일링 하기. 위에서 우리는 PCA를 하기전에 변수들의 평균이 0이 되도록 센터링 시켜야 한다고 하였다. 이에 더불어서 우리가 PCA를 통해 도출한 결과값은 변수들이 각각 얼마나 스케일 되었는지에 대하여 dependant 하다. 이는 다른 supervised &amp; unsupervised 와 차이점으로 존재한다 (다른 방법들은 스케일링으로 인한 결과값이 변하지 않는다). 왼쪽의 경우 위와 같이 SD의 총합이 1이 되도록 scaling 한 상태. 오른쪽에서 Assault가 PC1에서 가장 큰 로딩을 가지고 있는데 이는 다른 변수들에 비해 가장 높은 분산을 가지고 있기때문이다. 또한 각 변수들의 unit 또한 각기 다르기 때문에 (100명당 하나, 1000명당 하나, 돈의 경우 1000달러 등등) 그냥 기본적으로 SD를 1로 설정하는 방식이 추천된다. These four variables have variance 18.97, 87.73, 6945.16, and 209.5, respectively. Consequently, if we perform PCA on the unscaled variables, then the first principal component loading vector will have a very large loading for Assault , since that variable has by far the highest variance. 만약, 모든 변수들이 같은 unit으로 측정되었다면, SD를 1로 하지 않는게 좋다. Uniqueness of the Principal ComponentsEach PC loading vector는 고유하다. 이 로딩 벡터의 사인 (플마)는 바뀔지 언정 값 자체는 어느 소프트웨어 패키지에서 실행하던지 같다. 또한 이 사인의 변동또한 의미가 없는것이 결국 방향을 이용하여 분석하기 때문. 따라서 loading vector, and score vector 가 동시에 사인이 바뀌는 이상 최종 결론에는 문제가 없다. (하나만 바뀌고 그러면 안됨) Proportion of Variance Explained 위와 같은 방식으로 각각의 PC가 얼마만큼의 분산을 설명하는지에 대하여 알 수 있지만, 어느선에서 얼마정도의 PC가 필요한가? 에 대한 사항은 특별히 정해진게 없다. scree plot (각각의 PC의 분산 설명도 그래프) 을 이용하여 elbow 를 이용하여 정할수도 있긴 하다. 현실적으로, 혹은 실증적으로는, 우리는 첫 몇몇의 PC를 시각화해서 특이한 패턴이 있는지 확인 하는 식으로 결정한다. 당연하게도, 이러한 방식의 접근은 매우 주관적이며 이로 인해 우리는 PCA는 exploratory data analysis를 위한 시각화 도구로 사용하는 이유중 하나다. 물론 PCA를 supervised에 사용한다면, CV와 같은 방법을 이용하여 score vectors 를 regresisson 튜닝 패러미터로 사용된다면, 몇개의 PC가 사용되어야 하는지 알 수 있다 (왜냐면 이걸 지금 어디에 쓰는지 우리가 분명하게 알고있으니까)","link":"/2020/05/19/MSL/Ch%2010%20Unsupervised%20Learning%20cd06ce30533144c7a419b2f3f621a004/"},{"title":"Lasso, Ridge","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html Why Not Least Square?OLS 는 오차의 평균이 0, 오차의 분산이 등분산 (모두 비슷함), 그리고 오차가 서로 관계가 없는 선형 모델중에서 최적이다. 또한 분포가 정규분포일 경우, OLS estimator 는 Maximum Likelihodd estimator 와 같은 결과를 낸다. OLS는 unbiased 한 대신 variance하고, 이로 인해 데이터에 따라 변동차이가 크다. 하지만 다음과 같은 이유로 OLS를 대신하는 대체 방법들이 존재한다. 예측정확도: OLS는 가정된 분포가 어느정도 맞고, 변수의 개수 p보다 자료의 개수 n이 훨씬 많을때 좋다. 만약 n이 p 보다 (보통 3배) 많지 않다면, OLS는 큰 변동성 (variance)를 가지게 되고, 이로 인해 새로운 자료에 대해 예측을 잘 못하는 overfitting 이 나타난다. variance = p * (SD/N) 이므로, p가 클 수록 증가한다. 만약 n이 p 보다 적으면, OLS는 variance가 무한인 사용 불가능한 방법이다. 이 이유는 matrix 연산에서 full rank인 matrix만 가능한데, n&lt;p는 비가역행 행렬 (non full rank) 가 된다. 해석력: OLS는 Y에 전혀 관계가 없어도 0으로 제외할 수 있는 능력이 없다. 즉 중요한 변수를 선택하고 무쓸모한 변수를 제외하는 능력이 없음. 그래서 5장에서 사용한 방법들이 존재하는것. Options? Subset selection: 유의미한 변수를 골라내고 OLS 하는것 Shrinkage: 모든 변수들을 이용하여 저합한다. 계수들인 OLS에 비해 0으로 가려고 하는 경향이 있다. 자동적인 변수 선택도 가능하게 한다. Dimension Reduction: p개의 차원 (변수)에서, m의 차원 (변수)로 projection 후 OLS 하는 방법. Subset SelectionBest Subset selection모든 경우의 수를 써보고 최고를 찾는법. 하지만 p가 클수록 ovrefitting 된 모델을 고를 확률도 늘어남. 변수 p개 중에서 0 ≤ k ≤ p 인 모델 모든것을 계산 하는 방법 각 k개의 모델들중 R^2 이 가장 높은거 선택 (변수 수가 같으니 간단하게 찾기 가능) 뽑힌 모델들중 최고를 뽑는것. 변수의 갯수가 달라 R^2은 이제 못쓰고 CV-error, AIC, BIC, Radj 등을 쓴다. 다시 말하지만 변수의 수가 많을 수록 설명력이 당연히 강해지고, 이로 인해 low training error값인 R^2이 좋게 나올수 밖에 없다. 하지만 우리의 목표는 테스트 에러지, 트레이닝 에러가 아니다. 이 방법은 계산양이 많다는 단점이 있다. Stepwise SelectionBest Subset selection의 단점인 계산양과 잘못된 모델 선택의 대안으로 사용 가능한 방법이다. Forward Selection: 보수적인 모델 (변수가 최소화된) 을 선택함 backward selection: 변수가 많이 들어간 모델을 선택함 mixed selection: 제일 best subset selection과 비슷한 모델을 찾아줌 이 세가지 방법들은 best 모델을 찾는것이 보장되어 있지는 않다. 세세하게 다른 차이점이 존재한다. Choos Optimal Modeltest error를 최소화 하기 위한 방법이 두가지 가 존재한다. Overfitting 을 고려한 수학적 보정을 통안 test error의 간접 추정 Traninig est중 몇개를 빼서 하는 직접 추정 (5장에서 배운것들) 간정 추정들로는 CV-error (C_p), AIC, BIC, adjusted R^2 이 존재한다. 위에서 RSS = SSE_r (reduced model SSE)를 뜻한다. Validation and Cross-Validation예전에는 컴퓨터의 계산 능력으로 위의 방법들을 선호 했지만, 이제는 CV를 더 선호한다. 위의 방법과 CV는 몇개의 그룹으로 잘렸는지, 혹은 데이터가 어떻게 나뉘어졌는지에 따라 변동될 수 있어, 선택된 변수 숫자가 최적의 모델이 아닐수 있다. 이를 해결하기 위해서 one-standard-error rule을 적용한다. Test MSE 의 SD의 SE 를 구한뒤, 최소 Test MSE에서 SE만큼 떨어진 모델들을 고려하는것이다. 즉 최소 Test MSE 의 갯수가 4이면, 앞뒤로 1개씩 더 총 3개를 고려하는것이다. Shrinkage Methods모든 변수로 적합하되, 계수들을 0으로 constrain 혹은 regularize하는 방법이다. 이 방법은 추정된 계수들의 (hat values)의 variance를 대폭 줄여준다는 장점이 있다. Ridge Regression기존의 RSS + 모든 계수 합의 제곱 * 람다 의 값을 최소화 하는 식이다. 따라서 계수들이 점점 줄어든다. 이 방식으로 데이터 적합성을 올리는 동시에 계수들을 0 으로 가게한다. 다만 이 계수는 intecept 값을 포함하지 않는다. 람다 값이 커질수록 shrinkage 효과에 더 비중을 두는 식이다. 이 람다 값은 CV를 통해 결정하며, 0일때는 기존의 OLS와 똑같다. 주의해야 하는점은 이 추정되는 계수는 람다에만 영향을 받는게 아니라 변수들의 스케일링에도 영향을 받는다. (애초에 그 계수가 어느 스케일링을 기준으로 만들어진거니까) 따라서 표준화 작업을 해주고 시작을 하게되면, 모든 변수들의 표준편차는 1이 되며, 이로 인해 Ridge regression이 스케일링에 영향을 받지 않는다. Why Ridge?람다가 증가함에 따라 flexibility는 감소하고 Variance가 감소하고 Bias는 증가하게 된다 즉 Bias Variance Trade off 에 있는것이다. Bias는 람다값의 변화에 따라 조금씩 바뀌지만, Variance의 경우 람다가 증가함에 따라 큰폭으로 감소한다. 이는 람다라는 제약에 따라 계수들이 shrinkage 하면서 변동이 크지 않는 모델이 나온다는 의미이다. (점점 람다 값에 미미해져가는거). 선형에 가까울때 OLS: unbias 하지만 variance가 높고, 이는 데이터의 변동에 계수가 크게 변동한다는 의미이다. 또한 p&gt;n 일때 OLS는 유일한 해가 없다 즉 모델을 만들때마다 값이 다 다르게 나오는거 Ridge: 약간의 bias 손해소 varaince 를 크게 줄인다. p&gt;n 일때 덜 flexible한 적합을 통해 소수의 데이터 특성에 국한되지 않는 모델을 만드는것. 또한 람다 계산은 한번만 하면돼서 best subset selection에 비해 계산이 간편한 장점이 있다. LassoRidge의 단점Ridge Regression의 방식은 예측과 관련해서는 아무런 문제가 없지만, 해석측면에서 약점을 가지고 있는다. 만약 해석의 경우 1,2,3 변수만을 통해 하고 싶다고 하자. 다만 Ridge는 모든 변수로 적합을 해야만 하고, 나머지 계수가 0이 아니다 (0에 가깝다) 즉 1,2,3 변수만을 통한 해석이 쉽지 않은것. 적당한 람다 값으로, 몇몇 계수를 정확하게 0으로 만들어서 ridge 보다 더 강령한 해석이 가능한것 (나머지 불필요한 계수들이 모델에서 사라진것이니까). 따라서 Ridge보다 더 적은 변수들을 포함하기에 sparse model 이라고 한다. Ridge와 다르게 위에서 rating 계수만 끝까지 남아 있다가 사라진다. 즉 람다 값이 올라감에 따라 변수들이 차례차례 0이 되어 버리므로, 원하는 계수들만 가지고 있는 람다값의 선택이 가능한것. Ridge 는 꾸준히 같이 함께 줄어든다 (마치 비율처럼). 다른 식위의 Ridge, Lasso, best subset selection 은 다른 식으로 표현 가능한데, 식들을 살펴보면 Lasso and Ridge는 Best subset selection을 실현 가능한 형태로 대체한 식임을 알 수 있다 (즉 계산의 부담을 덜은점). 특히 Lasso는 명확하게 변수를 없앤다는점에서 Best subset과 더 유사하다. Lasso 변수 선택 성질 빨간선이 RSS, hat value는 OLS점이다. 만약 s 가 충분히 커서 hat value를 포함하면, 이는 OLS와 같은 값을 가지게 된다. 즉 hat value는 해당 제약범위 (초록색)과 가장 작은 RSS와 만나는 지점일 것이다. Lasso는 사각형의 모양이라, 다른 계수가 0인 지점에서 쉽게 교점이 생긴다. b2 축에서 교점이 생겼으므로 b1 = 0 이 된다. 하지만 Ridge의 원 모양은, 한 계수가 정확히 0인 교점이 생기기 힘들다. 즉 한놈만 선에 닿는 일이 벌어지기 힘들다. 왜냐면 공평하게 퍼지니까. Lasso and Ridge 차이점 해석력은 Lasso가 변수들을 완전히 제외시킴으로써 더 쎈거는 이제 알게 되었다. 오른쪽 그림에서 두 방법 모두 bias는 비슷하지만 ridge의 variance가 약간 더 낮아서 Test MSE가 Lasso 에 비해 더 낮다. 하지만 이 경우는 모든 데이터가 Y값과 관련이 있는 (correlated)한 데이터 였다. 이에 따라 몇 계수들을 제외한 Lasso 가 불리하다. 위 처럼 만약 2개의 변수만이 유리하다면, Lasso 가 Test MSE를 더 낮은 값을 가진다. 즉 두 방법의 성능은 데이터 상황에 따라 다른것이다. 이를 알기 위해 CV 방법을 사용한다. 람다값 정하는 방법몇몇 람다값을 선정해서 CV해보고 이중 가장 적은 CV-error를 가진 값을 선정하고, 이 계산에 쓰인 데이터를 원래 총 데이터에서 빼서, 새로운 데이터에 뽑은 람다 값을 이용하는것이다.","link":"/2020/04/23/MSL/Ch%206%201%20Lasso%20Ridge%20741cfbd6c5c5480bba27899d7669e971/"},{"title":"PCR, PLS","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) [ISL] 6장 -Lasso, Ridge, PCR이해하기 Dimension Reduction Methods앞서 공부했던 방법들은 몇 변수만 선택하거나, 계수들을 0으로 줄이는 방법과 같은 variance를 줄이기 위함이었다. 차원축소 방법은 변수 자체를 변환하여 분산을 줄이는 방식이다 기존 p개의 변수들에서 m의 변수들을 이용한 Least Square 를 이용한 적합을 하는것 (M&lt;P) 이처럼 제약이 있는 상태에서 계수를 정하면 bisa가 생기나, 이로 인해 variance가 눈에 띄게 감소 되므로 결과적으로는 더 좋은 모델들이 만들어지는것이다. Principle Components RegressionPrincipal Components Analysis (PCA)n*p의 크기를 가지고 있는 x를 줄이기 위해 데이터들의 변동(분산)을 가장 잘 나타낼수 있는 first principal component direction을 찾는다 (이 선이 분산의 크기가 가장 크다) 이 계산 과정에서 데이터 중심에 축을 두고자 centering을 하게 되는데, 이 방식은 분산에 영향을 미치지 않아 결과는 같게 된다. 물론 분산의 무한함을 방지하기 위해 두 계수의 제곱합은 1과 같다라는 제약을 걸어 두었다 이렇게 만들어진 Z1 = principal component score라고 불린다. 왼쪽의 초록선은 데이터가 가장 큰 분산을 가짐과 동시에, 모든 n개의 관측값에 가장 가까운 선이기도 하다 (즉 수직 점선들의 거리가 가장 짧게). 파란점은 (pop,ad) 의 평균 값을 의미한다. 오른쪽의 그림은 2차원으로 표현된 왼쪽 그림은 회전시켜서 1st PC의 방향이 x축과 같아지게 만들은것. 이 1st PC의 값은 결국 저 파란점과의 거리를 의미하며, 음수이면 두 평균값보다 낮고, 양수일수록 두 평균값보다 높은것이라고 해석을 할 수 있는것. 위의 왼쪽 그래프에서 볼 수 있듯, 두 변수는 선형관계를 가지고 있는데, 이를 파악하여 정보를 압축한 1st PC는 각각의 변수에 대해 강력한 선형 관계를 보여준다. p개의 변수는 곧 최대 p개의 다른 component를 만들 수 있음을 의미하는데, 2nd PC의 경우 1st PC와 uncorrelated 1st PC가 미처 설명하지 못한 부분 에 대해 설명 할 수 있는 방향, 즉 1st PC의 제약 하에 가장 분산이 큰 방향으로 linear combination이 결정된다. 위 오른쪽 그림에서 수직선들에 대해 2nd PC가 사용된것이 왼쪽 그림에서 이와 같이 표현될수 있다. 초록색이 첫번째, 파랑이 두번째 PC 이 두 PC는 (두 선은) 직교 (90도)를 유지하는데, 이는 두 관계가 zero correlation임을 의미한다. 현재는 변수가 2개여서 2개만 있지만, 더 높은 다차원은 여러 방향의 선으로 분산이 가장 높은 방향의 선을 긋는다. 저 위의 오른쪽 그림에서 보이듯, 1st 에 비해 2nd의 값의 수치가 훨씬 적다는 것을 확인 가능하다 (1st는 -25 ~ 20, 2nd는 -10~10). 지금은 변수가 두개여서 불가능하지만, 여러 변수가 있는 상황에서 이와 같은 형태는 차원을 축소 할 수 있다는 것을 의미한다 (1st가 대부분의 정보를 포함하니까 굳이 2nd까지 가지고 있을 의미가 없지). 따라서 차원을 축소함에 따라 이전 compnent에 비해 uncorrelate하면서도 variance가 가장 큰 방향으로 component를 결정 가능하다. Principal Components Regression Approach (PCR)PCR은 PCA를 통해 만들어진 M개의 예측변수들을 통해 Least Square적합을 하는것. “p개의 변수를 가장 큰 variation으로 나타낼수 있는 direction 은 Y와 연관이 있을것이다” 라는 가정하에 이루어지는 분석이므로, 이 가정이 항상 참일수는 없으나 대게의 경우 좋은 적합을 보여준다. 또한 가정이 맞을 경우, 전의 p개의 변수보다 더 적은 m개의 변수를 사용하므로 overfitting을 완화할 수 있다. (n이 p보다 크지 않다면 - 데이터가 변수갯수보다 일정이상 크지 않다면 least square의 변동성이 큰 결과를 내고 overfitting이 커짐을 다시 기억하자) 저번 블로그에서 마지막에 나왔던 데이터에 관한 PCR결과이다. 왼쪽의 경우 45개의 변수중 45개 모두가 유의미한 데이터인 경우, 오른쪽의 경우 2개의 변수만 중요할 때이다. 더 많은 component를 사용할 수록 bias decreases, but variance increases 45개의 component 사용한 값은 단순히 Leaner Square에 모든 변수들을 사용한 것과 같은 값을 보여준다. 왼쪽의 경우 15개 정도의 component에서 성능 증가를 보인경우에 비해 오른쪽은 훨씬 더 많은 component를 가져야 TEST MSE가 낮아졌다. 이는 PCR의 가정, 몇몇의 component로 데이터의 분산을 잘 나타낼 수 있고 Y의 관계가 있을것이다, 이 충족될때 큰 성능을 발휘하기 때문이다. PCR은 변수 선택법이 아니고, 모든 기존의 p개의 변수가 선형결합으로 포함된 변수이다. 이는 PCR이 Ridge의 continuous version이라고 할 수 있다. Partial Least Squares (PLS)앞의 PCA는 unsupervised 방식으로 Y값을 전혀 고려하지 않았다. 이 방식은 PCR의 단점을 곧 의미하는데 (PCA를 이용했으니까 PCR이) 예측 변수들의 관계를 가장 잘 설명하는 방향이, 반응변수 (Y)를 설명하는 예측 변수들의 관계를 가장 잘 설명하는 방향이 아닐수도 있다는것. PLS는 이 방식을 보완했는데, 같은 방식이지만 M개의 변수들을 supervised해서 만들어 내는데, 이로 인해 반응변수와 관계된 변수들의 관계를 더 잘 나타낼수 있는것. PCR과 마찬가지로, PLS역시 변수들을 표준화한 후 계산해야하고, 몇개의 direction을 만들것인지는 cross-validation을 통해 알아본다. 그러나 실제에선 PLS는 supervised라는 점에서 bias는 줄여주지만 그에 상응하여 variance가 높아지기에 PCR이나 Ridge만큼의 성능을 보이지 못하는 경우가 많다.","link":"/2020/05/19/MSL/Ch%206%202%20PCR%20PLS%205b81cc2f4cb340ecbb20a81c959ae0d5/"},{"title":"Local Regression","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html 선형 모델: 모델의 단순성으로 해석과 추론이 쉽다는 장점. 하지만 이러한 가정한 현실적인 문제에 대한 예측을 하기에는 터무니 없는 가정. 따라서 이와 같은 선형가정을 완화시키되, 해석과 추론력을 최대한 잃지 않는선에서 예측력을 증가 시키는 방법들에대해 배워본다. Polynomial Regreisson: 다차항을 이용하여 선형 모델을 확장 Step function: K부분으로 변수를 나누어서 constant를 생성하는 방법 Regression splines: 위 1,2 방식의 확장으로 K부분으로 나누어 각 부분에 다차항을 적합하는 형식이다. 각 부분은 양 옆의 범주에 대해 매끄럽게 만들어야 한다는 제약이 있지만, 적당한 범주로 나눈다면 유연한 적합이 가능하다 Smoothing penalty: 위 3번과 비슷하지만 매끄럽게 한다는 제약을 최소화 시키는 방식 Local Regression: 3,4 번과 비슷하지만, 각 범주가 겹칠수 있다. 이로 인해 유연한 적합이 가능한것 Generalized additive model: 여러개의 예측 변수들에 적용하는 방법 Polynomial Regression예측변수의 전체 구간에 non-linear 형태를 부여하는 방식단순하게 각 변수를 다차항의 형식으로 넣어준 방법이다. X2 = X1 ^ 2 과 같은 형식. 일반적으로 3,4차 이상으로 포함시키지는 않는다. 왼쪽: Least Square 4차 적합. 오른쪽: 왼쪽의 250이상의 고소득자에 대한 Logistic 4차 적합. 점선들은 예측값의 분산을 통해 구한95%의 confidence interval 예측값의 분산은 다음과 같이 구할 수 있다 Logistic의 경우 확률을 반환한다는것을 기억하자. 고소득층에 대한 데이터는 79개에 불과하여 신뢰구간이 매우 넓게 나옴을 확인할 수 있다. Step Functions전체 X를 몇개의 구간으로 나누고 일정한 상수를 부여하는 방식 절편인 b0 는 Y값의 평균이고, 나머지 b 들은 각 구간에 속한 데이터의 평균과 b0와의 차이를 의미하게 된다. C1 ≤ X ≤ C2의 평균값 - b0 = b1. 이러한 각각의 계수들은 마찬가지로 least square로 적합하여 구한다. 각 더미 변수에 대한 (C들은 더미 변수이다) 분산/신뢰구간은 3장 참조 예측값에 자연적으로 부분을 나눌수 있는 지점이 존재 하지 않는다면, 이 방식은 옳지 못한 방향을 나타낼 수 있는데, 명확하게 증가 추세인 구간을 제대로 구분지어주지 않는다면, 이 증가 추세를 반영하지 못하기 때문이다. 위 그래프에서 나이가 들수록 월급이 올라가는 증가 추세를 반영해주지 못한 상황이다. Basis Functions앞의 두 방식은 Bisis funciton의 특별한 형태라고 볼 수도 있다. 앞선 두 방식과 다르게, 선형 모델로 X를 적합하지 않고 다음과 같은 모델에 적합한다. 각 b의 값은 이미 정해져 있으면 알려진 상태임을 명시하자. 이 말인 즉, 우리는 사용할 함수를 미리 선택해 놓는다는 의미이다. Regression SpinesPiecewise Polynomials맨 위 1번 Polynomial regression 처럼 전체 X에 대한 다항적합을 하는 형식이 아닌 몇개의 범주에 대해 비교적 낮은 차수의 적합을 따로따로 하는것을 piecewise polynomial regression 이라 한다. 계수가 바뀌는 지점을 knots 라고 하는데 (서로 다른 부분을 묶는거니까) 삼차 다항식에 이 knots가 없다면 결국 그건 그냥 보통의 평범한 삼차항이다. 다음은 knots가 한개 존재할때의 3차항이다. 즉 c를 기준으로 2개의 부분으로 나누어 각각의 부분에 다항적합을 한것이다. 이 모델의 degreef of freedom = 8 이다 (각각 4개씩) 하지만 이 형식은 중간의 knots 들을 부드럽게 연결하는 제약이 없기때문에 다음과 같은 말도 안되는 모델이 탄생하게 된다 (1번). Constraints and Splines1번의 그래프에서 나이가 50일때 갑자기 월급이 폭등하는 것은 말이 안된다. 이에 50부근의 선들을 연결해 준 그래프가 2번이다 (continuous piecewise cubic). 하지만 이 또한 꺽인듯한 부분을 볼 수 있는데 이러한 약한 제약을 (50 부근 이어준것) 가지고는 다른 그래프에서 v자 형태로 나올수 있기에 고쳐주어야 한다. 이 부분을 부드럽게 해주기 위해 1,2차 미분을 해주어야 한다. 즉 50부분에서 continuous + smooth (1차 2차 미분) 라는 세 가지의 제약을 적용한것이 3번 그래프. 이러한 제약은, 자유도를 하나씩 잃음을 의미한다. 따라서 1번에서는 자유도가 8, 2번에서는 7, 3번에서는 5이다. 보통 cubic spline uses 4 + K df (K = num of knots). Splines Basis Representationd차 적합을 하면서 d-1차 까지의 미분을 달성하기 위해서는 basis function 을 올바르게 선택해야 하는데, 이는 trucated power basis funciton 을 이용하면 된다. 다음은 cubic spline을 cubic regression에서 만드는 방법이다. 위의 뱀처럼 생긴것이 knot을 의미한다. 위의 식을 각 knot마다 추가하는것이다. 하지만 위와 같은 방식으로 구할 경우, 양 끝에서의 예측 신뢰구간이 넓어지므로 예측의 정확도가 떨어지는 현상이 나타난다. 원래 모든 모델의 분산은 양 끝에서 커지지만 non-linear 적합을 시도한 이 경우에 (which has more flexibility) 분산이 더 커지게 된다. 이러한 현상을 고치기 위해 맨 양쪽의 knot 이후에 있는 부분의 경우 선형 적합을 하여서 문제를 완화시키는데 이를 Natural Cubic Spline이라 한다. 위의 그래프를 보면 수직 점선 (knot) 이후에 빨간 점선이 분산을 적게 가지고 있음을 볼 수 있다. 이러한 양끝쪽에 3차 적합이 아닌 1차 적합을 하기에 자유도를 2씩 잃어서 K+4-(2*2) = K df.를 가지게 된다. Num and Location of the knots이제 knot를 어떻게 사용하는지 알았으니 몇개를 어디에 사용해야 하는지를 알아야 한다. 적정한 df를 설정하고, 이에 따른 균등한 quantile에 knot를 배정하는 형식. 결국 df (자유도)를 몇으로 설정하지가 문제인데, Cross-validation을 이용하여 CV-error 값이 가장 낮은 자유도의 갯수를 사용한다 Comparison to Polynomial Regression보통 Polynomial Regression의 경우 flexible 하기 위해 차수를 엄청나게 높이고는 하는데, 반대로 regression spline의 경우 차수는 유지하되, knots를 늘리는것으로 유연해진다. 따라서 대부분의 경우 regression spline이 produces more stable estimates. 또한 급변하게 변하는 부분에 대해서 우리가 따로 더 많은 knots를 부여함으로써 (반대로 원만하면 knots 수 줄이고) 유연성을 적절하게 조절 할 수 있기에 더 좋다. 위의 polynomial의 경우 15차 항인데, 이로 인해 끝쪽이 매우 요동친다. Smoothing SplinesOverview of Smoothing SplinesRegression과 다르게 Smoothing은 모든 x에 knots를 두기에 갯수나 위치 지정의 문제가 없다! 결국 우리가 원하는 사항은 RSS를 작게 만들면서, 부드러운 함수를 찾는것. 위 식의 왼쪽 부분이 RSS이다. 이러한 형태는 Loss (잘 적합) + Penalty (변동이 크지 않게) 식인데, Lassor and Ridge에서 사용되었던 형태와 비슷하다. 오른쪽의 식은 t부분에서의 변화도를 나타내주는데, 변화도가 음수일 경우도 있으니 제곱을 해준다. 람다 값이 커질수록 더 부드러워질것이다. 람다가 0이면 모든 데이터를 지나가고, 무한하다면 선형 (굴곡이 없는 직선 - 선형회귀와 같다). 결국 람다 = bias variance trade off 정도를 조정하는 값인것이다. 이 람다가 3차에서 최소화 될때는 위에서 이야기 했던 2차 미분이 가능한 knot를 가지고 양 끝이 linear 한 natural cubic spline이다. 물론 이와 정확히 같은 값의 식이 나오는게 아니라, 비슷한 형식의 shrink된 함수 Choosing lambdaIn smoothing spline, lambda controls the smoothness. Hence, the effective degrees of freedom changes depending on the value of lambda. 람다가 0에서 무한까지 변할때 effective df는 n에서 2까지 변한다. 기존의 자유도는 pramater의 갯수로 계수의 수를 뜻했다. 따라서 smoothing spline은 명목상 n개의 자유도를 가지고 있지만, 이들인 이미 shrink 되도록 constrain (제약)을 받고 있기에, 이 제약의 정도에 따라 flexibility가 다르다. 따라서 정확히 어느정도의 자유도를 실질적으로 가지고 있는지를 나타내주는것. Regression 과는 다르게 람다를 어느 값으로 할지가 남아있다 (RSS를 최소화 하는). 물론 Cross-validation 을 이용한다. 임의로 정한 effective df 인 16에 비해 계산으로 나온 6.8 이 거의 유사한 형태를 보여주고 있다. Local Regression각 특정 타겟 포인트 근처의 관측 자료들만을 토대로 적합시켜 flexbile하게 하는 방식 위에서 중요한 사항은 얼마나 많은 이웃들을 볼것인지 즉 s를 몇퍼센트로 설정할지이다. s가 작을수록 더 지역적인 (조그만) 부분으로 꾸불한 선이 나올것이다 물론 이 s 또한 cross-validation 을 통해 찾는다. Local Regression은 p-차원에서 p가 3이나 4보다 훨씬 클 경우, 굉장히 안좋은데 이는 대체로 트레이닝 데이터가 굉장히 적음을 의미하기 때문이다. Nearest Neighbour Regression의 경우도 같은 단점을 지니고 있다.","link":"/2020/05/20/MSL/Ch%207%20Local%20Regression%2071eec92f294545e9a27e1a03145a7f40/"},{"title":"Tree Based","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html Why?Tree-based는 regression과 classification을 위한 방법으로, 예측변수의 전체 공간을 단순한 여러 영역으로 계층화 (stratifying) 혹은 분할 (segmentation)하는 방법이다. 예측: 해당 영역의 training data의 평균값이나, 최빈값에대해 예측한다 이 방식은 단순하고 설명력이 좋은 반면에, supervised (chapter 6,7)에 비해 예측력이 떨어지나, 이를 보완하기 위해 bagging, random forests, boosting과 혼합하는데, 위의 방법들을 사용하면 다중트리 (multiple trees) 드링 생성된다. 이 다중트리는 합의 예측을 제공하기에 나중에 하나로 결합된다. 이로 인해 예측정확도의 엄청난 상승을 가져온다. 하지만 이로 인해 해석이 다소 어려워질 수 있다. Decision TreesDecision Tree는 regression and classification 모두에 사용된다 Regression Trees 각각의 노드 (R1,2,3)들은 terminal nodes or leaf of tree 라고 부르며 그 전까지의 노드들 (리프가 아닌 중간 단계)은 internal node 라고 부른다. 위에서 보면 알 수 있듯, 메이저리거의 경우 년차가 연봉을 정하는데 가장 중요한 역할을 하고 있음. 이처럼 Decision Tree는 설명력 측면에서 강점을 가지는데, 위의 그림으로 시각적 설명이 가능하다. Prediction via Stratification of Feature Space 모든 X (변수) 가 포함된 공간을 J 개로 겹치지 않게 나눈다 RSS를 최소화 하는 방향으로 위의 그림처럼 박스형식으로 쪼갠다. 물론 무한한 박스 조합이 가능하기에 Top-down or greedy 방식을 사용한다. 당장의 RSS를 최소화 하는것을 목표로 한다 (greedy) - recursive binary splitting 이라고 칭한다. s 는 cutpoint 로 RSS가 최소화 되도록 영역을 밑의 두가지로 분할하는 점이다. 다음의 식이 최소화 하는 j (공간 갯수) 와 s를 찾는다 위의 첫 식으로 만들어진 두 영역중 하나를 선택해 같은 방식을 적용하여 3개의 영역이 된다. 이와 같은것을 계속해서 반복하며, 설정해둔 stopping criterion 을 만족할때가지 진행한다. 예를 들어 한 영역당 관측치가 5개 이상이어야 한다등의 조건. 각 공간에서 training data 평균을 통해서 일관된 예측값을 반환한다. 모든공간에 같은 예측을 시행한다. Tree Pruning위의 방법은 훈련셋에 좋은 예측이 가능하지만, 데이터 overfit의 가능성이 높은데 이는 지나치게 세분화된 tree는 training set 의 특징또한 포함할 수 있기 때문이다. 이로 인해 test set에서 성능이 좋지 않다. 분할 수가 적다면 편향성이 약간 증가하지만 분산이 낮아져 해석하기 쉬울것이다. 위에서 설명한 방법을 보완하는 방법은 어느 threshold 까지만 리빌딩일 진행하도록 하는것. 이는 작은 트리를 (분할 수가 더 적은) 만들수는 있지만 short-sighted (근시안)적인데 왜냐면 초기에는 좋지 않아 보인 분할이 나중에 가면 좋은것일수도 있기 때문이다. 더 나은 방법은 큰 트리 T0 를 만든뒤 이 트리를 다시 prune 하여 subtree를 얻는것. 그렇다면 어떻게 prune 하는것이 좋은 방법인가? - 최종 목표는 lowest test error 를 갖는 subtree를 찾는것이지만 이에 대해 모든 CV는 불가능 하다. 이를 위해 Cost complexcity pruning (or called weakest link pruning) 을 사용한다. 가능한 모든 서브트리를 고려하는것이 아닌 조율 parameter a 로 다음식을 최소화 하는것 T = num of Terminal node, R_m = box corresponds to mth terminal node, hat(y)R_m = R_m 훈련 관측치들의 평균. a = 0 일 경우 subtree T = T_0. 각 terminal node 에서의 RSS 를 줄여주는 loss-term (앞부분) 지나치게 많은 terminal node 가 없도록 (복잡성늘 낮춰주는) penalty form (뒷부분) 위 두가지의 폼을 a로 비율적으로 조정하는것인데 이 a를 CV를 통해 구하는것. 최종 알고리즘 모든 자료들을 이용해서 resursive binary split 계속해서 진행하여 stopping criterion 만족하면 멈춤 (full size tree) 이는 a = 0 일때의 트리와 같다. 이렇게 최종적으로 만들어진 트리에 cost complexity pruning 을 적용하여 가장 좋은 서브트리들을 a의 함수로 얻는다. K-fold 를 진행하며 a를 선택한다. 모든 훈련자료의 kth fold 의외의 fold 에 위 1,2번 반복 kth fold 를 이용하며 나머지에 error 를 평균내서 validation error 가 가장 낮는 a로 결정한다 3번에서 구한 a를 통해 1번의 트리 (처음 큰 트리) 에 pruning 을 진행한다 - 그러면 가장 좋은 서브트리를 선택한다! Classification TreeFor a classification tree, we predict that each observation belongs to the most commonly occurring class of training observations in the region to which it belongs. 가장 많이 등장한 클래스로 분류. 따라서 클래스 비율또한 관심을 가진다. recursive binary splitting 을 classification error rate 를 이용하여 시행한다. Pmk = kth class에 나온 m 번째 영역내의 훈련 관측치들의 비율 1 - (m 영역에서 여러 k들중 가장 많이 등장한 비율). 하지만 클래스간의 비율을 고려하지 않아 좋은 식은 아니다. 이를 보안하기 위해 Gini index or entropy를 이용한다. 지니는 impurity를 가장 낮게 가지는 클래스를 선택하여 진행한다. 마찬가지로 교차 엔트로피또한 m 번째 노드가 pure 할 수록 impurity 지수가 낮을것이고, 그것을 선택한다. 최종 pruned 된 트리에 대한 예측 정확도의 경우 위의 classification error rate 방법을 사용한다. 양쪽 모두 Yes (left: 7/11, right: 9) 인데 이는 지니와 엔트로피의 purity를 올려주기 때문에 분할한것. 즉 두개다 모두 Yes 이므로 분류오차를 줄여주지는 않는다. Tree vs Linear Models 선형이라면 선형회귀,아니면 트리. 결국 때에 따라 다르다 맨위의 경우 선형이, 아래의 경우 트리가 더 좋은상황. Pros and Cons of TreesPros: 설명하기 매우 쉽다 (linear 보다도) 인간의 의사결정 과정을 더 밀접하게 반영한다고 생각된다 그래픽으로 나타내기 쉬우며, 비전문가 또한 쉽게 해석 가능 (물론 크기가 작으면) 더미 변수를 만들지 않고서도 qualitative, quantatative 모두 가능 Cons: 예측 정확도가 좋지 못하다 - prune을 하더라도 overfit의 한계를 벗어나지 못하기 때문. ‘non-robust’ - 데이터의 작은 변화에도 트리의 최종 예측값이 크게 변동한다 (variance가 크다) 예측 정확도를 bagging. random forest, boosting 을 하여 향상 시킬수 있다. Bagging &amp; radom forest &amp; boostingBagging (Bootstrap aggregation)bootstrop 을 활용한 방식. Decision Tree 는 high variance (non robust) 하다는 단점을 가지고 있다. bagging 을 사용하여 variance를 낮추는것. 분산을 줄여 예측 정확도를 증가시키는 자연스러운 방법은 population으로 무터 많은 수의 training set 을 취하여 각각의 training set 별로 예측모델을 만든후, 이 예측결과들을 평균내는것. 물론 이 처럼 다수의 훈련셋은 보통 불가능 하므로, 붓스트랩을 사용하여 표본을 샘플링, 훈련자료들을 생성하는것. 말 그대로 bootstrap 하여 (자료를 만들어서 예측하고) aggregating (평균내는것) 하는 방법. Regression tree의 경우: 붓스트랩하여 훈련셋 B개를 만들어 B개의 regression tree 를 만들고, 이 예측 결과들을 평균낸다. tree 들은 prune 되지 않은 큰 트리들이다. 따라서 각각의 훈련 tree 들은 분산은 크되 편향이 작은 상태. 이 처럼 분산이 크고 편향이 작은 나무들을 모두 모아 평균하여 분산과 편향이 작게 만들어주는것. Classification Tree의 경우: 똑같지만, B 개의 나무에 의해 예측된 클래스를 기록하여 이 예측간에 가장 자주 발생하는 클래스를 선택하는것. Out of bag Error Estimation Bagging 은 bootstrap에 의해 복원추출에 뽑히지 않은 데이터들 (보통 1/3가 안뽑힘) 이 자동으로 validation set 되어 CV를 하지 않아도 test error의 추측이 가능한데. 이 뽑히지 않은 데이터들을 out-of -bag (OOB) 라고 부른다 즉 뽑히지 않은 B/3 개의 모델들이 특정 데이터에 예측을 하고, 이 예측들을 평균낸다. 이 방법으로 OOB error and Classification error 를 구할수 있다. B가 클경우 OOB 오차는 LOOCV의 오차와 사실상 동일하며, CV가 힘들만큼 데이터가 클때 유용한 방식이다. Variable Importance Measures 여러 나무를 합하여 예측력을 올렸지만 (분산을 줄여서), 이로 인해 해석력을 잃었음. 왜냐면 이제 나무 한개가 아니니까. Bagging 전만큼은 아니지만 RSS (regression), Gini Index (classification) 를 이용하며 전반적인 예측변수 중요도를 확인할수있다. 모든 B개의 나무에대해 각 변수에서의 split으로 인한 RSS/Gini 가 감소한 정도를 측정하여 평균을 낸후, 가장 많이 감소하였으면, 해당 변수가 중요하다는것. Random ForestBootstrap은 샘플링을 통하기에 correlation 이 높다 (서로 비슷한 모델이라는 뜻). 이로 인해 covariance가 높고, 그렇기에 bagging으로 인한 variance 감소가 크지 않다. Correlation을 줄인 bootstrap 방식이 바로 random forest 인것. 똑같이 bootstrap을 통해 B개의 나무를 생성한다. 하지만 split 할때 전체 p개의 예측 변수중 랜덤하게 m 개만 골라서 그 중에 또 split 기준을 만든다. 이후 계속해서 반복한다. 보통 m^2 = p 이다. m개는 결국 p개의 반도 안된다. 이는 한개가 강력하고 나머지는 적당한 예측 변수를 가정한다면, bagging 의 경우 모두 나무가 비슷비슷 하기에 가장 강력한 변수를 top split으로 뽑을것이고, 이로 인해서 bagged tree들이 모두 비슷해지는 효과를 만드는것. 앞에서 말하였든 highly correlate 된 통계를 평균 내는것은 correlate가 약한것들의 평균으로 얻는 variance감소보다 더 적다 이와 같은 현상을 피하기에 랜덤으로 뽑아서 다른 예측변수들도 (기회를 얻는것) 사용되게 하여 bagging 보다 결과적으로 decorrelate한 효과를 가지는것. 따라서 이 나무들의 평균으로 얻는 variance 감소가 훨씬 커진다. m = p 는 결국 random forest = bagging 이며 많은수의 변수들이 correlate 라면 sqrt(p)보다 더 적은 m 이 유효할 수 있다. Boosting강력하지는 않으나 보완에 초점을 맞춘 약한 모델 (weak leaner)를 결합해서 정확하고 강력한 모델 (strong leaner)를 만드는 것. 다른곳에서도 사용가능하나 decision tree만 이야기한다 Bagging 의 경우 bootstrap을 이용하여 데이터셋을 만든후, 개별적인 decision tree 생성인데 이 생성과정이 서로 관련이 없고 독립적이다. boosting 의 경우 tree들이 순서대로 만들어지는데, 각각의 tree는 이전 트리들의 정보를 이용하여 만들어진다. 즉 boosting 은 bootstrap sampling 을 사용하지 않는것. 대신 각 트리는 수정된 버전의 원래 데이터셋에 적합한다. 맨 처음에만 데이터에 적합을 하고, 그 이후부터는 이전 tree 의 residual에 적합하는것. 즉 boosting 의 경우 slowly learning method 이다. Boosting tree에는 3가지의 hyper parameter 가 존재한다. Tree의 갯수 B: Boosting 은 variance 감소가 목적인 bagging 과 다르게 bias를 줄여나가는 방식이다. 따라서 B가 너무 크면 overfit이 될 수 있다. B 는 CV 를 이용하여 선택한다 반영비율 lambda: 각 step에서 배운것을 얼마나 반영할지 정해주는것. 보통 0.01/0.001 을 사용한다. 람다가 작을수록 더 큰 B 가 필요하다 (왜냐면 람다가 작다 = 매 스텝에서 (그 전 트리에서) 배우는것이 적다). Tree 의 split 갯수 d: boosting complexity 를 조절해준다. Complexity가 높으면 flexible하고 이는 variance 가 높고 bias가 작음을 의미한다. 위에 말하였는 boosting은 bias를 줄이는데 목표를 두고 있기에 complexity가 크지 않다 (왜냐면 overfit 위험이 생기니까). 때로는 d = 1 일때가 좋을수도 있는데, 이는 addtive model에 적합하기 때문. d = interaction depth라고 생각할수도 있는데 선형회귀의 X1X2 같은 여러 변수의 조합을 고려하는 tree node가 생기기때문. Boosting 은 이전 모델의 실수를 기반으로 만들어지기에 각각의 트리들이 작은 트리여도 충분한 경우가 많다.","link":"/2020/05/26/MSL/Ch%208%20Tree%20Based%206dcd1f84441e45ecb3dfa18a7f35db9c/"},{"title":"Classification","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html Why Not Linear Regression?There is no natural way to convert a qualitative response varaible with more than two levels into a quantitative response that is ready for linear regression. Therefore, better use classification. Logistict RegressionIt models the probability that Y belongs to a particular category (All probabilities lie between 0 and 1). The function will always produce S-shaped curve, hence regardless of X, we will obtain a sensible prediction. The fact that it is not a straight line between p(X) and X, and the rate of change of p(X) per unit change in X depends on the value of X, can be seen by the line. Estimating the Regression CoefficientsIn case of Logistic Regression, MLE is suitable than Least Square to estimate coefficinets in case of non-linear models. Hence, Maximum Likelihood takes parameter b0 and b1 that makes below Likelihood function max. z-stat : hat(b1)/SE(hat(b1)) —&gt; large (absolute) value indicates evidence against the null hypothesis: b1 = 0 in p(x) although still use p for hypothesis test. For multiple predictors more than two, Linear Discriminant Analysis is better. Usually good under parameter ≤ 2 Linear Discriminant AnalysisEsitmation through the distribution of Xs. P(X|Y) through Bayes. When the classes are well-separated, the parameter estimates for the logistic regression model are unstable; LDA does not have this. If n is small and predictors X approx norms in distribution, LDA is more stable. LDA is more popular when having more than two response. Bayes’s Theorem for Classification.To classify into one of K classes (K ≥ 2); meaning Y can take K possible distinct and unordered values. Posterior Likelihood = Prior Likelihood * density function/ … If we can estimate Posterior Likelihood corrcetly, ideal classifcation that has low error con be made. Esitmating posterior likelihood is hard, so need to assume particular distribution for density function. LDA for p = 1Assumption: Normal/Gaussian Distribution; each different distribution exists among K (num of class) with its corresponding mean and shared variance. Use log for above equation and remove duplicated term that not changed to certain k —&gt; giving you the largest class k! Since log is one to one func —&gt; no info loss. To implement LDA Estimating the parameters Compute the decision boundary that results from assigning an observation to the class for which Var_k is the largest (above figure, bottom). Left, right of this dotted line represents each classes. Comparing Bayes Error Rate and LDA error rate to see how the model does. 최종 정리하자면, LDA는 ‘ fk(x)=P(X=x|Y=k) 에 대한 정규 가정과 각 클래스마다 다른 평균, 동일한 분산’을 가정하여 Bayes classifier의 확률을 추정하는 방법이다. 뒷장에서 ‘등분산’에 대한 가정을 떼어내는(즉 클래스마다 σ2k를 가질 수 있게 하는) 방법을 배울 것이다. 출처: [ISL] 4장 - 분류(로지스틱, LDA, QDA) 이해하기 LDA for p &gt; 1Assumption: Each multivariate Gaussian —&gt; each class has diff mean, and still shares the same variance. Multivariate Gaussian: each variable follow its Gaussian Distrib, and each variable pair has correlation —&gt; can be seen as mulit-dimensional Gaussian Distrib. Left: Two predictors are not correlated; meaning Xs’ variacne are the same, while correlation = 0. Use Bayes Equation gives the second equation above; choosing the largest K. Since it is still a linear to X, it is LDA. Problem of Null ClassifierLDA has low on training error rate but It will usually lower than test error rates; meaning it may perform worse to predict a new data. Because specifically adjusted the parametrs of the model to do well on the training data. The higher ratio of parameters p to number of samples n, the more expect overfitting. The trivial null classifier will achieve an error rate that is only a bit higher than the LDA training set error rate. Confusion Matrix can identify the binary classifier error (putting into different category). Sensitivity : if the targeted class well measured. Specificty: if the non-targeted class well measured. Why does LDA do such a poor job of classifying the customers who default? In other words, why does it have such a low sensitivity? LDA is trying to approximate the Bayes classifier, which has the low est total error rate out of all classifiers (if the Gaussian model is correct). The Bayes classifier will yield the smallest possible total number of misclassified observations, irrespective of which class the errors come from. Meaning if classify as non-default will be likely correct in this case, the model be considerate at classify the data as default. In this case, using lower threshold could be a solution. Recall: TP/P - 재현율 (진짜 애들중 몇명) Precision: TP/P* - 정확률 (잡은 애들중 진짜가 몇명). Quadratic Discriminant AnalysisUnlike LDA, each class has its own covariance matrix in QDA. Still use multivariate nomal distrib and use Bayes theorem. This function is not linear to X, hence called QDA —&gt; therefore decision boundary is non-linear as well. For LDA, cov matrix = p(p+1)/2 hence it is less flexible and low variance model. However it will have high bias if it is not nomally distributed (which is in most real cases). If less variance is more important because of small training data, use LDA. For QDA, cov matrix = Kp(p+1)/2. If large training data (so less concern with variance) exists, or covariance seems unrealistic (not normally distributed) use QDA. Comparison of Classification Methods.LDA and Logit Both creates decision boundary although use diff calculations. If it is close to normal distribution, LDA is better. If not, Logit. KNN If decision bondary is non-linear, it would be good. It will not be good for intepretation for which variable played an important rule —&gt; Since the purpose of this method is to analyze the data status. QDA KNN+LDA+Logit characteristics. Less flexible than KNN, but decision boundary is Non-linear Hence it is more flexible than LDA. Due to the assumption of distribution, it will more fit in small data unlike KNN. (Ofc needs more data than LDA as it has more parameters). Case Experiment: Diff mean, Uncorrelated, Normal Distribution LDA did the best due to the distribution. KNN and QDA are too flexible for distribution so bias (strength it has) did not show off much, and has higher variance —&gt; did not do well. Logit is slightly worse than LDA since the boundary decision is linear. Diff mean, correlation : -0.5, Normal Distribution It means multivariate normal distribution Same as 1. t-distribution Since assumption of LDA is violated, Logit &gt; LDA &gt; KNN, QDA It is because it is still similar to Normal Distribution. First class : 0.5 corr with normal dist, Second class: -0.5 corr with normal dist. Satisfies QDA assumption, hence QDA was the best. 2-Polynomial Decision boundary QDA then KNN-cv More non linear than 5th one KNN-cv &gt; QDA &gt; LDA,Logit &gt; KNN-1 It states k does matter as 1 is too flexible. 출처: https://godongyoung.github.io/머신러닝/2018/01/23/ISL-Classification_ch4.html","link":"/2020/03/24/MSL/MSL_Classification/"},{"title":"Linear Regression","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html Linear Regerssion is uesful tool for predicting a quantitative response. It is a good jumping-off point for newer approaches. SLR It assumes there is a approximately a linear relationship between X and Y. hat denote the estimated value for an unknown parameter or coefficient or to denote the predicted value of the response. Estimating the Coefficients Wants to find parameter and coefficient as close as possible → use Least Squares Assessing the accruacy od the Coeff Ests.Population Regression Line: Generally not known. best linear approximation to the true relationship between X and Y. Each regression line may differ from this as the models are based on a separate random set of observations. The purpose of using least square is to estimate caharacteristics of a large population. If we estimate certain parameter based on a particular data set, it may overestimate or underestimate. However, observing huge amount of data and average will give us the exact value of it. Hence, treat the estimates as unbiased (such as hat values). Stadarad Errors tells us the average amount that this estimate hat(mean) differs from the actual value of mean. can be used to conduct the confidence interval. can be used to perform hypothesis tests on the coeff. t = hat(b1) - 0 / SE(hat b1) if SE(hat b1) is small, it means the strong enough to reject null hypothesis t measures the num of SD that hat(b1) is away from 0. if no relationship, will have t-distrib with n-2 degrees of freedom. p-value: indicates the unlikeness to observe the association between predictor and the response. Therefore, small p implies the associtaion. The accuracy of the modelAfter we performs the hypothesis tests, want to quantify the extent to which the model fits the data by using: residual SE, and R^2 statistic. Residual Standard Error (RSE): is an estimate of the standard deviation of error. is the average amount that the response will deviate from the true regression line. measure of lack of fit —&gt; Small RES : well fit of data. R squared: takes the form of proportion. TSS measures the total variance in the Y and can be thought of as the amount of variability inherent in the response before the regression is performed. RSS measures the amount of variability that is left unexplained after performing the regression. Therefore TSS-RSS : var explained after the regression. Hence, R-squared measures the proportion of var in Y that can be explained using X. R-squared = correlation. MLRImportant Qs Is at least one of the predictors useful? Do all the predictors help to explain Y, or is only a subset of the predictors useful? How well does the model fit the data? Given a set of predictor values, what response value should we predict, and how accurate is our prediction? Relationship between Y and Xs When n is large, F close to 1 might still provide evidence against null hypo. Given these individual p-values for each variable, why do we need to lookat the overall F-statistic? After all, it seems likely that if any one of thep-values for the individual variables is very small, then at least one of thepredictors is related to the response. However, this logic is flawed, especiallywhen the number of predictors p is large. Hence, if H_0 is true, there is only a 5 % chance that the F-statistic will result in a p-value below 0.05, regardless of the number of predictors or the number of observations. Decide on important variablesVariable Selection: AIC and BIC and Adjusted R-squared. Forward Selection: Start from Null. Fit p SLR and add to null model the variable that results in the lowest RSS. Backward Selection: Start from all. Remove the variable with the largest p-value (the least significant). Mixed Selection: p-values can become larger as more predictors. Hence. at some point conduct backward selection. Model FitRSE and R-squared : the fraction of variance explained. R-squared In MLR, = Cor (y,hat(y))^2 In SLR, = Cor(y,x) Will always increase with more variables - as it increase the accuracy of the model by adding more training data. If the variable significant, it will bring substantial increase in the R-sq. RSE more variables can have higher RSE if RSS is small relative to the increase in p PredictionsUncertainty associated with prediction: The inaccuracy in the coeff est. is related to the reducible error. Use confidence interval to determine the closness to true population regression plane. Model Bias: potential reducible error that may come from the model. But we ignore and operate as if the model is correct. Even if knows the TPRP, irreducible error makes impossible to accurately estimate the response value. Hence use prediction interval. It is always wider than CI as it both covers the irreducible and reducible. Use CI for Y over a large num of cities. While use PI for Y over a particular city. The coefficients and their p-values do depend on the choice of dummy variable coding —&gt; use F-test. ExtensionsImportant assumptions betwenn predictor and response are Additive Assumption: the effect of changes in a predictor on the Y is independent of the values of the other predictors Synergy Effect = Interaction Effect : spend newspaper and TV half can be better than putting all money in one place. Use interaction term —&gt; if X1X2 term has low p-val, then it means X1 and X2 (the main effects) are not additive each other (share the effect) if we include an interaction in a model, we should also include the main effects, even if the p-val associated with their coeff are not significant. Linear Relationship: using polynomid regression to accommodate non-linear relationship which still allows to use linear system. Include polynomial functions of the prdecitors in the model to improve the fit Unnecessary predictor makes the model wiggely, which casts doubt whether that additional variable makes the model more accurate. Potential Problem Non-linearity of the response-predictor relationships Residual Plot - tool to identify non-linearity. Due to multiple predictors, plot residuals vs predicted (or fitted) y. The presence of a pattern —&gt; some aspect of the linear model. If non-linear association, use non-linear transformations of the predictors such as log X, sqrt(X), and X^2 Correlation of error terms If correlation exists, estimated SE will tend to underestimate the true SE. Hence, PI gets narrower, p-val is lower which could cause errorneously conclude that a parameter is statistically significant. In short, lead unwarranted sense of CI in the model. Time series data: Residual plot, if error terms are positively correlated, tracking in the residuals - adjacent resi may have similar valuse. Non-constant variance of error terms SD, CI, Hypothesis test rely upon this heteroscedasticity: funnel shape in the residual plot. Solution: transform results in a greater amount of shrinkage of the larger responses, leading to a reduction in heteroscedasticity. Outliers Usually has no effect on the least square fit. But has significant effect on RSE which is used for CI and p-values —&gt; important for the interpretation of the fit. + R-sq declines as well. Use studentized residuals: each residual / ESE. ≥ 3 is outlier It may imply missing predictor, so be aware. High-leverage points Removing high leverage has more substantial impact on the least squares line than removing an outlier. It may invalidate the entire fit —&gt; better remove it. Leverage Stat: ≥ (p+1)/n —&gt; suspect Collinearity predictors are closely related. Use Contour plot of RSS for visual. Small change in the data could cause the pair of coeff values that yield the smallest RSS, the smallest LSE, to move anywhere along the valley. It is a great deal of uncertainty in the coeff est. It reduces the accuracy of the esitimates of the regression coefficients, hence, increases the SE of hat(predictor). It reduces the t-stat hence affect the hypothesis test weak (the probability of detecting a non-zero coeff). Use Variance inflation factor (VIF): value of 1 indicates the absence of collinearity. Exceeds 5 or 10 —&gt; problematic amount of collinearity.","link":"/2020/03/19/MSL/MSL_Linear%20Regression/"},{"title":"Congestion","text":"Sliding Windows For reliability and throughput 만약 단방향 딜레이가 50ms 라고 한다면, Round-trip-time (RTT) 는 100ms 따라서 single segment (윈도우에서의 한 segment를 말한다) per RTT 라고 한다면 ⇒ 10 packets/s (한 패킷 RTT = 100ms) - 10개의 segment 가 1초에 진행됨 이 상황에서는 대역폭이 증가해도 늘어나지가 않음, 왜냐면 이건 딜레이랑 관계된거니까 1 s = 1000 ms Per connection 당 W 개의 segments-window 를 만든다고 가정해보자 다음과 같은 공식을 따른다 W = 2 * bandwdith * delay 예를들어 100 Mb/s, delay = 50ms 라면 W = 2 * 100 Mb/s * 50ms = 200 Mb/s * 0.05 S = 10 Mb (윈도우 사이즈가 10메가 피트인거) 따라서 만약 한 segments 가 10kb 라면, W has 1000 segments 윈도우는 양방향 이므로 한 방향으로 500개의 segments가 있는것. 즉 윈도우는 양방향을 의미하며, 10Mb 사이즈의 윈도우라면, 각 방향으로 5Mb 씩 사용이 가능한것. 5Mb 양이 가는중이거나 오는중인것. 윈도우 Ack 하는 방식에는 여러가지가 존재한다 Go back NReceiver: 단 한가지만 버퍼 한다 (1,2 이후에 3만 기다리는거) 만약 도착한 sequence 가 내가 기다린거면 오케이 만약 아니라면 뭐든 상관없이 싹다 버리고 내가 원하는거 올때까지 기다린다 시간제한이 지나면 해당 세그먼트를 재전송 하라고 송신자에게 요구한다 Sender 만약 일정시간내에 ACK를 받지 못하면 알아서 다시 보낸다 문제는 이 방식이 1 부터 100까지 보냈는데 수신자가 10 못받았다고 기다리면 10 부터 다시 보내야함 당연히 효율적이지 못함 Selective RepeatReceiver: 여러가지를 버퍼한다 (예를들어 1,2, [], 4, []) 받은 순서대로 ACK 한다 (즉 내가 원하던게 순서대로이지 않아도 일단 ACK 보냄) 받지 못한것도 ACK (못 받았다고 알려주는거) 이 행위를 SACK (selective ACK) 라고 한다 Sender: 각 segment 별로 타이머가 따로 존재한다 시간내에 ACK 못받으면 알아서 보냄 (각 segment별로 타이머가 존재하는것을 상기하자) 훨씬 효율적이며 요즈음은 대중화됨 매우 송신자/네트워크 위주이다 송신자가 transmssion 을 담당한다 UDP - 보내고 잊는다 (컨트롤 없음) TCP - 천천히 ACK를 기다린다 (메세지 전달을 보장함) 네트워크를 full로 쓸수 있게 optimize 한다 수신자가 송신자의 속도를 따라가지 못할 경우를 대비해서 flow control 이 필요하다 Flow Control: Receiver 쪽의 sliding windows Transport Layer: 네트워크로 부터 segment 를 받고, 어플리케이션 버퍼에 넣는다 Application 은 recv(N-bytes) 를 이용해 버퍼로부터 읽는다 SYN 과 ACK 를 통해서 송수신자는 서로 어디까지 읽었는지 보내지만, 수신자가 flow control window (WIN)의 크기또한 송신자에게 같이 보낼수 있음 즉 WIN의 크기를 송신자에게 보내서 송신자는 지금 수신자가 어느 상태인지 알수 있는거. 더많이 읽을수 있는데 보내는 속도가 느린지, 아니면 거의 꽉차서 조금 위험해서 속도를 줄여야 하는지. Congestion 교통체증: 뭔가 막혀서 지금 나머지 다 기다리는중 여러가지 이유로 존재 가능하며 어디서 무슨 이유로 이러는지 알 수 없음 송신자는 계속 보낸다 이는 상태를 개인이던 모두에게던 악화시킨다 혼잡은 곧 손실을 의미한다 Router Buffers: Queues FIFO on every interface 빠른 속도로 트래픽을 감당할 수 있다 문제는 이 큐가 오버플로우가 발생하면 패킷이 드롭되는것 보통 트래픽 패턴에 따라 좌지우지 된다 이렇게 패킷이 드랍되면, 수신자는 다시 보내라고 할거고, 송신자는 다시 보내고 결국 악순환이 이어짐 따라서 이러한 상황을 피하기 위해서 이 사태가 일어나기 직전까지 아슬아슬하게 성능을 최대한 유지하는게 관건 (물론 네트워크 상황은 변화기에 상황에 따라 알아서 변하는 알고리즘이어야 한다) 요점은 효율성 (최대한 네트워크 최대치를 사용) 그리고 공평하게 (모두가 비슷한 사용량) Network layer 가 혼잡을 see 할수 있다 (IP - ICMP 말하는듯) 따라서 피드백을 줌 Transport layer 에서 혼잡이 일어난다 (큐 오버플로우 등) 따라서 송신자의 행동을 수정함 TCP 윈도우 사이즈를 다이나믹 하게 조정한다 Statistical multiplexing 하면 안됨? 매우 어렵다 모든 어플리케이션은 다른 양상을 띄고 있고 로드는 항상 변하며 다양한 장소에서 혼잡이 발생 할 수 있고 한곳에서 전체적인 상황을 볼 수가 없다 따라서 이를 해결하기 위해서는 송신자가 지속적으로, 병행적으로 적응할수 있어야 한다 효율성과 공평성에서 가장 중요한것은 그 누구도 starvation을 겪으면 안되는것 그럼 송신자는 어떻게 “ADAPT” 할 수 있는가 OPEN/CLOSE loop Open: 서킷을 미리 예약해 두는것 Close: 피드백에 따라 적응하는거 Host or Network driven Host: 얼마나 사용할지 호스트가 정하는거 Network: 네트워크가 규약으로 정해둔거 (유동적이지 못함) Allocate bandwidth via Rate Based : 어플리케이션에게 어느 속도로 보낼지 알려줌 Widows size : 윈도우 사이즈 (control flow)로 보고 정함 TCP의 경우 Closed, host, window based 이다. Additive Increase, Multiplicative Decrease (AIMD) 송신자는 천천히 송신율을 올린다 혼잡을 일으키는 숫자를 줄이니,결국 더 많이 보내는것 혼잡이 발생하는 순간 배수적으로 송신율을 줄인다 빨리 줄여서 혼잡을 최소화 시키는것 장점: 모든 호스트가 이 방법을 쓰면 모두 공평하고 효율적으로 대역폭을 사용할 수 있음 위상을 알 필요가 없음 (왜냐면 피드백 위주니까) 모두가 (조금씩 다른 방법으로 ) 한다 다른 control law 에 비해 효과적으로 작동함 네트워크로부터 단 한가지의 신호만을 필요로함 (사실 리시버로부터) 왜냐면 수신자가 혼잡 상황에 대해 알려주기만 하면됨 밑의 표를 참조 How network signal the sender AIMD implementationACK Clocking ACK가 돌아오는 속도를 보고 송신자가 이에 맞추는것 보낸 속도보다 ACK 돌아오는 속도가 적다면, 중간에 무슨 이유던간 라우터가 buffer 에 저장되어 있는 상태를 의미하기에, 이 라우터 버퍼 오버플로우를 방지하기 위해 속도를 줄이는거 이 돌아오는 속도로 Congestion Window (CWND) 를 계산 할 수 있다 W (window size) 보다 작다, 또한 CWND 는 WIN 과 전혀 관계없다 WIN 은 수신자 컨트롤 플로우 사이즈이고, 혼잡 CWND는 라우터에 관한거 (혹은 네트워크 전반) 적은 손실과 딜레이를 네트워크상에 가능하게 한다. Clocking 을 통해, burst 를 smooth 하게 바꾸면서도 같은 송신율을 유지한다 중간 라우터에서 queue up 하지 않으니까 그렇다면 이 CWND를 처음에 어떻게 알 수 있을까? 처음 1 패킷 부터 보내기 시작해서, 손실 없이 ACK가 돌아오면 CWND 를 1씩 더한다 ⇒ 이 방식은 매우 안전하지만 동시에 매우 느리다 (이는 곧 비효율성을 의미한다) 따라서 이 CWND의 효율적인 증가및 감소를 위한 알고리즘이 바로 TCP Slow Start 극 초기에 (1부터 시작할때) 1씩 더하지 말고 ACK 가 올떄마다 2씩 증가시키는거 첫 시작은 slow (1이니까) 대신 빠르게 속도를 올림 배수로 증가시키기에 어느 한순간 급작스럽게 congestion을 만들어 패킷 손실/피드백을 받을것이다 이럴 경우 multiplicative 하게 감소한다. 이 감소 방법에는 여러가지 버전이 있지만 초기버전의 경우 Threshold: ss-thresh = 0.5 * CWND (@ loss) (Reno 방식이다) 이 순간부터는 배수가 아닌 더하기 형식으로 증가한다. Fast retransmit (빠른 재전송) Pre-SACK: 만약 기다리던 segment 가 아닌 다른 세그먼트가 도착한다면 예를들어 92 108 116 124 가 도착했다고 하자 ACK는 기다리는 넘버를 의미하니 수신자가 송신자에게 ACK 100 을 보내야 한다 108 이 도착하면 ACK 100, 116 이 도착하면 ACK 100, 124 가 도착해도 ACK 100 을 보낸다 이 ACK 100 이 세번 도착하면 해당 100 데이터를 (타이머가 되기전에) 빠르게 다시 보낸다 만약 잘 도착했다면, 현재 내가 보낸 데이터들 다음 번호인 132 (124+8) 이 도착할것이고 만약 100 이후에 잃어버린 세그먼트가 있다면 그 세그먼트에 대해서 ACK를 보낼것이다 따라서 타임아웃 되기전에 빠르게 고치려고 하는것. 주의 해야 하는점은 빠른 재전송의 경우 같은 ACK를 세번 받았을때 행해진다. 이 빠른 재전송이 일어나면 CWND 를 반으로 줄여야 한다. 타임아웃이 일어나면 1부터 다시 시작하는것 초기 모델은 이 타임아웃과 ACK 3번 중복을 받으면 (둘중 하나) 그럼 바로 1부터 시작했음 현 Reno의 경우 타임아웃은 심각하게 (1부터) 3-중복은 덜 심각하게 (* 0.5) 받아 들인다. Fast Recovery (빠른 회복)빠른 재전송이 일어났으면 일단 cwnd 는 반으로 줄이고, 빠른 재전송이후 seq number 가 어디에 있는지 기다린다 (즉 이 기간동안 기다린다 패킷 보내지 않고) 기다리는 동안 해당 100 ACK 이 오면 cwnd 1씩 증가 만약 그 다음 segment 들이 모두 성공적으로 도착했다면 (catch up 헀다면), 반으로 감소시킨 CWND 로부터 증가시켜 간다 (ACK Clock 을 유지한다) 안고쳐지면 타임아웃이 일어날거임, 그럼 cwnd = 1, ACK clock 또한 초기화 한다. 여러가지 방식들이 존재한다 TCP Reno 위의 얘기한 0.5를 곱하는 방식이다. 이 방식은 한 손실을 고칠수 있다 per RTT 즉 하나 손실하면, 보내고 기다리고 (고쳐진지 확인) 만약 여러 손실이 발생하면 CWND 를 반으로 감소시킨다 TCP New Reno ACK 분석이 더 좋으며, 이로 인해 여러 손실들을 고칠수 있다 per RTT TCP SACK 훨씬 좋다, 수신자가 ACK를 범위 단계로 보내기 때문에 송신자가 필요한것만 여러개 딱딱 보낼수 있음.","link":"/2020/03/08/Network/Congestion%20add6356566344a51ab188da187eac9bf/"},{"title":"Resampling Methods","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html ResamplingExtract sample from training data set, and apply series of models. Application of several models will allow users to estimate which “region” will our models be when the data gets changed. Cross-ValidationTest error and training error are different. Lowering the test error (data that was not given) is the goal. Training error is the error in the given data that can be underesitimated due to overfitting. There are two ways of esitimating test error (often future prediction case) Indirectly infer test error by mathematical edition on the training data set (AIC, BIC). Hold out some training data to directily infer test error (Cross-Validation). The vaildation set approach Hold out half of training set randomly — picked data is called vaildation set. 반을 자르기 때문에 어떻게 잘리느냐에 따라 모델 변동과 test MSE 도 심하게 변함 Use remainder training set to get error rate (ususally MSE) about vaildation set and infer test error rate. Degree of polynomial 이 에러를 줄이는데 도움이 안됨을 알 수 있다. 어떻게 잘렸는지에 따라 test MSE와 degree 또한 확연하게 달라진다 반을 잘랐기 때문에 추정 성능 또한 감소한다 - 반으로 적합하다고 모델을 정의 하면, 전체 자료를 적합했을 때는 test MSE가 크게 나올수 밖에 없다 (overestimate 한거니까). 반으로 전체를 예상할수 있다고 한것 Leave-one-cut Cross Validation (LOOCV)한개의 자료를 빼고 이 자료에 대한 error rate 을 계산하는데, 이 계산을 모든 자료에 반복한다. Training MSE is unbiased to Test MSE but has huge variance. Random error 를 포함하고 있어 이로 인해 분산이 생기는것. 이 분산들을 보완해주는게 validation 이다. validation으로 분산을 줄이지만, 약간의 bias가 생긴다. 이 약간의 편향된 모델들을 평균냄으로써 분산이 줄어드는것 데이터 반을 가지고 하는것에 비해, test MSE에 대한 training data가 거의 정확한 추정이 가능하다. 이는 overestimate 하지 않으며 bias가 적음을 의미한다 Validation set approach 와 다르게 항상 같은 결과가 나온다. K-fold Cross-Validation가장 대중적으로 test error rate 구할때 사용하는 방법이다. 최선의 모델이나, 최종 선택된 모델에 관한 테스트 에러에 대해 이해하는데 사용된다. Validation set approach 는 너무 단순하고 LOOCV는 손이 너무 간다 (하나하나 적합해야 하니까). 이 중간지점이 k-fold CV. k 그룹으로 랜덤하게 데이터를 나눈다. 한 그룹을 뺴고 적합해 MSE 구하는것을 k번 반복한다 (LOOCV 처럼). 이후 K로 평균을 낸다. k = n 일경우 LOOCV와 같은식이다.k-fold CV는 LOOCV에 비해 더 간결하고 빠르게 계산을 함에도 불구하고 성응에서 큰 차이를 보이지 않는다 (좋은쪽으로). 즉 LOOCV의 장점들을 다 가지고 있다. 또한 bias-variance trade off에서 LOOCV보다 더 강점을 가지고 있다 (다음 항목 참조) Bias-Variance Trade off for k-fold CV 위 식에서 알 수 있듯 test MSE는 bias 만으로 결정 되는것이 아니다. Variance의 관점에서 (위에 서술하였듯) LOOCV 보다 k-fold CV가 더 좋다. LOOCV는 낮은 bias와 높은 variance를 가지고 있는데 이는 적합시의 데이터 n-1개중 n-2가 동일한 데이터 (두개의 적합에서 2개를 제외한 나머지 데이터는 재사용된것들) 따라서 재사용을 많이한 n개의 모델들는 highly correlated 되었기 때문이다. highly correlated —&gt; higher variance (overfitting과 비슷한 개념) 이로 인하여 덜 겹치는 k-fold CV가 더 낮은 분산을 갖는것이다 CV on Classification Problems 식이 조금 달라졌다. 이전까지의 계산은 데이터 수에 대한 양적 변수를 가정한 CV였고 위의 식은 질적 변수에 대한 식이다 (질적 테스트는 error rate를 의미한다) 검은색 선이 10-fold CV인데 파란색인 training error에 비해 테스트 에러를 잘 잡아주고 잇는 모습이다. 저 테스트 에러는 진짜 테스트 에러로 (시뮬레이션 데이터를 이용한) 실 상황에서는 구하지 못하는 경우가 많은 선. 따라서 위 그래프는 진짜 에러 비율에 대해 k-fold CV가 어느정도로 잘 잡아주는지 보여주는 것. Bootstrap실제로 계산하기 어려운 uncertainty 들을 계산하는데 쓰이는 강력한 기법이다. 선형희귀의 계수 분산의 경우 표준편차 정도는 구할 수 있지만 이에 대한 정확한 통계량은 구할 수 없는데, bootstrap은 이를 가능케 한다. 또한 이 방법은 분포를 미리 가정하지 않은 (실상황처럼) 상태에서 사용 할 수 있기 때문에 더 강력한것. 밑의 식은 a, 1-a를 각 두 회사에 비율 투자할때, 분산을 (risk) 최소화 할 수 있는 비율을 찾는식이다. 위와 같은식을 사용 할 수 있는 이유는 아래와 같이 가지고 있는 데이터들을 복원추출 하여 새로운 샘플들을 계속 만들어 내기 때문. 밑의 식을 반복하여 큰 수인 n 개의 샘플들을 만들어 이에 대한 추정량 hat(a)가 생기는것. 위의 식을 이용하며 추정량에 대한 standard error 또한 구할수 있게 된다. 노란색이 모든 자료들을 가지고 반복 추출해서 구한값, 파랑색이 bootstrap으로 하나의 data set만으로 반복추출해서 얻은 결과이다. 매우 비슷함을 알 수 있는데, bootstrap이 적은 data set으로 구하기 힘든 통계량의 특성까지고 구사 한다는것을 알 수 있다. Bootstrap for Prediction Error?bootstrap 샘플의 경우 원래 데이터 들과 많이 겹치게 되는데, 이로 인해 true prediction error 을 많이 underestimate 하게 된다. 마찬가지로 원래 데이터들을 훈련 샘플로 쓰고 bootstrap의 데이터들을 vaildation 에 쓰게 되면 안 좋은 (쓰레기 같은) 값이 나온다. 이에 대한 데이터 셋 겹침을 구할수 있으나, 매우 복잡해지고 이로 인해 결국 CV가 prediction error를 예상하는데 더 나은 방식이 된다. 정리하자면 Test error rate을 구하는데는 bootstrap. Prediction error을 구하는데는 CV.","link":"/2020/04/01/MSL/MSL_Resampling%20Methods/"},{"title":"Network - Lab 1","text":"Reference: The Australian National University CECS Q: Why frequency? A: 자연은 날카로운 엣지 (디지털) 를 좋아하지 않고 웨이브를 선호함. 빛, 전자, 소리, 액체등 파동 (팍 하고 튀는거) 스위치는 순간적이지도, 지속적이지도 않음 (한번 킬때 팍 보내지도, 계속 보내지도 않음 짧은시간 유지임) 전구또한 확 켜지는게 아닌 밝아지고 어두워지는 형식. 즉 아날로그 파동과 주파수들의 조합을 이용해서 디지털 엣지를 구현하는식. Q: Why FDM &gt; Frequent Shift Keying? A: Because electronics can be tuned to a frequency and use it as a dedicated channel with ASK/PSK. Hence better than using an idle frequencies and jumping between them. 즉 한 주파수 내에 정보를 담을수 있는데 주파수의 높낮이로 정보를 보내는것은 비효율적이다. Q: The benefit of the thicker coax, and what are the main downsides? A: Greater Shielding and noise protection, less resistance hence longer runs with same power. However; difficult to deplof (stiff) and expensive. Q: Diff betwenn cat5 and 7 A: 7 has foil —&gt; shield, solid core wires. Hence good quality and performance but higher cost with hard to deploy as it is harder to bend around the corner. Q: Fiber. Diff between multimode and single mode. A: Wider MMF core gets a brighter and broader light out of the end and easy to line up with LEDs. SMF core narrower than MMF and gives you much greater and higher data rates but costs alot more as it is harder to terminate and light up with laser (MMF uses LED) SMF: 레이저, 두께에 따른 성능 차이 적음, 멀티모드보다 훨 빠름, 매우비쌈 (레이저라서) MMF: LED 광원, 두께에 따른 성능차이 있음, 광원이 확산되고 코어지름이 커서 많은 신호를 보낼수 있는데 이로인해 전송거리가 SMF에 비해 짧음. Q: How 16 QAM works A: Each position represents a unique phase and amplitude shift of a signal wave. with 16 unique positions, can encode four bits per symbol (2^4 이니까 이진수로). Can arbitrarily allocate patterns to points (아무대나 배치해도 됨). Small bit pattern changes may result large changes in phase and amplitude ig. 0100 —&gt; 0101. Can have any QAM, but will be harder to separate n levels of ASK and PSK. Efficienfy = bits can encode per symbol. 35 = 5.1 bits —&gt; waste of spaces. Better to use power of 2. Q: Nyquist. 1Mhz wave with amp modulated to 8 levels. A: Potential datarate achievable = 2 * 1Mhz * lg(8) = 6 Mb/s. We multiply 2 as we can use 180 degree phase shift key = 2 bits into a single wave. Q: Why copper less useful in longer distance? A: It has too much attenuation (energy loss) as wire resistive especially with higher frequencies. Too Noisy as wire is an antenna Can be fixed with shield, twist, diff signaling, better connectors… Q: Why encoding bits into modulated signal important? A: It makes signal clear overall by ensuring a higher rate of transitions (easier to detect) to avoid same repeated bits like 1000000 hence solve “are you dead” problem. Provide a mechanism for clock-recovery hence able to know how wide a bit is. (data rate and clock sync - bit boundaries). Q: dB, dBm, and dBi mean. A: dB: signal/noise ratio. 20dB = 2B = 10^2. -20dB = -2B = 10^-2 = 0.01. dBm: zero point is 1mW (0dBm = 1mW, 20dBm = 100mW) dBi: measure gain of antenna relative to an isotropic antenna (transmitter or receiver). Q: How can make wireless transmission better? A: Shout louder or slower (clearer), frequency hopping to avoid noise (smarter), beam-shaping (focus), or higher/tailer antennas (terrain). Q: How can make signal go further? A: Repeater (regenerate signal), and amplifiers (both signal and noise). It costs money and power, and also may cause delay for unpack and repack process in repeater.","link":"/2020/03/24/Network/Lab%201/"},{"title":"Network - Lab 10","text":"Q: In the 7 layer model, what are some security ‘opportunities’ at each layer? A: Physical: Tapping (도청) Link: break in and listen/interfere 와이파이, 이더넷 Network: break in and listen/interfere 라우터, 게이트웨이, 모뎀, 방화벽 Transport: see/modify 어플리케이션 대화 Applications: for access to content or to interfere Q: The idea behind encryption is mainly seen as providing confidentiality. Why do we have both SSL/TLS and IPSec, if they do pretty much the same thing? A: SSL/TLS 와 IPSec 은 서로 다른 계층에서 실행된다 (트랜스포트, 네트워크) 따라서 다른 특징을 지님 TLS는 어플리케이션의 기밀성을 책임지지만, 여전히 출발지, 목적지, 포트 등의 정보를 드러낸다 IPSec 의 경우 본래 패킷에 대한 모든것을 숨기며, 터널을 제공함으로써 src / dest 에 대한 정보를 숨김 또한 IPSec의 경우 어플리케이션 계층을 커버하는 반면, TLS는 오직 어플리케이션만을 책임짐 Q: What does it mean to have ‘confidentiality’, ‘authenticity’ and ‘integrity’ of packets traversing the network? What about ‘freshness’? A: Confidentiality: 아무도 듣지 못함 Authentication: 상대방이 주장하는 신원이 확실하다고 믿음 (즉 본인확인) Integrity: 패킷이 중간에 변질되지 않았음 Freshness: 패킷이 새로운것이며, 재사용되지 않음 Q: Why does TOR (onion routing) use 3 routers for passing traffic through? A: 아무도 한번에 어디서 어디로 향하는지 알게 하지 못하게 src &amp; dest. 이로 인해 그 누구도 양 종단에 대한 정보를 알지 못함. Guard: Knows src Middle: Knows nothing Exit: Knows dest Q: Why would a worker on the road use a ‘mixed-mode’ VPN connection to their office? What’s the benefit, compared to say a ‘transport-mode’ VPN? A: Mixed-mode 란 호스트와 라우터 같이 다른 기기가 연결된 모드를 말한다 이로 인해 이 호스트는 라우터에 속한 다른 기기들에게 마치 같은 LAN에 속한 기기처럼 보여질것 Transport Mode 는 호스트와 호스트를 직접적으로 바로 연결한다. 차이점은, 만약 해당 대화가 (communication) 이 point to point 형식이라면 Transport 모드를, 여러명과 대화해야 한다면 mixed-mode 가 더 적절하다. Q: How does ingress filtering prevent (most) spoofing? A: 라우터의 경우 해당 패킷이 어디서 온건지 알 수 있다. 예를 들어, 어느 패킷이 항상 어느 네트워크에서 오는지 알고 있다면, 다른 곳에서 오는 (특이하게도) 패킷의 경우 필터링이 가능한것. 이전과 다르게 다른 네트워크에서 온 패킷을 마치 spoofing 처럼 고려해서 그냥 드롭해버림.","link":"/2020/06/22/Network/Lab%2010%201c6b99b66e024efa94f783010dbce271/"},{"title":"Network - Lab 3","text":"Reference: The Australian National University CECS 소켓 프로그래밍. (Socket Programming) Q: Why is the layer model for networking good idea? A: 레이어들은 어느 기능등이 제공및 미제공 되는지에 대해 명확하게 해준다 (각각의 레이어의 서비스들의 명확성). 필요한 기능들이 무엇인지, 그리고 상/하 레이어와의 관계, 그리고 존재하는 기준들의 사용등. Q: What’s a Protocol Data Unit, and what is a Service Data Unit? A: PDU는 말 그대로 네트워크 프로토콜을 통한 두 종단간의 정보교환 패키지를 말한다 (전송은 세그먼트, 네트워크는 패킷 응용계층은 데이터/메세지). SDU는 보통 API 를 통한 두 레이어간의 한 종단 지점에서 교환되는 정보 패키지를 말한다 (캡슐화 되서 넘어갈때). PDU는 같은 레이어의 교환이고 SDU는 한 모델안에서의 수직적 교환이다. Q: What’s the difference between a Frame and a Packet? A: 프레임은 랜 프로토콜에서 (데이터 링크) 전송되는 다양한(불분명한) 길이를 말한다. 패킷은 변수-길이 (정해진) 화물을 가지고 전역 네트워크로 전송되는 것을 지칭한다 (아이피 패킷같은). 데이터그램이나 세그먼트와 다르게 UDP or TCP와 같은 인터넷 프로토콜로 전송된다. Q: Why do we think of IP as being ‘end-to-end’ between hosts, and TCP/UDP as being ‘end-to-end’ between applications A: 즉 아이피는 각 호스트 (기계들) 의 연결을, TCP/UDP는 어플리케이션 연결이 주된 임무라서. 아이피는 다양한 종류의 랜 기술과 라우터등을 통한 광역-구간 (인터넷)에서 기계간의 연결을 제공한다. 랜과 라우터등은 필요한 정보만을 읽은뒤 이 패킷들을 올바른 지역으로 보내주는 역할 (물론 체크섬이나 홉, 그리고 NAT의 경우 아이피 주소와 포트등을 수정하기도 한다). 운영체제는 패킷을 받고 언팩한다 (포트가 운영체제에게 키를 전달해준다). 아이피는 종단에서 다른 종단을 찾아 내는데 필요하다. 어플리케이션은 TCP/UDP (외 다른 프로토콜) 를 서로간 대화하는데 필요로 하는데, 포트는 운영체제에게 키를 제공함으로써 패킷 수하물 (페이로드)가 올바른 어플리케이션으로 전송되게 한다. 라우터와 다른 기기들은 (NAT와 깐깐한 네트워크 보안을 제외하고) 패킷안의 내용을 확인하지 않는다. TCP/UDP 는 어플리케이션끼리 이야기 하는데 필요한 프로토콜, 종단간의 위치를 찾는데는 사용되지 않는다. Q: Why does the IETF standards process look for ‘rough consensus and running code’? A: IETF (프로토콜 표준화 기구). The phrase is often extended into the saying “rough consensus and running code”, to make it clear that the IETF is interested in practical, working systems that can be quickly implemented. (거친 합의란, 모든 사람이 동의할 필요는 없지만, 관련자들간에 사용 될 수 있도록 합의된 상황이다. - 정치권에서 정당내에서 의견이 다르지만, 정당의 의견을 거친합의로 모은후 대중에게 알리는것과 같은것). 표준화를 만든다는것은 매우 복잡하고 끝이 보이질 않는 작업이다 (RFC 는 표준화 프로토콜의 공식 문서다). 프로토콜은 RFC문서에 명확한 기준을 가지고 명시되는데 이는, 다른 사람과 당신이 서버/클라이언트에서 통신할 수 있도록 가능케 해준다. 즉 이 거친 합의는, 모두가 이 프로토콜을 따르지는 않지만, 이 프로토콜을 따르는 사람들 끼리의 통신을 가능하게 한다. Q: Which IP header and which ICMP packets are important for traceroute to find the path of packets? Why? (how does it use them?) A: ICMP (Internet control message protocol). TTL값은 IP 데이터그램이 인터넷 시스템 내에서 존재할 수 있는 시간의 상한선으로 볼 수 있다. TTL 필드는 데이터그램의 송신자에 의해 설정되며, 목적지까지의 전송 경로에 있는 모든 라우터들에 의해 그 값이 감소된다. 목적지에 다다르기 전에 TTL 필드의 값이 0이 되면 해당 데이터그램은 폐기되고 ICMP 에러 데이터그램 11 - Time Exceeded가 송신자에게 보내진다. TTL 필드의 목적은 전달되지 못한 데이터그램이 인터넷 시스템 내에서 지속적으로 순환하여 넘쳐나게 되는 상황을 방지하는 데에 있다. Traceroute는 1부터 선형적으로 늘어나는 TTL을 포함시켜 목적지로 보낸다 (죽으면 하나 늘려서 다시 보내고 등등). Each router will decrease the TTL by one, our server on the other end will receive an IP packet with a TTL of one and replies with an ICMP reply to H1. We now know that the destination is reachable and we have learned all routers in our path. Each IP packet that we send is called a probe. Traceroute can be used with ICMP, UDP and TCP, depending on your operating system. 정리: TTL이 0이 될때마다 라우터는 자신의 아이피 주소와 시간초과 패킷을 보내고, 서버또한 수신 응답 메세지를 보내므로, 서버까지 도달하는 라우터들의 주소 즉 경로들을 알 수 있게 된다. 이 방법은 최단 경로를 항상 의미 하지 않으며, 최단 경로를 제공 받는 경우는 라우팅 테이블이 최적으로 관리되고 있을때만이다. Q: Given some /25 address range, how many hosts could we potentially have on our network? What does the /25 netmask look like in dotted-quad notation? A: 네트워크 주소는 총 4바이트로 32비트이다. /25는 첫 25비트가 호스트 주소이고 나머지 7비트가 내 개인 주소가 된다. 2의 7승은 128인데 1개는 유선, 1개는 브로드캐스트 주소를 빼면 128-2 = 126개가 된다. /25 넷마스크는 첫 25 자리가 모두 1이라는 뜻이므로 255.255.255.128 이 된다. 즉 128~255 사이의 128개 중 126 개가 가능한것. Q; What’s the benefit of using the longest-prefix rule in forwarding table? A: 수많은 주소들은 한 곳에 축약할 수 있음 (이 프리픽스에 해당하는 주소들을 프리픽스로 통합이니까). 이로 인해 예외적인 주소들을 추가 하고 싶으면, 해당하는 주소 한개만 더 추가하면 됨 (프리픽스 안에 주소 중 하나여도). aggregate an entire network’s worth of host addresses into a single entry. 장점은: 경로 찾기의 성능향상, 비용 감소, 안전성 증가. IPv4 주소 Q: Why would a host send a Gratuitous ARP frame? A: 쓸데 없는 ARP란 답변을 바라지 않는 브로드 캐스팅 패킷이다. 패킷안에는 송신자와 수신자 모두 같은 아이피를 가지고 있으며, 맥주소는 브로드캐스트 주소이다. 유용한 이유로는 다음이 있다. 아이피 충돌 감지. 해당 패킷을 받은 머신은 자신의 아이피와 비교후 충돌하는지 알 수 있다. 먼 DHCP에게 아이피를 받는 경우도 있어서 중복될 경우 충돌 확인이 가능하다. 혹은 자신이 아이피를 바꿀 경우에도 1,2번 모두 도움 가능. 다른 머신들의 ARP 테이블 업데이트를 도운다 (라우팅 테이블 같은거) 각 머신의 맥 주소 스위치에게 어는 포트로 연락을 취해야 하는지 알릴수 있음. (스위치는 해당 네트워크 세그먼트를 향한다고 생각하면 된다.) Gratuitous_ARP","link":"/2020/04/11/Network/Lab%203/"},{"title":"Statistical Learning","text":"Reference: An Introduction To Statistical Learning with Applications in R (ISLR Sixth Printing) https://godongyoung.github.io/category/ML.html Why Estimate f? Prediction: hat(y) represents prediction of y. reducible error: imperfect estimate of hat(f) of f - can be fixed by using SL to estimate f. irreducible error: error introduced by random error term cannot be reducible no matter how well estimate the f. larger than zero: as there are some useful variables not considered in predicting y. There are unmeasurable variation that may change day by day. Parametric Methods make an assumption about the functional form. stick to esitmating the chosen form instead of testing all of the others; know what u need. Uses the training data to fit or train the model. For linear → least squares. Assuming a parametric ease the entire process compares to trying to fit the model into arbitrary forms. It may not match the true form of the function, which can be fixed by flexible model (it requires far more parameters though). But this flexible model can also be overfitting (follw the errors or noise too closely). Non-parametric Methods Do not make explicit assumptions about the f form. seek an estimate of f that gets as close to the data points as possible. Pros: potential to accurately fit a wider range of possible shapes for f (모양을 가정하지 않기떄문에) Cons: large # of observations is required. Wrong amount of smoothness may result in overfitting - as it does not yield accurate estimates. Tread offs in flexi and interpreta IF interested in inference → more restrictive model is more interpretable. ⇒ difficult to understand how individual predictor is associted with the response. Interested in prediction: moderate flex and interpret is better due to the possibility of overfitting. Supervised vs Unsupervised Learning Unsupervised: lack a response variable that can supervise our analysis. Cluster Analysis: whether the observations fall into relatively distinct groups → each group may differ. Not be expected to assign all of the overlapping to their correct group (too crowded). Will be covered in the different chapter. Regression vs Classification Quantitative - Numerical Values regression Problems Qualitative - K different classes or categories. Classification Problems The differene is vague. Both can be co-used in various methods. Although tend to select via type of response varaible (패러미터의 타입은 중요하지 않음). Measuring the Quality of fitMeasure of how well its predictions actually match the observed data. In the regression setting, it is MSE. Interested in predicting unseen test observation (whether it is future event or not) which is not used to train the model. Consider Degree of freedom and MSE results for finding suitable methods. we observe a monotone decrease in the training MSE and a U-shape in the test MSE. This is a fundamental property of statistical learning that holds regardless of the particular data set at hand and regardless of the statistical method being used. As model flexibility increases, training MSE will decrease, but the test MSE may not. When a given method yields a small training MSE but a large test MSE, we are said to be overfitting the data. Bias-Variance Trade off Variance: amount by hat(f) would change if we used different training data set to estimate it. x의 변화에 민감하게 그래프가 꺾임. Least Square (straight line) has inflex, low variance.In general, more flexible methods have higher variance. Bias: error that is introduced by approximating a real-life problem. Linear regression (straight line cannot explain real life) results in high bias but also could estimate accurately via cases.Generally, flexible → less bias. Classification Settingequal = 1, inequal = 0 Above equation computes fraction of incorrect classification = training error rate as computed based on our training data for the classification. Test error rate. A good classifier = one has small test error rate. = Misclassification error rate. Bayes Decision Boundary: line that assign each test data sets into categories it belongs to. It has the smallest error (in the population). In real life, not know the conditional distribution of Y given X. so impossible to use. K-Nearest Negihborsk-최근접 이웃 알고리즘 attempt to estimate the conditional distribution then classify to get highest estimated probability. Identify K points in Tr that are closed to x_0 represented by N_0. Estimates conditional prob for class j as the fraction of points in N_0 whose response values eq j. Applies Bayes Rule and classifies with the largest prob. As K grows, the method becomes less flexible and produces a decision boundary that is close to linear. This corresponds to a low-variance but high-bias classifier.","link":"/2020/03/08/MSL/MSL_Statistical%20Learning/"},{"title":"Network - Lab 4","text":"Q: TCP 192.168.1.2:53398 150.203.56.47:80 CLOSE_WAIT A: 소켓이 현재 닫혀진 상태이나, 웹 서버로부터 마지막 ACK를 받기를 기다리는 상태 Q: Packets with a source IP address of 0.0.0.0 is used (by DHCP) to signify what? What does the address mean to the Operating System? Why do we use it that way? A: 이는 해당 호스트가 현재 아이피 주소를 모르고 있은 상태이고, 이로 인하여 해당 호스트와 연락하기 위해서는 브로드캐스트를 이용 할 수 밖에 없다. 운영체제에서 0.0.0.0 은 “모든 인터페이스” 를 뜻하며 모든 인터페이스들에게 보내지고 모든 인터페이스는 이 메세지를 듣는다. Q: Why does DHCP have both discover/offer AND request/acknowledge? Why not justrequest/acknowledge? A: DHCP의 아이피 주소 할당은 임시 (lease)이며 확인되어야 하기 때문이다. 또한 만약 여러기기가 동시에 같은 아이피 주소를 요청할 경우를 대비해야 하기 때문이다. 따라서 서버와 클라이언트는 해당 아이피가 고유하다는것을 알기위한 확인 절차가 필요하다. Server Discovery IP lease offer IP Request IP lease ACK Q: Give some examples where and why a single IP address may be used by multiple (DNS)names? What about examples where a single name may resolve to multipleaddresses? A: 예를 들어 같은 아이피 주소를 가지고 있는 웹서버와 메일 서버 같은 다른 서비스를 제공하는 경우. 이는 결국 일어날 서비스의 이동에 대한 유연성을 준다. 한 이름에 대한 여러가지 주소를 가지는 경우는 옵션과 같이 사용되는데 첫번째가 사용 불가하면 두번째가 사용된다던가, 혹은 이로 인해 로드 밸런싱도 가능하다. Q: In DNS, how are Zones and Domains different? A: 도메인의 경우 DNS 의 일정 부분을 이야기한다. 예를 들어 anu.edu.au 의 경우 도메인이고 (au, edu, anu 순으로 내려온다), 이 이하의 다양한 부서와 서버들과 같은 여러가지를 묶어서 zone 이라고 표한다. Q: Why are DNS delegations legally important? A: 도메인 네임은 보통 그 해당 entity의 법적 이름과 연결된다. 즉 구글이라는 사업체가 있는데 이를 모방해서 google.com 등을 사용한다면? 이는 곧 사기와 trademark infringement 와 같은 법을 어기는것. Q: What’s the difference (and for/against) using Iterative or Recursive DNS queries? A: Interative 는 내 스스로가 정보를 받고 다음에 물어보고 받고 물어보고 하는형식 Recursive는 네임서버에게 물어보면 걔가 알아서 물어물어 정보 가져다 주는것. 당연히 Recursive가 편하지만 더 느림.","link":"/2020/05/26/Network/Lab%204%20428af546b17f49db86c3c876a150e074/"},{"title":"Network - Lab 5","text":"Q: What is the ‘root’ of the Domain Name System? i.e. what is at the very top? A: “,” is the root of the DNS. It is to refer the root DNS server Let’s look at some Fully Qualified Domain Names (FQDN) with different Top Level Domains (TLD). Consider: www.anu.edu.au. and www.gov.au Q: Which part is the ‘genericTLD’ (gTLD)? A: Edu, gov. Q: Which part is the ‘countrycodeTLD’ (ccTLD)? A: au 다만 미국의 경우 us 를 사용하지 않음. Q: Which part is the hostname? A: www 가 이에 해당한다. DNS에서 해당 주소 (www.anu.edu.au) 의 A가 이 호스트 주소에 해당된다. 호스트 네임은 종단 기기에 지정된 이름 (DNS를 통해 식별) 도메인 네임은 네트워크에 지정된 이름 (네트워크에 연결되야함) Q: In the case of cbs.anu.edu.au is the ‘cbs’ a hostname or a domain name, or both? How can you tell the difference? What’s the benefit/downsides of this approach? A: 모두 가능하다. (host and domain) www.cbs.anu.edu.au 혹은 mail.cbs.anu.edu.au 와 같은 호스트네임을 가질수도 있다 (www, mail) 아니면 cbs.anu.edu.au 라는 cbs 호스트 네임을 anu.edu.au 라는 도메인에 가질수 있을수도 있음 어차피 DNS를 통해 확인후 전달 하기 때문에 길다면 줄일 수도 있는거. 대신 커넥션을 만들기전에 확인해야 한다. 만약 종단의 이름이 a 이고 도메인이 x 라면 해당 종단에 대한 주소는 a.x 가 되는 형식 Q: In HTTP, how does the application handle the ‘session’ and ‘presentation’ layers? A: 세션은 쿠키로 관리된다. 또한 URL-Referenced tokens 들로 관리 되기도 하는데 이때는 쿼리 필드의 어느 부분을 공유하는 식을 이용한다. 세션 기반의 문제점은 이 기록을 서버에 저장을 해야 하는데, 이로 인해 확장성이 좋지 않음 세션을 유지 할 수 록 더 많은 트래픽을 감당하기 위해 프로세서, 서버등을 추가해야함 이 과정이 매우 복잡하다 토큰의 경우 상태 유지를 하지 않아 (stateless) 고로 확장성이 좋다 클라이언트 쪽에서 정보를 저장하기 때문에 서버 확장에 용이하다. 또한 클라이언트가 서버에게 쿠키를 전달하지 않음으로 쿠키로 인한 보안 취약점이 사라짐 (대신 토큰 보안 취약점 존재)","link":"/2020/05/26/Network/Lab%205%20b6548719daad4143ab78c5edc0d51241/"},{"title":"Network - Lab 6","text":"Q_1: What causes the ‘latency’ on the left? A_1: sender/receiver transmission 딜레이로 피할수 없는 딜레이 이다. Q_2: What causes the long tail at the far right? A_2: 도착하기 까지 여러 구간에서 다양한 이유로 멈춰진 패킷들의 도착 Q_3: What would cause jitter to become very large? A_3: 지터는 다양한 넓이의/종류의 딜레이를 나타낸다. 아마도 이와 같은 경우는 중간에 경로가 다양하게 바뀌었거나, 해당 경로의 라우터들의 load가 갑자기 바빠지거나 한듯하다 Q: Why is packet 4 not able to be played out, since it was received? How could we fix that? What problem does that cause? A: 수신 버퍼의 길이가 패킷 4를 수신하기에 너무 짧았음. 이를 고치기 위해 버퍼의 길이를 더 늘릴수 있지만, 그렇게 하면 송신과 플레이 시간의 지연이 더 커질것임. 따라서 실시간이라 부르기 애매해진다 (내가 말하고 몇초뒤에 상대방이 답한다던가 하는것). Q: Why is retransmission (except in multicast) generally a bad idea? Why is it ok in multicast? A: 잃어버린 패킷을 감지하고, 재요청하고 (그 잃어버린 패킷을 아직 가지고 있길 희망하면서), 패킷을 받는과정이 너무 오래걸리기 때문. 물론 재요청해서 바로 받는다는 보장도 없다. 멀티캐스트에서는 retransmission 해주는 위치가 가까울수 있어서 지연이 줄어들기 떄문. Q: Why are the performance problems reduced in streaming applications? A: 문제는 여전히 존재하나, 이는 단방향 트래픽이기 때문에 딜레이를 알아차리지 못한다 (화상 통화가 아닌 트위치 같은거 말하는거). 이 뜻은 내가 받은 버퍼의 크기를 키워서 안정적인 (reliable) 프토토콜을 사용 가능하다는것. → 내가 트위치 볼때 안끊기기만 하면 되니까 이에 맞춰 버퍼만 키우면됨 Q: What are the main network and device issues for IoT? Why is it different to other devices connecting to the internet? A: Scale, Power, Network, Timeliness, Reliability → 해당 자료 읽어볼것. Q: As an application model, how is PubSub different to Client/Server? Why is it better suited to large-scale IoT applications? A: 클라이언트와 서버는 1:1 관계를 가진다 반면에 PubSub은 데이터 진원지 (소스)와 publishing 하는것이 나뉘어져 있기 때문에 서버/브로커를 통해 구독자들이 정보를 얻을수 있다. 또한 확장성과 관련해서 n 개의 생산자와 m의 소비자들이 있다면, n*m 대신 n+m의 직접적인 관계를 유지 할 수 있다 (중간에 브로커 하나). 또한 이러한 관계는 오직 해당 토픽에 관심있는 구독자들에게만 정보를 push 하기 때문에 reducing load for producers and brokers. Q: Why are MQTT packets so compact and simple? (compared to HTTP say) A: 성능과 부하를 위해서 이다. 짧은 메세지는 대역폭을 거의 소모하지 않고 간단함은 패킷 구성에 관한 CPU 소모량을 줄일수 있다. Q: Why does MQTT offer multiple levels of QoS (quality of service)? Why is there separate, potentially different, QoS on both sides of the broker (producer-&gt;broker, broker-&gt;consumer)? A: 상황에 따라 해당 메세지가 반드시 ensure 해야 할지, 혹은 가끔 업데이트로 충분한지, 혹은 메세지를 놓치더라도 다음까지 기다릴수 있는지 등 요구조건이 다르기 때문이다. 해당 소비자가 그 정보에 대한 중요도가 다르기 때문에, 중요하게 여기는 소비자는 높은 QoS를 이용할것이고 아니면 낮은 레벨을 사용할 것이다. 이로 인하여 데이터 소모량에 대한 유연성을 가질수 있다 (QoS 레벨에 따라 데이터 필요량이 다르니까 - 커뮤니케이션 횟수가 다름) QoS 0 을 선호하는 사람들은 굳이 복잡한 QoS 2 안 써도 되니까. Q: In what circumstances is it useful for a server to ‘retain’ an MQTT-published message? A: 소스가 가끔 메세지를 주던지, 소비자가 언제던지 들어올수 있던지, 혹은 비안정적으로 연결되어 있던지 할때 좋음. 서버에 리테인 함으로써 위와 같은 상황에 현재 which state (메세지) 가 있는지 빠르게 배울수 있음. 즉 서버가 정보를 가지고 있으면 소비자가 재부팅하고 (그 사이에 정보를 못받았던, 정보가 초기화 되서 아무것도 모른다던지) 다시 들어와도 빠르게 “응 지금 메세지 이 상태임” 하고 알려줄수 있는거.","link":"/2020/05/26/Network/Lab%206%2087131c3cc15447ffab50ef9be9e40b93/"},{"title":"Network - Lab 7","text":"Q: Can you explain the difference between unicast routing, broadcast routing and multicast routing? i.e. what are they trying to achieve? A: Unicast: 호스트간의 전달을 기반으로 다른 호스트에 부하는 주지 않는다. 다만 동일한 정보를 많은 호스트에게 전달할시에는 비효율적임 Broadcast: 단일 호스트가 세그먼트의 모든 호스트를 대상으로 전달. 여기서 세그먼트는 브로드캐스트 도메인, 즉 자신의 네트워크를 지칭함 Multicast: 흥미 있는 구독자와 그룹멤버들에게 예약된 주소를 통해 수신 (즉 유니캐스트 같은 브로드캐스트) 224/8 Q: Why does routing tackle fixed parameters about links, and ignore dynamic things likecongestion and load? A: 라우팅 알고리즘은 각각의 모든 라우터들이 포워딩 테이블을 만드는데 사용된다 (시간과 에너지) 이러한 알고리즘들은 congestion/load 와 같은 변화들에 빠르게 반응하지 못하며, 할 생각도 없다. 라우팅 알고리즘에서 가장 중요한것은, 해당 링크의 존재 유무 (크게는 위상)와 비용이다. 혼잡과 로드는 알고리즘의 부가적인 요소에 불과함 (먼저 라우팅 테이블이 있어야 혼잡이던 뭐던 해결책을 제시할수 있으니까) Q: What is a sink tree, and how does it differ from a source tree? A: sink tree = soure tree일때는 양 방향의 비용이 같을때이다. 즉 A부터 B가 3, B 부터 A가 2라면 싱크 트리와 소스트리는 다르다. 싱크트리: A에 대한 shortest paths의 조합 (모든 노드로부터) 즉 A로 싱크 소스트리: A로 부터 shortest paths의 조합 (모든 노드에 대해) 즉 A가 소스 Q: Can you explain the path optimality property? A: 어느 최단 경로의 부분 경로는 그 부분 경로간의 최단경로임 Q: What’s the downside of using Dijkstra’s algorithm? Why is Distance-Vector (Bellman-Ford) better? A: 다익스트라의 경우 전체 위상을 미리 알아야 하고, 모든 노드들을 알아야 함 DV는 음의 가중치일때도 사용 가능하며, 위상을 몰라도 되지만 시간 복잡도가 더 높음 Distributed algorithm Likn-satet: 링크 스테이트 라우터를 이용하여 서로 네트워크 위상을 배울수 있도록 메세지를 교환함. Q: What’s the benefit of regional route aggregation? What’s the downside? A: 장점은 네트워크의 포워딩/라우팅 테이블이 유의미하게 짧아지고 라우터들의 테이블 업데이트 유지에 관한 processing load를 줄여줌. (테이블이 짧으니 유지보수 할것도 적지) 단점은 해당 경로가 최단 경로가 아닐수 있음 Q: Why do we use different routing algorithms internally versus globally? A: 내부적으로 (지역) 정확한 지식을 가지고, 짧은 네트워크 반경을 가짐. 따라서 DV나 다익스트라, link-state 모두 가능하고 (다양한 라우팅 알고리즘 가능), reasonable 한 시간내에 완료 가능함. 외부 네트워크에 대해서 불완전한 지식을 가지고 있기에, 그냥 바깥 지역으로 던지고 걔네가 알아서 해결하게 두는게 편함. Q: What is the difference between a transit and a peering arrangement? A: transit: 나를 통해 다른 네트워크 갈 수 있음 (유료). Peering: 내 네트워크 내의 기기에 접근 할 수 있음 (대부분 공짜).","link":"/2020/05/26/Network/Lab%207%2073662f91a456426d96a6c0328115ddcb/"},{"title":"Network - Lab 8","text":"Q: On congestion, where does that actually happen on a network path? A: 어느 특정 아웃바운드 연결/경료에 대해 너무 많은 트래픽이 올시에 라우터의 버퍼에서 발생함 특정 아웃바운드 연결/경로가 중요하다. 각각의 연결/경로는 다른 버퍼를 가질수 있으니까. 라우터 버퍼가 가득참 → 패킷이 드롭됨 → 손실 발생 라우터 버퍼가 거의 가득참 → 패킷이 보내지는데 시간 걸림 → 지연 발생 Q: What’s the difference between ‘throughput’ and ‘goodput’? A: throughput은 통과하는 데이터의 볼륨 (크기)를 말한다 (그게 무슨 데이터간에). Goodput은 통과하는 “새로운” 데이터의 볼륨을 칭한다 (이게 어플리케이션에서 말하는 “effective transmission rate” 과 관계되어 있음). 즉 재전송이 아닌 새로운 데이터의 볼륨. Q: Why do we get a collapse in goodput as we approach congestion? A: 혼잡해질수록 새로운 데이터가 통과하는 볼륨은 줄어들고 대신 retransmission 과 이에 대한 requests만 늘어날테니까. Q: Why does TCP traffic (often) have a sawtooth pattern? A: 네트워크를 정찰 (probe) 하면서 혼잡을 일으키지 않을떄 까지 점점 증가하다가, 혼잡이 발생하자마자 바로 줄여버리니까 Additive Increase, Multiplicative Decrease (AIMD) Q: How can we detect congestion? (3 ways, at least) A: 패킷 손실 증가: 명확하게 혼잡 감지, 대신 혼잡이 생긴후에 감지 패킷 지연 증가: 혼잡이 생김을 예상 (추론), 혼잡을 미리 감지함 ECN: 혼잡을 감지 (라우터가 알랴줌), 대신 라우터와 호스트간에 협조 필요 IP header에 플래그를 설정한다. Q: How does Selective Acknowledgement (SACK) greatly help TCP performance? A: 송신자에게 수신가자 무엇을 받았는지 정확하게 알려줌으로써 놓친 부분만 다시 보내게 되니 보내는 양이 줄어들고 성능에 도움이됨 Q: What’s the difference between ‘fairness’ and ‘efficiency’ in networking terms? A: 공평성은 네트워크 접근에 공평하게 (비슷한 송신율) 처리되는지. 효율성은 전체적인 네트워크를 보면서 가능한 최대한 성능을 끌어 올리고 있는지 Q: TCP has (at least) 3 types of “windows” for managing the transmission of segments (overpackets). Explain their key roles: SendWindow, ReceiveWindow, and CongestionWindow A: SendWindow: 네트워크 효율성을 최대한 높이기 위해서 RecvWindow: 송수신자 간의 성능 밸런싱을 위해서 (수신자가 송신자보다 빠르면 문제가 발생함) CongestionWindow: 송수신자간의 네트워크의 capacity 를 (거의 즉각적으로) 계산해서 흐름간의 공평성을 보장함. 혼잡 윈도우는 그냥 전송가능한 버퍼크기라고 생각하면 되는데 송신자는 최대 자신의 혼잡윈도우 크기만큼 트래픽을 전송가능하다. 이 혼잡윈도우는 네트워크의 혼잡도에 따라 커지기도하고 작아지기도 한다.","link":"/2020/05/26/Network/Lab%208%201aac84c9f9ee44ff894faa1f52943dd2/"},{"title":"Network - Lab 2","text":"Reference: The Australian National University CECS Q: Statistical Mulitplexing 과 다른 양방향 차이점 (CSMA/CD 말하는듯) A: 통계적 멀티플렉싱은 “시도 해 보자” 형식으로 일정하며 공유되는 대역폭에 메세지가 전달되나 시도하는 방법 (겹치면 멈치고 나중에 다시 시도하고 그거). 나머지 TDM/FDM/SDM 등은 써킷으로 대역폭이 할당되어 있다. 즉 할당된 대역폭을 아무도 사용 안하고 있다면 그 대역폭이 낭비가 됨. Q: 왜 프레임의 시작 끝 부분을 프레임 플래그를 통해 보여주는가? 그냥 길이 안말해주고 A: 싱크가 엇나가기 너무 쉽기 때문에 (비트 하나 오류). 정기적인 시작/끝 부분을 명시하면, 모두에게 프레임 길이 안에서 회복할 기회를 주게됨. Q: 충돌 방지와 충돌 감지의 차이점 A: CA 는 모두가 랜덤한 시간을 기다리므로써 같은 타이밍에 전달 하는것을 막는다, CD는 충돌을 감지하면 멈추고 기다리는것. Q: CTS/RTS 가 Hidden Terminal 문제를 어떻게 해결하며, 왜 메세지 길이가 정보에 포함되는가 A: CTS는 구간내 모두가 들음으로써 RTS를 보냈던 송신자도 수신자가 받을 준비가 됨을 안다. CTS는 RTS를 보낸 송신자가 이제 메세지를 n 만큼 보낼테니 이 구간동안은 다른 사람들은 다 조용히 있으라는 정보를 같이 전달하는것. 메세지가 전달 된후 (기다림의 구간이 끝나면) 다른 사람들도 일 시작함.. 숨겨진 지국 문제는 충돌 가능성으로 인한 네트워크 용량 감소를 야기한다. 숨겨진 지국 문제란, 1 과 2, 2와 3은 서로 겹치지만, 1과 3은 서로의 존재를 모른다 (즉 데이터를 보낼수 없다) 즉 이로 인해 1과 2가 통신중일때 3은 2가 사용중이라는것을 모른다. 하지만 2가 CTS를 보냄으로써 사용중임을 3이 알 수 있고 기다릴수 있다. 이 CTS RTS는 핸드쉐이크 프레임이라 한다. CSMA/CA 에서 CTS 프레임으로 숨겨진 지국으로 인한 충돌을 막는다. 이 시스템 자체는 Multiple Access CA 로 MACA 라고 불린다. Q: 1000Base-T Ethernet A: 1000Mb/s over Twisted Pairs (copper) Q: Heartbeat signal (Normal Likn Pulse)를 Etheret은 왜 데이터를 송신하지 않을때 보내는가 A: 보냄으로써 자신이 존재 한다는것을 알리는것 (새로 연결됬던 기존이던). 이 시그널을 수신한 기기는 링크 라이트를 깜빡인다. Q: 802.3/802.11의 프레임이 왜 preamble 로 시작하는지 A: 수신자가 절전모드에서 일어나서 수신 받을 준비 (클럭 동기화)를 위해서. 이것이 프리앰블의 존재 이유이고, 클럭동기화는 고정된 프리앰블을 통해 시작한다. Q: 왜 무선 프레임은 fixed rate preamble과 header로 시작하는지 A: 신호율은 라디오 주파수에 따라 (거리 노이즈) 다른데 고정된 프리앰블이 양 기기가 모두 사용가능한지 아니면 주파수를 낮춰야 하는지 결정하기 위해서. Q: 스패닝 트리 프로토콜/알고리즘 을 이더넷 네트워크에서 사용하는 가장 큰 이득은 A: 루프들을 없애 broadcast storm, 중복되는 프레임들, 비순서적인 프레임들을 방지 할수 있다. Q: 가상랜은 이더넷 네트워크에서 사용하는 중요 이유는 A: 트래픽의 단절화 (독립화)로 인한 보안과 성능 향상. Q: 2.4Ghz의 무선 밴드의 채널 공간 문제와, 왜 5GHz 는 문제가 없는가 A: 다양한 채널등의 중복. 최대 3개 까지만 서로 방해없이 스페이싱이 가능하고, 5Ghz의 경우 공간이 훨 씬 넓어서 채널간의 혼잡이 존재 하지 않음 (다만 거리가 짧아서 아직 덜 쓰임) Q: 무선 Beacon 프레임의 이유는 무엇인가 A: Access Point가 SSID, channel, rates 등등을 광고하는것. 누가 있는지 듣고 있는 클라이언트에게 정보제공","link":"/2020/04/12/Network/Lab%202/"},{"title":"Monitoring/SNMP","text":"MonitoringNetwork Feedback ECN (Explicit Congestion Notification): Router set up ECN flag ICMP (Internet Control Management Protocols): ping/traceroute 등으로 사용 TCP ACK: sequence number 로 알아차리는거 SNMP Simple Network Management Protocol (SNMP)We want to…. Reach everywhere: 모든 타입, 종료의 기기들 (스위치, 라우터, ap, IoT 등등) Lightweight: 기기의 성능에 영향 가지 않도록 (no interference on device) No rates, no calculation, no history No absolute clock: 정해진 클록이 존재하지 않음 (즉 다양한 클록 스피드로 통화가능) 단지 Counters/gauage, Time since start-up, strings/identifiers 만 존재 시간은 1/100 sec 단위이다 command/control 은 변수 셋팅을 통해 이루어진다 Operate when under stress: 부하가 걸린 상태에서도 작동 가능하게 뭐가 문제인지 알아내고 고칠수 있도록 도움을 주기위해서 Scale to large num of device: 글로벌 네이밍, delegated, 제조사-독립적, 추가적 즉 누가 만들고 이런거를 떠나서 다양하게 많은 수의 기기들을 포함할수 있도록 Provide both queries/response and command/control: 질문/답변, 명령/조종 모두 가능하게 security and upgrade later 말 그대로 간단한 네트워크 조절 프로토콜로, 네트워크에 수많이 존재하는 모든 기기들 (무슨 타입 종류건 상관없이) 에 대해 문제가 생기면 고칠수 있고, 해당 기기와 교류 할 수 있는 (질문답변…) 것을 제공하는 것. 이는 곧 해당 네트워크 기기에 문제가 생기면 경로를 탐색할 필요 없이 걔만 고치면됨. 따라서 부담을 줄이기 위해 UDP 161 (서버), 162 (에이전트) 포트를 사용한다. 여기서 에이전트는 (서버) 클라이언트는 (매니저) 이다. SNMP 어플리케이션 프레임워크 네트워크 리소스의 관리 및 모니터링 담당 SNMP 구성요소로는 다음과 같다 SNMP agents: 각 기기에 존재하는 소프트웨어 설정및 데이터베이스 상태 관리 Proxies: 혹은 non-SNMP (IoT 등등 얘를 거쳐야만 그 기기랑 대화 가능) 기기와 대화 가능한 프록시 역할해주는 agent Proxy agent 와 Proxied Agent가 존재한다. SNMP managers: agent와 대화하는 어플리케이션 해당 에이전트의 데이터베이스를 쿼리 혹은 수정하는 역할 또한 네트워크 장치의 이벤트를 인식함 (에이전트가 전송함) Network management system 의 일부이다 Management Information Bases (MIB) 다양한 데이터 베이스 구조가 존재함 Structure of management Information (SMI) 는 MIB에 존재하는 관련된 오브젝트를 정의함 즉 관리 장치에 대한 정보가 집합되어 있는 데이터베이스 SNMP protocol 여러 버전 존재함 1, 2, 3 SNMP Messages SNMP/UDP is connectionless request ID 를 이용하여 세션을 유지한다 SNMP messages use “protocol data units” - PDUs 다양한 버전의 SNMP는 같은 PDU를 다른 메세지로 사용한다 (그래서 지금 문제되고 있음) 또한 각 다양한 메세지 form은 이 PDU의 전체 맥락에서 조금씩 바꿔서 사용하는것 Trap : 에이전트가 무슨일이 있다고 (이벤트) 매니저에게 알리는것 (비동기적 - 일방적으로 알리는것) 링크 다운/업, 스타트 콜드/웜 (급작스러운 재시작 혹은 예정된 재시작) 인증실패, egpNeighbourLoss (링크는 켜졌는데 이웃이 사라짐) 과 같은 6가지 기본 상태와 벤더에 따른 여러 trap 상태가 존재한다 2^32 개수까지 존재 가능 SNMP Community - 어디 소속인지 SNMP1 의 경우 특정 변수 셋트에 대해 특정한 액세스를 정의함 read-write, read only, none 등의 세가지 타입이 있음 각각의 SNMP 는 community name 이 패스워드 같고, 암호화 되어 있지 않음 이게 무슨말이냐면 read-only: Public, read-write: Private 가 비밀번호임 ㅋㅋㅋㅋ 따라서 보안적으로 하나하나 새로 설정해 주지 않으면 위가 기본 비밀번호 에이전트가 특정 IP 주소를 저장해서 해당 아이피의 매니저만 데이터베이스 건드릴수 있도록 하는것도 가능 SNMP Versions v2c 벌크 기능 추가, 매니저간 대화 기능 추가, TCP 기능 추가, 64 비트 카운터 추가 v3 보안 추가 (v2c 의 기능은 없음) 보통 다들 v1,2,3 모두 지원함 SNMP Security v1 - community string 을 인증 방법으로 이용함 (아까 그 public, private) - 암호화 전무 v2 - 위 문제 고쳤어야 하는데 안고침 ㅋㅋ v3 Integrity - 패킷이 tampered 되지 않음을 분명히 함 authentication - 정당한 소스로부터 해당 메세지가 왔음을 분명히 함 privacy - 메세지가 읽히지 않음을 분명히 함 다향한 보안 단계를 가지고 있으며, 단계에 따라 접근 권한이 다르다 noAuthNoPriv: 유저네임 매칭을 통한 인증 방법 authNoPriv: 메세지 digest를 이용한 인증 방법 authPriv: message digest 를 통한 인증과 암호화 사용 MIB 안에 값들이 저장되어 있는데, SMI 를 통해 정보가 수집된다 (통계 자료 등등) 예를 들어 값들이 어느 디렉토리 안에 저장되면, 해당 디렉토리까지 가는데 SMI 을 통해서 지나간다. 이 지나가는 와중에 해당 정보들을 structure 하게 수집해서, 몇개의 패킷이 지나갔는지, 지금 전송율이 어떤지 등등을 모집하는것이 바로 Structure for Management Information (SMI) 이다. 물론 에이전트가 직접 계산하는게 아니라, 단지 자료를 모음으로써 위의 계산들을 가능하게 해주는 형식 Counter / Gauages 위 두가지가 현재를 가장 잘 알려줌 Counter: 현 인터페이스에 존재하는 패킷들 (can wrap) Gauge: 메모리/디스크 공간 (0부터 맥시멈까지) 에이전트는, 다시 말하지만, history를 가지지 않으며 계산도 하지 않음 단지 켜진 순간부터 얼마나 시간이 지났나만 알고 있음 따라서 매니저는 계속해서 물어보면 다음과 같은 가정들을 세워야함 Counter 가 바뀌지 않았다 (패킷 수가 똑같다) → 이전과 같은 상태 Gauge가 바뀌지 않았다 → 이전과 같을수도 다를수도 있다 (메모리/디스크 소비량은 같은데 값은 바뀔수 있으니까) MIB 디자이너는 해당 정보를 위해 여러 필드/타입이 필요 할 수 있다 (즉 어느 정보를 유추하기 위해서는 여러가지 필드들을 참조해야 할 수 있다) ASN데이터들은 ASN 이라는 Abstract Syntax Notation One 규격에 따라서 저장된다 string 예시로는 Access: Read only, read-write, write-only, not-accessible Status: mandatory, current, optional, obsolete 이 존재한다 가장 중요한것은 Object Identifier 이다 정보 오브젝트와 레퍼런스를 알려주는 identifier로 international 한 수준에서 관리된다. globally unique → MIB에서 무조건 unique 함 OID (Object Identifier) 나무 계층적이다 (DNS처럼) - 각 OID 는 나무의 노드에 해당한다 1.3.6.1.2.1 의 경우 루트에서부터 각 계층의 OID를 타고 내려오는것 제조사는 각자 이 OID에 특정한 object를 만들수 있음 즉 MIB 1.3.6.1.2.1.2 의 디렉토리에 ifNumber 라는 오브젝트를 만드는것. 해당 오브젝트는 Integer를 (읽기만 가능하며) 값으로 가지며 필수적인 오브젝트. OID 의 필요성?OID 가 왜 필요하느냐 하면 gloabl uniqueness 와 extensibility를 가지고 있다 human-readable-names를 나무-위치-identifier 형식으로 가지고 있다 ASN1 은 테이블 (사람이 쉽게 읽을수 있는) 을 제공하지 않는데, 사람이 관리상 필요함 Table and GetNextGet-Next : 예를 들어 IP 관련 데이터를 받으려면, 하나 받고 그다음꺼로 계속 요청해야함 즉 같은 형식의 정보를 얻으려면 GetNext를 계속 반복해야 하는거 → 당연히 GetNext를 반복하면 트래픽도 생기고, 관리하기도 힘들다 버전2 에서 이를 위한 벌크 형식이 등장했는데 다음과 같이 작동한다 Get bulkt(“interface”) - every row every column 을 넘기는 형식 ONLY ONE UDP 로만 반응한다. 만약 이 64kb의 UDP 제한을 넘기면 tooBig 이라는 오류가 발생한다. 즉 트래픽 최소화를 위해 한 UDP로 교환이 가능하도록 만들어둔것. SNMP를 내 도메인 이후로 넓히는것은 현명하지 않은 선택이다. 에이전트들을 바깥에 보여주는것은 옳지 않으며 (보안상인듯) - 특히 보안이 약한 1,2 이로 인해 많은 트래픽이 생성되고 남들이 해당 네트워크를 쉽게 스캔, 맵핑할수 있기 때문. 이로 인해 타 도메인과의 확장은 사람간의 문제가 된다.","link":"/2020/06/20/Network/Monitoring%20and%20SNMP%20cfdc2c9571204c9cb9efd4b1b62e92c3/"},{"title":"DHCP/DNS","text":"Reference: Computer Networks, Fifth Edition by by Andrew S et al. The Australian National University CECS 어플리케이션의 디자인은 확장성, 권한, 그리고 신뢰성을 위주로 한다. 보통의 클라이언트/서버 관계부터, P2P, 그리고 Publication/Subsription 등이 존재한다. steteless network (비 안정적인) 에서 세션을 만드는데 쿠키, URL 토큰, 특정 종단과의 비디오 컨퍼런스 (줌 같이), 그리고 패킷 플로우 등을 이용한다 보통 TCP/UDP 등을 이용하여 세션이 만들어진다. 어플리케이션 계층의 경우 프레젠테이션 계층 또한 같이 관여 하는데, 컨텐츠 패키징 (파일 확장자), 타입 (이미지, 비디오, 텍스트), 인코딩, 셀렉션 (상대방이 사용 가능한걸 보내야 하니까) 종단간의 명령어와 조종을 관여한다 (나는 무엇을 원하고, 너는 무엇을 받을것이며, 나는 끝났다 와 같은 것들) 영어와 같은 프로토콜을 사용하기에 디버깅이 쉽고, 오버헤드가 타 계층에 비해 적다. 알려진 도움 프로토콜의 경우 (물론 어플리케이션이기도 하다) ARP: 2.5 layer (MAC &amp; IP) ICMP, IGMP: network control and feedback. 즉 어떻게 IP를 찾고 어떻게 주소들을 찾을것인지 등등 방법을 정하는 계층이 어플리케이션 계층이다 (DHCP, DNS) 하위 계층은 상위 계층에게 서비스를 제공하는 종속된 관계임을 잊지말자. DHCP ApplicationClient/Server 관계의 어플리케이션이다. Bootstrap Protocol 은 BOOTP로 불리며 TCP/IP 즉 트랜스포트 계층의 프로토콜로써 어플리케이션 계층에 속한다. 우리가 DHCP에서 자동으로 구성되는 기능이 이 프로토콜을 기반으로 만들어진것이다. 보통 UDP의 경우 클라이언트 포트는 68, 서버 포트는 67이며 모르면 ARQ 하면 된다. 처음으로 부팅된 기기에 IP등 구성정보를 제공한다 정적인 클라이언트 서버 형태의 구성정보 (configuration) 제공 프로토콜이다 3가지 정보를 제공하는데 IP, boot file server name, boot file name. 지금은 거의 사용안한다 DHCP의 하휘호환 버전이며 완벽하게 호환 가능하다. 요청 메세지는 브로드캐스트로 소스 주소는 0.0.0.0, 목적 주소는 브로드캐스트이다. UDP 유실에 대비해서 ARQ 와 Time out 정책을 사용한다. Discover Offer Request Ack로 4단계로 구성되어 있다. Lease Renewal 하는 것은 유니캐스트로 50, 87.5, 100% 사용시마다 요청한다. 만약 리뉴얼에 실패를 한다면 혹은 처음 할당 받았으면 gratuitous ARP를 통해 겹치는 아이피가 없는지, 그리고 자신의 새 아이피를 남들에게 알리기 위해 발송한다 이러한 일이 일어나는 이유는 DHCP가 여러개 존재 할 수 있기 떄문이다. DHCP Relays: 만약 DHCP 서버가 있고 라우터가 릴레이 역할을 할당 받으면, 라우터가 DHCP와의 연결을 단독으로 진행한다. 이로 인해 당연히 네트워크내 트래픽이 줄어들고, 해당 서버가 한 네트워크를 담당하니 깔끔하기도 하다. DHCP reservation 은 한 클라이언트가 항상 같은 아이피를 사용하기 원하는 경우 (연결 할때마다 같은 아이피 할당 받음), static은 프린터와 같이 특별한 목적으로 만들어진 경우이다 (즉 이 기기의 아이피는 변하지 않는다). 요즘 나오는 라우터들은 DHCP and DNS and router 역할을 모두 한다 보통 192.168.1.0/24 subnet을 사용함. DNS Redirection, load balance, dynamic allocation. 즉 관리 하기 쉬워야하고 (여러개의 협조로) 효율적이어야 한다 (높은 요청/답변 양으로 딜레이자 짧고 로드가 적어야 한다) 이를 위해 분산 디렉토리, 계층적 namespace (존), 자동적인 프토토콜/프로세스 을 이용한다. Service metadata Names for humans, Addresses for protcocls, and resolution for mapping between the first two. Resolution: 분명하고 깔끔하게, 보통 names to addresses 반대로도 가능하긴함 튜플 형식으로 (Names, value (addresses), type, TTL) 로 이루어져 있다. Root starts from . TLD: Top level domain ccTLD: two letter country code; jp, kr, de. It has sub domain as well; edu.au… Types: SOA: Start of authority - who is the owner A, AAAA: IPv4, IPv6 CNAME: canonical name (alias) 한 아이피 주소는 여러가지의 DN을 가질수 있다 MX: eMail exchange for domain. 같은 foo.bar여도 호스트와, 메일 주소로 쓰일수 있다. 네이버처럼 NS: Nameserver for the delegated domain. 이 도메인의 주인은 ns1.anu.edu.au 이 도메인의 메일 서버는 mail.anu… www.anu.edu.au는 gaia-proxy…. 도메인의 캐노니얼 네임 (alias임) gaia-proxy의 주소는 130… 여러개의 루트 서버가 존재하지만, 네임서버들은 보통 모든 루트 서버를 알고 있음. 이 루트서버는 보통 anycast (구독자와의 연결)로 이루어짐. 내 네임서버가 먼저 루트서버에게 물어보고 (캐쉬 없으면) 루트서버로 부터 받은 정보로 해당 서버에 물어보기 시작함 (DNS) Iterative: 내가 가야할 다음 장소가 어디니? 하고 물어보는것 높은 성능, 낮은 딜레이 Recursive: 내 목적지 장소를 니가 찾아서 알려줘. 낮은 성능, 하지만 편함. 보통 ZONE 서버들의 주소는 바뀌지 않음, 그래서 네임서버는 (처음에는 루트서버에서) 받아서 캐쉬를 함. 그러면 덜 물어보니까 네트워크 혼잡도가 줄어듬. 메세지의 경우 UDP port 53 을 이용하며 가볍다. ARQ를 사용한다. 메세지 패킷의 플래그는 메세지의 상황마다 변화며 이로 구별한다. 다른 기능들: 여러 이름이 한 아이피를 가지는 경우 (한 서버가 여러 웹서버 지원하는경우) 한 이름이 여러 아이피를 가지는 경우 (실패 혹은 부담을 줄이기 위해서) Reverse Lookup: 안전성을 확인하는 작업 (이메일 스푸핑, 사이트 확인 절차등) 질문: 이 아이피 도메인 이름이 뭐에요? 답변: 구글이요 이 작업은 PTR을 이용하며 (A 가 도메인에서 아이피 인것처럼 PTR은 반대이다) Sort-list: 답변에 우선순위를 부여할 수 있다. 즉 가까운 서버나 멀티인터페이스 서버에 유용하다 Geopolitical-sensitives - split DNS: 너가 어디서 물어보는지에 따라 결과가 달라짐 (우리나라 야동 막은것처럼) Round-Robin / Load Balancing: 리스트를 보낼때마다 다른 순서로 보냄, 즉 한 이름이 여러 아이피를 가지고 있으면 그 아이피 순서가 바뀌어져서 보내지는것 (그래야 하나만 쓰고 그러는거 방지하니까) DDNS: 보통 개인 사용자는 유동 아이피인데, DNS 주소를 새로 할당해버리면 얘랑 주고받던 메세지가 다른곳에 도착할 수 있으니, 이른 해결하기 위한 실시간 DNS 갱신 방법이다.","link":"/2020/04/26/Network/Network_DHCP%20DNS/"},{"title":"Ethernet and Wifi","text":"Reference: Computer Networks, Fifth Edition by by Andrew S et al. The Australian National University CECS IEEE 802.3 for Ethernet 1000BASE-LX: 1Gb/s Baseband Fiber Optic Pairs 1310nm over MMF (500M) or SMF (10km) 8b/10b NRZ encoding EthernetIf not all 4 pairs unused, can run power over data wires (DVD TV from textbook) Very good plug and play - well designed to cope with network changes Very good backwards compatibility - Link negotiation on connection Auto-negotiationPlugging in an Ethernet device to a switch, need to agree Speed, Duplex, and Cross-over (which wire does what) Detect a plug-in and disconnect Heartbeat = Normal Link Pulse (NLP) Capability = Fast link Pulses (FLP) - Encodes messages in 16bit words Every device can listen. If it is not for you, drop it. If it is, inform OS - Unless you are in ‘promiscuous mode’ that listens to everything. Addressing ff:ff:ff:ff:ff:ff = Broadcast Frame Ethernet HubsShared Media, CSMA and Collisions - through a hub/repeater Ethernet SwitchingMore scalable, more reliable. Listen to what’s coming and record the source MAC address If its a new mac address Send it to all ports (unicast port flooding) Hope somebody replies and then record their port Broadcasting in now switch’s resp, not the cable Hierarchy of SwitchesGood for loop-free topology. If there is a loop, it creates Redundant links, parallel links, Short cuts, mistakes, evil intent… To avoid the broadcast storm (switches trying to find a device in the network and it results in creating a loop of searching), implement spanning tree. Spanning tree is the loop free tree. Spanning Tree Protocol (STP) 802.1d,w,… Block all but STP protocol Elect a root node (lowest address wins) and at the same time Grow the shortest Tree using distance (hop count) and value (speed) from root. Tie - Lowest address wins Record the ports that are not on the tree towards the root. Initially everyone thinks they are the root - tells its neighbours —&gt; Everyone updates by competing Once converged: turn off ports (paths) that are not on the upward tree - although remember where they are for back ups Casting Broadcast: ff.ff.ff.ff.ff.ff —&gt; everyone gets it. Uni-cast: Only intended recipient should get it. Multi-cast: Everyone who is interested get it; special bit flag in MAC, or Devices can subscribe their NIC (network interface controller). Link Aggregation하나의 연결이 지탱할 수 있는 스루풋 증가와 링크 실패를 대비한 다중화 (redundancy)를 제공하기 위해 여러 네트워크를 병렬로 연결하는 방식. 링크 어그리게이션 그룹은 물리적 포트들을 하나로 병합해 고대역 데이터 경로를 만듬과 동시에 여러 포트들간의 트래픽 부하 분산을 구현하고 연결의 신뢰성을 강화한다. Single point of failure (단일 장애점) - 한곳의 실패가 네트워크 다운 시키는 현상을 막아주고, 대역폭의 한계를 하나의 논리 링크로 병합해 극복하는것. Switch vs RouterSwitch: Pros: Plug and play —&gt; good for network engineer Has relatively higher send and filtering rate of packets. (as it is 2 layer) Use Spanning tree topology to prevent broadcast storm (from loop) Cons: Has high APR traffic at large network Do not handle broadcast storm caused by one problematic host. Router: Pros: No circular loop —&gt; but only follow the routing table. Hence maintain the best route No Spanning tree —&gt; flexible topology Firewall exists —&gt; prevent broadcast storm by host. Cons: Not plug and play. Packet process time is longer. Virtual LAN가상 랜 이로 인해 트래픽 분산과 트래픽 우선 순위 설정이 가능해진다. 스위치의 불필요한 낭비, 트래픽 격리, 그리고 유저 관리에 도움을 준다 각 가상랜은 자기들만 스위치에 있는것 처럼 행동하며, 독자적인 브로드캐스트를 구성한다. 두 독자적 가상랜의 병합은 한가지 포트를 라우터에 연결후 (혹은 스위치내에 자체적으로 가지고 있기도 하다), 병합 설정해 주면된다. 이로 인해 같은 스위치 내이지만, 라우터를 통한 다른 스위치가 서로 연결된듯 구성된다. VLAN Trunking 을 이용하여 스위치 두개를 설정된 트렁킹 포트에 연결함으로 각 스위치 내의 가상랜은 서로 병합시킬 수 있다. Wifi much more challenging communication Based on CSMA/CA with optional RTS/CTS (MACA) Along with OFDM: Orthogonal Frequency Division Multiplexing MIMO: Multiple Input Multiple Output (multiple antennas, multiple paths) DSSS: Direct Sequence Spread Spectrum Related to Frequency Hopping Spread Spectiurm Codes accross a freq band (CDMA) 802.11There are two reasons 802.11 MAC protocol does not implement CD: To do CD, it requires send ane receive at the same time. Generally, 802.11 adapter receive is relatively weaker than send, making both available costs alot. Even if send and receive available, hidden terminal problem, and fading may not allow to detect properly. Address Wirelss station MAC address that receives frames. Station MAC Address that sends frames. Router Interface MAC address The router does not know the existence of address 1, the Acess Point. Connects wired lan and BSS. Ad-hoc address. Frame Cotrol has: Control Frames: Control the communication with the Access Point Management Frames: Manage the relationship with the Access Point Data Frames: Send data… Control Frames:ReliabilityDue to the high BER, has three approaches: Detect errors and drop frames (something else will take care of it – 802.3) Detect errors and fix frames at receiver (forward error correction) Detect errors and sender sends again (Automated Repeat reQuest – ARQ – 802.11) Automatic Repeat reQuest (ARQ) by AcknowledgementAutomatic repeat request For every frame I sent need ACK; if not, send again within timeout. If ACK lost —&gt; send again with a flag that it is resent frame If timeout too short —&gt; send again with a flag Stop and Wait ARQ Helps with high delays, Single bit sequence number, ACK includes the sequence num Robust, but throttles performance goes up as bandwidth*delay goes up. Stop-and-wait ARQ 802.11 Control Frames has:RTS, CTS, ACK, Request for RTS (RRTS), Data Sendinf (DS)","link":"/2020/03/12/Network/Network_Ethernet%20and%20Wifi/"},{"title":"Network - Lab 9","text":"Q: What are some the network feedback sources that help tell you when things are going badly somewhere on the network? 네트워크상에 안좋은 일이 일어나는지 어떻게 알 수 있나? 안 좋은일: 혼잡…? A: ICMP: 다양한 이유로 안 좋다는 사실만 알 수 있음; MTU가 너무 낮을수도, 높을수도 등등 IP 의 경우 신뢰성이 없으며 비연결 지향적이기에, 이를 보조하기 위해 ICMP 가 등장 ECN: 라우터가 혼잡이 생겼음을 알려줌, back off 해야 할지 알려주는 기준임 TCP Feedback (flow control) such as ACK Clock, SACK info, Jitter+latencry ACK clock - ACK 가 오는 속도가 줄어드니까 알수 있음 SACK - 놓친 패킷에 대해 ACK 가 반복되니까 손실이 발생한지 알수 있음 Jitter + latency - 패킷 별로 도착하는 시간이 (variation) 다르니까 알 수 있음 Q: Why can’t we use all that feedback to measure what is going everywhere? A: 왜냐하면 각각의 피드백은 그 path에 관한 내용인데, 이 경로가 고정된것도 아니고, 우리가 어떻게 조절할 수 있는것도 아님. TCP feedback 들 또한 전체 경로중 혼잡이 발생한거지, 특정 경로, 위치에 대한 내용을 포함하고 있지 않음 결론: 정확한 위치에 대한 피드백을 받는것도 아니며, 그 위치를 알아도 고칠수 있는 방법이 없음 Q: What problems does SNMP solve? A: 내 경로에 속하지 않은, 혹은 내 어플리케이션과 대화 하지 않는 네트워크 요소 (기기) 에 대한 상태를 확인 할 수 있게 해줌 Provides data that is standardised and that you can aggregate 이는 혼잡, 에러, 다른 문제들을 detect 할 수 있게 해준다. 특히 어느 기기가 문제를 일으키는지 모든 경로를 탐색하지 않아도 바로 알수 있음 (왜냐면 해당 기기의 상태를 확인만 하면 되니까) IP 를 통해서는 알 수 없는 기기의 상태 (온 오프), 혹은 이벤트 발생등을 알 수 있다 물론 이를 가능케 하기 위해, 해당 네트워크 요소가 SNMP agent (or server) 기능을 가져야 한다 최근까지 보안도 안 좋았음. Q: Why doesn’t it solve all those problems across the width of the Internet? A: 내부 인터넷에 대한 정보를 알려주기 싫으니까. 덕분에 내가 권한이 있는 네트워크에 대해서만 사용 가능하다. Q: Why do we want views over time and space? A: Views over Time (기간동안 살펴보는거) - 패턴 시간적으로 지켜봐야, 이 behaviour 가 정상인지 비정상인지, 혹은 우리가 보고 있지 않을때 일어났는지 알 수 있게 해줌. 혼잡이 짧은 시간동안 버스트 형태로 일어난건지, 아니면 해당 시간에 단순히 유저가 너무 많아서 expand 가 필요한건지 알려줌 즉 시간적으로 지켜봐야, 해당 행동의 정상 유무와 이를 해결하기 위한 방법을 알 수 있음 Views over Space (순간 순간 공간 (상황) 을 지켜보는거) 현 네트워크 상황의 스냅샷을 제공해주며, 이로 인해 우리가 지금 해결해야 하는 문제가 있는지 알려줌 예를 들어 어느 링크가 다운되었다 는 공간적 입장에서 현 상황이므로 해결되어야 함. Q: Why does an SNMP trap get sent, and by whom? A: agent 가 manager 에게 보내는데, 이는 어떤 중요한 이벤트가 발생 했다는것을 알리는 알림이다 매니저로부터 요청받는 보통의 쿼리/응답 메세지가 아닌 6개 이벤트 (링크 다운업 등등) 이거나 제조사가 정의해 놓은 이벤트가 발생한것. Q: What’s the point of a MIB? A: MIB 는 데이터베이스의 구조로, 다른 MIB 와 합쳐 질 수 있음 (나무 형식). 이로 SNMP agent 가 가지고 있는 데이터에 대해 모든 object는 unique 한 이름을 가질수 있다 MIB는 각각의 필드, 구조, 성격, 관계들을 정의 하며, 사람들이 읽을수 있는 설명도 포함하고 있음 Q: What is a ‘GetNext’ used for? A: Lexicographical order of OID Tree - 곱집합에 위지하는 부분 순서 즉 밑의 사진의 경우 Interface 와 ipAddress 사이의 숫자 부분을 말함. Get 요청은 SNMP에서 굉장히 구체적인 명령어로, MIB 에 존재하고 있음을 알아야 함 따라서 Get으로 비슷한 관련 데이터를 읽기 위해서는 모두 각각의 위치를 알고 있어야 함 (행열 모두). The SNMP GETNEXT operation is similar to the SNMP GET operation. The GETNEXT operation retrieves the value of the next OID in the tree. The GETNEXT operation is particularly useful for retrieving the table data and also for variables that cannot be specifically named. It is used for traversing the MIB tree.","link":"/2020/06/22/Network/Lab%209%205eaaddc5ddf14a00ac77433f761669e6/"},{"title":"LAN","text":"Reference: Computer Networks, Fifth Edition by by Andrew S et al. The Australian National University CECS Local Area Network Adiministrative Domain: as a collection of hosts and routers, and the interconnecting network managed by a single authority. Broadcast Domain: Can talk to anyone on the LAN! Design should be: Simple as possible Deliver msg from sender to receiver asap/efficiently (over a cable) LAN is hardware. Leave the difficulties to software There is: No guaranteed delivery No built in error detection and correction No specialised features (realtime, bulk-transfer) Yes to performance MultiplexingIt can be by time, space, and frequency. Everyone gets an equal share but does everyone need that much? It’s a effectively a circuit —&gt; wasting capacity. Statistical Multiplexing Demand for capacity varies with time Random access-priority across all devices Statistically don’t need the bandwidth all the time, give it a try! A communcation channel is divided into an arbitrary number of variable bitrate digital channel or data streams. The link sharing is adapted to the instantaneous traffic demands of the data streams that are transderred over each channel. Is faciliated through packet mode or packet oriented communication which is utilized by packet switch. Code Division Multiple Access (CDMA) - different amount of spreading codes or spreading factors can be assigned to diff users. Circuits : a fixed pipe only for you that tied to both endpoints - send bits whenever wants to the other end Cells : TDM - Send a specific number of bits when it is your turn to the other end Frames : Arbitrary length, targeted messages - Send a collection of bits when you want (The most common LAN approach). Frames Destination address, source address, assemblage of bits starts and stops. Need to agree how long the frame could be Need to agree how to access the network fairly Flag is needed to ensure the sync. payload has escape byte before its escape byte or flag byte ig. FABEFCDF (F is flag and E is escape) To ensure the message, it must be sent as FABEEEFCDF. Then receiver drops two Es. Media Access Control (MAC) and sharingIt Needs Address Scheme: MAC address for your network interface Identity of the interface Listen to all traffic, respond msg sent to you Access Scheme for multiple devices: Party Atmosphere : your job to listen and respond. Randomised Access (try your luck) Send data if you have If receiver does not acknowledge or you hear other sending its data, we have collision If collision then back off and try again. Simple but effective if the congestion is not high. Stat performance is 18-36% while it depends on the back-off scheme. Carrier Sense (for) Multiple Access (CSMA) - Stricter RulesIt is good for wired network Check if anyone sending (senses for carrier) if clean, send the whole frame It may cause: Delay on long cable as both may send at the same time. As bandwidth delay gets bigger, problem gets bigger. Sets upper limits on delay and minimus frame size. Need time to detect a collision Min frame time = 2* (oneway delay) CSMA/CA (collision avoidance) Listen for carrier. If clean, wait for random time (to avoid everyone wait and start at the same time.) Then send the frame CSMA/CD (collision Detection) Listen carrier. Send and listen for a collision while sending. Collision —&gt; stop immediately and jam everyone. Then back-off and retry (while everyone wait) Backing off needs some limits for how long - not too short or long Ideally 1/N (n = num of terminals) Binary Exponential Back-Off (BEB) is to estimate out the N - Count num of collision you had. First wait 0-1 second wait 0-3 Third wait 0-7 frames. WirelessWireless is harder as each node has coverage - can be part of a single network but can’t see all the nodes due to power limitation. TX (transmit) can be a million times louder than RX (Response) - Can’t listen collisions, or can’t respond quickly (wasting time). MACA (Broadcast - anyone can hear) Multiple Access, Collision Avoidance. Quick handshake before yelling Sender: Request To Send (RTS) + N bytes Receiver: Clear To Send (CTS) + N bytes Sender Transmits Any nodes heard CTS silent for N bytes Any nodes heard RTS silent for CTS. Contention Free AccessNot random, take turns Token RingPasses around the token and can send data only if u have it. Ideally aligned with physical reality. If token lost - need regenerate after agreed timeout less efficient TDM with lower loads. Great under load, but doesn’t scale well TopologiesMost wired LANs have moved away from bus topologies. Hard to scale Make cable longer Needs repeater, hub, bridge (which links two smaller LANs and learns addresses on each side.) Nearly all moved to Switch Crossbar devices that learn source/destination addresses from the traffic Makes every link point to point Great in scalability and performance","link":"/2020/03/11/Network/Network_LAN/"},{"title":"Physical Layer","text":"푸리에 식의 각각의 구성 성분이 같은 값으로 줄어들면, 진폭은 줄어들지 언정 왜곡되지 않는다 (직사각형 깔끔한 모양) 하지만 모든 전송 설비는 각 구성 성분값을 다르게 변화 시키므로, 왜곡이 유발된다. 보통의 와이어들은 0부터 어느정도의 구역까지는 왜곡되지 않음. 강하게 왜곡 돼지 않고 전송된 주파수 대역을 대역폭이라고 하는데 보통 0에서 수신전력의 절반까지의 주파수를 말한다. 대역폭은 구성, 두께 및 길이의 의존하는 전송 매체의 물리적 특성 The bandwidth is the width of the band of frequencien thar are passed. The information that can be carried is depending on the width. Baseband : 0 to max freq Passband : Signals shifted to occupy a higher range of freq for wireless communication. Purpose of Physical layer : send bits to the other system. Magnetic Media: Use portable device like CD. The cost and bandwidth are faster/cheaper than any network. However, delay isn’t good (as it cannot be the live communication). Twisted Pair: It is twisted to avoid constituting antenna (twisted cancel the waves hence lose less wire). Signal is carried by the diff between the two wires. Telephone: need repeater if the distance longer than few kilometers. Transmitting information: several mb/s for a few kilo. Adequate performance and cheap cost ⇒ will be used ** Different LAN protocol use the twisted pair differently. Full-duplex : in both direction at the same time. Half-duplex : one direction at once - can change the direction. Simpelx : only one way traffic. ** cat 5: LAN, cat 6: UTP, cat 7: STP Coaxial Cable: better than UTP in shielding and greater bandwidth ⇒ longer distances at higher speed. Construction and shielding ⇒ high bandwidth and excellent noise immunity. Was widely used for phone cable which now replaced by fiber optics for long routes. Power Lines - data signal is superimposed on the low freq power signal (the high frequency works as the normal power line). Fiber Optics - costs expensive and costs more energy to send bits. FTTH (Fiber to the Home). Light Source Transmission Medium Detector The light is refracted (bounced within the cable) while maintaining certian angle. Hence, propagate for many kilometers without any loss. Multimode fiber: multiple rays within the line. Singlemode fiber: one straight ray due to the small diameter of the cable (100 Gbps for 100 km).Transmission of Light-Fiber Chromatic Dispersion (length of the wave gets longer) - 겹치지 않기 위해서는 서로간의 거리를 늘려야 하나, 속도를 줄이는 방법만 가능. Soliton 이라는 특수 형태의 펄스를 만들어 분산 효과를 상새하는 방법을 사용중. Fiber Cable - core is surrounded by glass cladding to maintain the light. Plugged into fiber socket: Lose about 10~20% but easy to reconfigure. Spliced mechanically: carefully cut two ends and connect with special sleeve; lose 10% Fused (melted) to form one: small amount of attenuation (손실) occurs. Comparison of Fiber Optics and Copper WireFiber 1.Can handle higher bandwidth ⇒ can be used in high-end network. 2.Low attenuation ⇒ need of repeater every 50km (copper: 5km) → save costs 3.Not interfered by power surge, electromagnetic interference, or power failures → good for harsh env. 4.Thin and lightweight → phone companies like it. Good replacement for copper and they can resale copper and also cheaper to installation and maintain cost. 5.Do not leak and are difficult to tap - good security. 친숙치 않은 기술, 휘어지면 쉽게 손상 가능, 본질적으로 단방향이므로 2개의 섬유 또는 2개의 주파수 필요. 전기 인터페이스보다 비쌈. Week 2/2 - Wirelsee Communication. The Electromagnetic Spectrum - wave caused by movement of electron. The num of oscillations per second = Frequency in unit of Hz. Wavelength : distance between cosecutive maxima/minima. apprpriate antenna size - electromagnetic waves can be broadcast efficiently. In a vaccum - all elecmagnetic travel at the same speed (speed of light). → copper : 2/3 of this speed. Mostly use narrow frequency band - concentrate signals to use the spectrum efficient and to obtaion reasonable data rate with enough power.","link":"/2020/03/08/Network/Network_Physical%20Layer/"},{"title":"Network Security","text":"Security? 뭐가 위험한가, 공격자가 어떠한 능력을 가졌는가, 비용과 임팩트, 그리고 확률은 어떻게 되는가 리스크를 알기 위한 모든 도움과, 이 리스크를 피하기 위한 모든 노력들이 필요함 다양한 공격 방법들이 존재한다 eavesdropping : 메세지 중간에 가로채서, 안에 내용 파악하는거 (passive) Intrusion: 기기를 공격해서 메세지를 변질 시킴 (active) Impersonation: identity fraud, 컨텐츠 파악, 내용물 면질 (active) Extortion: 서비스 방해 (active) Vulnerabilities 공격 surface: 얼마나 많은 부분이 공격 가능한가, 이를 어떻게 아는가? single point of failure: 한 기기를 통해 공격 가능한가? 라우터, 서버, 디렉토리, 데이터베이스, 파일 등 한가지 point로 날 공격 가능한지 결국 보안은 리스크 매니지먼트와 같은것 절대 완벽할 수 없고 (왜냐면 부족함을 증명하기 쉽지 않음) 단지 확률을 줄이기 위해 보안 모델을 확실히 할뿐 또한 보안은 가장 약한 링크만큼만 안전하다 (걔가 뚤리면 그냥 그만큼 안전한거) 여러가지 flaws들이 존재하는데 Design Flaws: Law of unintended consequences (multi-component system) 의도하지 않은 결과: “이러면 안되는데…?” 왜냐면 인터넷은 여러가지 시스템이 존재함 Code Flaws: 항상 버그는 존재하지 Somebody’s flaws: 사람이 (의도하던 아니던) 문제를 일으킬수도 있고 다른 이유도…. Wifi Old WEP cryptography - easy to snoop and decrypt 64, 128 비트를 사용해서 키 값이 일정해서 보안에 취약함 802.11I came out to fix old WEP Impossible to brute-force decrypt Removed one threat but 예상 가능한 SSID/Key - get attacker on the WLAN 패스워드 예상 가능 wired LAN access to devices on WLAN - get attacker on the LAN/WLAN 해당 인터넷에 접근 가능한 기기에 선 꽂으면…. 네트워크 디바이스 (access point)에 대한 물리적 접근 - AP boards 에 chip 설치 등등 해당 인터넷에 접근 가능한 기기를 하드웨어적으로 바꾸는거 즉 하고자 하는 말은 우리가 아무리 무선을 암호화 해봐야, 해당 네트워크에 접근 하는 방법은 여전히 존재함 안일한 인터넷 디자인 (어플리케이션 계층 위주) 수년에 걸쳐 보안이 추가되었음 처음 프로토콜들은 조그맣고, 서로 친밀한 커뮤니티 사이에서 쓰이도록 먼저 만들어졌었음 DNS, DHCP, HTTP 모두 요청하면 들어줬음 즉 클라이언트와 서버가 서로 미리 알고 있던 관계였음 메일이 친한 대학간에만 사용되었던것 처럼 초기 디자인은 이로 인하여 네트워크가 전달하는 내용에 대한 중요도를 고려하지 않았음 서로 아는 사이인데 무슨 보안이야 (인터넷으로 대화하는거 자체가 신선했던 시기) 따라서 이후 보안을 추가하기 위해 굉장한 노력들이 필요해짐 아예 처음부터 보안을 위해 다시 디자인을 하던가 아니면 보안을 위해 다른 메커니즘을 추가하던가 아이피 패킷 (네트워크 계층) 종단간의 메세지 전달을 위해 다양한 방법, 경로를 통해 전달된다 헤더, 그리고 페이로드 또한 믿지 말아야 한다. 기본 가정들 누군가는 항상 나쁜 목적을 가지고 있다 모든 물리적 링크들은 여러가지 방법으로 방해될 수 있다 (스누핑, 미스다이렉트, 컷,등등) 프로토콜 디자인은 공공적이며 많은 헛점을 가지고 있다 와이어에 대한 보안은, 호스트에 대한 보안으로부터 뚫릴수 있다 기술은 해킹하기 쉽지만, 사람은 더 쉽다. 암호화는 다음과 같은 사항을 고려한다 고려해야할 데이터의 상태는 In motion: 움직이는 데이터의 보안 (네트워크 통과하는 중) At rest: 저장되어 있는 데이터의 보안 (어플리케이션, 보관소) 반드시 eavesdropping 을 위해서만을 위한것이 아니다 (confidentiality/privacy) 다음과 같은 사항을 체크하기도 한다 기다리던 기기로부터 도착했는지 (인증) 기다리던 원격 파티로부터 도착한게 맞는지 (인증) 해당 메세지가 정확하게 맞는지 (체크섬) - integrity 해당 메세지가 전에 보내졌지 않은지 (중복인지?) - 이거 안하면 replay 공격 당함 암호화 방식 Shared Secret: Both has the same key 양쪽 모두 같은 알고리즘을 사용하며, 공격자가 이 알고리즘을 알고 있다고 가정하는게 좋다 따라서 한 키를 공유하는것은 약점에 속한다 Public Key: Key pair - public/private 오너가 private key를 가지고, 아무나 public key를 사용할 수 있음 RSA 같이 복잡하고 비싼 (계산적으로) 암호화 형식을 사용한다 Public key Infrastructure (PKI)를 사용한다. 위와 같은 trade off를 좋게 이용하기 위해 public key를 이용하여 shared key를 보낸다 - private key를 가진 소유자만 decrypt 할 수 있으니까 shared key를 이용하여 추후 커뮤니케이션을 암호화 한다 (기밀성 보장) 이 shared key = session key이다 짧은 기간동안 매 패킷에 사용된다 크기도 상관이 없다 (키 숫자 말하는듯) 빠르게 키를 바꿀수도 있다. 즉 “야 나랑 이야기 하려면 이 shared key 통해서 암호화 해서 보내” 위에서 말했는 shared key가 계산적으로 싸고 빠르기 때문에, 이 shared key를 안전하게 보내는 비싼 계산 방법인 public private 은 처음에만 쓰는거. 세션 키 Authentication and IntegrityAuthentication : 해당 사람에게서부터 해당 인원에게 도착한건지 (인증) Integrity: 해당 메세지가 변질되지 않았는지 (무결성) Confidentiality 는 수동적인 빌런들에게 굉장히 효과적이다 수동적인 빌런들은 패킷을 읽지 못하며, 자원들을 autheticate 할 수 있어서 안전 능동적인 빌런들은 메세지가 전달되는 과정을 노릴수 있다 (intruder) 이로 인해 잘못되고, 오해되고, 혹은 고장난 메세지가 전달 될 수 있다 corrupt, replay, reorder packets. WAIT DO NOT STOP —&gt; STOP DO NOT WAIT 과 같이 말이다 이로 인해 message integrity가 필요한것 세션 키를 사용한다 (PKI를 통해 세션키를 생성) 메세지의 서머리를 계산한다 (시그네쳐, message digest, hash…) 서머리를 세션키/개인키 를 이용하여 암호화 한다. FreshnessReplay attack: 공격자가 해당 메세지를 가지고 계속해서 보내는식의 공격이 가능하다 예를 들어 A로 100불 보내기 를 여러번 보내는등 물론 이 공격은 timestamp를 메세지나, 시그네쳐에 적어두면 무력화 시킬수 있다 (물론 암호화 시켜야함) 암호화 사용하기 각 어플리케이션은 이제 스스로 다음과 같은 사항을 프로토콜에 적용할 수 있다 confidentiality authetication integrity freshness 물론 우리는 개발자, 언어, 운영체제들을 믿지 않음으로 네트워크에도 적용한다 네트워크 보안SSL - Secure Socket LayerHTTP의 보안을 위해 만들어짐 → HTTPs 또한 Transport Layer Security (TLS) 를 generalize 하는데 공헌도 함. → Between transport and application layer: encrypts TCP payloads SSL/TSL (TSL is SSL 3rd version edited one) provides 클라이언트에 의한 서버 확인 절차 메세지 교환 (기밀성, 무결성, 인증, freshness) 인증 phase로 시작한다 암호화된 채널과 세션키를 생성하기 위해 인증부터 시작 그 전까지는 어느 한 메세지도 교환되지 않는다 클라이언트는 새로운 (랜덤한) 서버를 인증해야 한다 네트워크 트래픽이 spoof and misdirected 될 수 있기때문 서버 public key, 그리고 인증된 CA 가 필요하다 이 밑의 SSL의 간단한 순서를 보면 알 수 있다. Handshake - 처음 세번은 TCP와 같이 똑같이 핸드셰이크를 한다 (세션 빌드) 헬로 메세지를 보내고 상대방은 공개키와 인증서 (CA)를 보내온다 따라서 우리는 상대방이 올바른 사람이라는것을 알수 있다 master secret key (MS)를 생성후 받은 공개키를 이용해서 상대방에게 보낸다 상대방은 자신의 private key를 이용해 decrypt 한다 — 이제 양쪽 모두 MS를 가지고 있다 —&gt; 모든 암호화와 데이터 무결성 검사를 위한 대칭 세션키로 사용된다. 물론 한가지만을 이용하면 위험하니, 특별한 방법을 거쳐서 암호화 키, 세션 MAC (무결성 검사) 키를 두개씩 총 네가지를 만들어낸다 —&gt; 총 네가지의 세션키를 공유하고 있는것. Public Key Infrastructures 인증서 발급, 인증서 관리 인증서 배포, 인증서 사용 인증서 저장, 인증서 취소 CA = Certification Authority RA = Registration Authority VA = Validation Authority 단 한가지 Certificate Authority는 당연히 너무 많은 유저 (네트워크) 를 상대하기 쉽지 않으며 한번 실패하면 큰일나며 타겟 되기가 너무 쉽고 만약 이 authority가 corrupt 해서 독주체제로 가면 믿을수 없어짐 따라서 이를 방지하기 위해 레벨별 다양한 CA를 가진다 크롬의 경우 70여가지의 CA 를 가지고 있으며 SSL/TLS initiation 의 server CA 또한 다양하게 확인한다. 물론 이러한 인증 절차는 상대방이 해킹을 당했으면 다 쓸모 없음 (이미 해킹해서 다 아니까) private key 가 이미 해커에게 털렸고 Certificate 은 반려가 되어야 한다 (털렸으니) 이러한 상황을 위해 PKI는 Certifacite Revocation List (CRL) 을 소지하고 있으나, 이런 일은 자주 일어나지 않음 또한 DNS 는 UDP base 임에 따라 spoofing 이 쉽다. DNS Poison (pharming)DNS의 경우 Nameserver가 해당 도메인에 대해 아이피 주소를 물어보는 형식임 또한 DNS는 단 세가지만을 체크하는데, 알려진 서버로부터 온 응답인가 아이디가 동일 한가 현재 물어본 쿼리에 대해 해결책을 제시하는가? 따라서 이 안의 내용에 대해서는 전혀 관여를 안한다. 즉 위 세가지 방식을 만족한다면, 잘못된 주소를 알려줘서 유저가 감염된 사이트로 방문하게 만들수 있는것. 이 응답은 여러곳에서 오는데, 제일 먼저 오는것만 채택하고 후의 것들은 무시한다. 따라서 해커의 응답이 제대로된 서버의 응답보다 먼저 도착 한다면, 제대로된 서버 응답의 경우 무시되는것. DNS 보안은 기밀성에 대한것이 아닌 integrity and authentication 에 중점 (위 해킹이 authentication의 부족에서 온것을 기억하자) 내용의 기밀성은 상관이 없다. 맞기만 하면됨. DNSSEC: RRSIG - 도메인 레코드 셋 (배운 A, AAAA, MX 등등)에 대한 디지털 서명 즉 이 데이터 셋은 이 디지털 서명에 의해 보장됩니다! 이런거 DNSKEY - RRSIG를 위한 public key (Zone Signing Key (ZSK) and key signing key (KSK) KSK &gt;&gt; ZSK 인데 이는 네임서버의 키-체크 부담을 줄여주기 위해서이다. KSK, ZSK 둘중 하나를 사용한다. Zone 의 공개키로 사용된다. ZSK : Zone 의 모든 RR 서명에 사용되며, 암호화 비트와 기간을 짧게 사용 KSK: ZSK를 서명하기 위해 사용한다. Zone의 Security entry point 로 사용됨 (암호화 비트와 기간을 길게 사용한다) DS (Delegation server key) - public key for delegated zones 부모 자식간에 인증 사슬을 형성하며, KSK를 사용하여 신뢰사슬을 만들어 부모 zone 에 제출 다음과 같은 사항들을 필요로 한다 암호화 오버헤드 감소 DNS는 매우 유명한 프로토콜이며 항상 사용되기 때문에 딜레이를 최소화 해야함 또한 다른 암호화 기술이 사용될수 있도록 해야함 (개방적) 다른 Resource Record (RR) - NSEC (next secure record) DNSSEC의 일환으로, 해당 레코드가 non-existence 한지를 체크하기 위해서 사용된다 (즉 해당 레코드의 존재 확인을 위해 존이나, 타입 리스트에 대한 링크를 가지고 있는것) 부정적 대답에 사용된다. 즉, 네임이 존재하는지에 대한 증명에 사용된다. 실제로 질의한 도메인이 존재하지 않는 도메인이거나 레코드가 존재하지 않는 경우 zone내에 각 도메인들을 sorting하고 그 순서에 맞는 domain을 NSEC으로 응답 NSEC3는 Return되는 도메인을 Hash 함수처리 이는 zone information을 유출한다. DNSSEC 이 반영된 DNS 절차 똑같이 네임서버에 대해 쿼리 하는것으로 시작한다 온 답변들을 인증을 이용하여 validate 한다 Top to Bottom 형식이며 PKI chain of trust 이다 또한 사실상 root 는 검증하기 불가능하므로, 검증되었다고 가정하고 질의를 시작한다 이를 anchor on root public key 라고 말한다. root 공개키를 가정 (anchor) 해서 시작하니까 각 도메인을 타고 내려가며 각 도메인또한 관련 키를 사용하여 검증한다. 모든 DNS 들이 사용하지는 않는다 → 늘어가는 추세이나 아직 100프로 아님 SSL/TSL 은 어플리케이션과 네트워크 계층 사이의 보안을 보통 담당하는데… 마찬가지로 여러번 이미 뚫렸음 코드, 암호, 혹은 프로토콜간의 접촉 등등 여러 이유로 모든 어플리케이션이나 다른 계층들이 모두 사용하는것도 아님 Firewall패킷들을 막아내는 edge (보더) 라우터, 게이트웨이, 프로세서들 Middlebox 라우터는 보통 IP만 검사하지만, middle box역할도 겸하고 있다. Packet Filter 는 다양한 방식의 정책으로 가능하다. 또한 각 패킷당 개별적인 검사를 시행한다 (stateless) 이는 연결에 대한 state가 아닌 각 패킷은 항상 검사 된다는것 IP주소 기반 UDP/TCP, ICMP, OSPF … 등등 프로토콜 기반 포트 넘버 기반 TCP flag bits, ICMP message type 등등 Stateful packet filter:state는 패킷이 아닌 연결에 대한것을 상기한다 (연결이 안에서 밖으로 시작되어야함) ⇒ 그래서 reverse_https 같은 기법들이 존재하는거. 패킷 플로우를 내/외부 차이점을 기준으로 검사하는 방법 예를 들어 NAT의 경우: 내부에 있는 Y가 시작하여 만들어진 TCP 연결에 대해 외부의 X가 Y에 대해 패킷을 보내는것을 허용 즉 TCP연결은 안에서 밖으로만 initiate가 가능하고, 바깥에서 안으로 들어올때는 해당 테이블을 보고 연결 검사를 진행해야 한다. 안에서 밖으로 연결 시행이 가능하기에 모든 연결은 테이블에 기록이 가능하다. Application Firewall - Deep Packet Inspection 어플리케이션 프로토콜을 이해함 메세지를 확인후 다시 재조립하여 해당 목적지로 보내줌 컨텐츠를 이해한다 (즉 이메일, 웹페이지 바이러스 검사가 여기서 이루어지는것) 물론 해당 패킷을 열어보고 검사후 버리기때문에 (여태는 걍 버렸음) 퍼포먼스 하락이 이루어짐 왜 가능하냐면, 메세지 자체는 이미 최종 목적지, 어플리케이션에 도착해서 다 풀린 상태임. 이 방화벽이 하는 역할은 이 decrypt 되어서 우리한테 최종 전달되기 직전에 검사를 하는것. 또한 기기마다 중요도가 다르기 때문에 여러 단계로 나누어서 다른 레벨의 방화벽 설정도 가능하다. 방화벽 간의 사이를 DMZ라고 부른다 Firewall Implementation - 설정 방법 허용된 기기들 : 특히 어플리케이션/DPI 방화벽 라우터/ 모뎀 Wireless access points OS based hosts - 리눅스 아이피테이블 (리눅스 기반 아이피 테이블) 패킷 필터 여러 방화벽을 사용할 경우 당연히 더 많이 신경써야 하고 느려지지만, 내부의 공격도 막을수 있으니 장단점이 존재 Firewalls = Islands of trust SSL 은 모든것을 숨기지 않는다 중간 라우터들은 트래픽을 볼 수 있음 (활동에 대한 정보가 새는것) Leased Lines (내 개인망) - 이러면 트래픽을 숨길수 있음 효과적이지만, 돈도 들고 (즉 크게 못함), 해당 라우팅에 대한 설정도 따로 필요함 따라서 SSL의 단점과 Leased lines의 단점, 즉 트래픽의 노출과 비용부담을 모두 보완하기 위해 아이피 (네트워크) 레벨에 보안을 적용해서 virtual leased line 을 만든다 ⇒ Virtual Private Network Islands of trust - VPNs사설망 (LAN) 처럼 공용 인터넷 망을 사용하는것. 하지만 ISP를 사용하되 이 ISP가 보지 못하도록 따로 암호화 기법과 해당 라우터안의 체계나 기법등을 비공개 하는것. VPN은 그냥 각 컴퓨터나, 라우터가 IP 데이터그램을 암호화 시켜서 보내는거. 이 VPN으로 이루어진 암호화가 진행되는 기간이 터널링이다. https://travelerstory.tistory.com/91#:~:text=IPSEC(Internet Protocol Security)은,된 인터넷 보안 표준입니다. ModesTunnel (=encapsulation) IP packets across the internet (IP in IP) 물론 단순한 터널링은 아무런 보호성도 가지고 있지 않음, 그냥 헤더만 하나더 붙임 No confidentiality, authentication, integrity IP Security 을 이용해서 VPN connection 을 secure 하게 establishment 하는것 네트워크 레벨에서의 암호화 종단간의 (호스트, 라우터) 키 공유 패킷의 캡슐화및 보호화 VPN Endpoints 는 위에서 말했든 호스트, 라우터 두개의 종단간에 가능하다 Tunnel Mode: Router and Router (with forwarding) 모든 서브넷을 투명하게 연결시킴 (하나처럼 보이게 터널로) 라우터간 연결되었으니 서브넷 두개가 하나처럼 보이는것. NAT friendly (라우터가 관리 터널끝이니까, 요즘 NAT은 라우터에 같이 있음) New IP header는 라우터의 주소이다 - 종단 라우터에 도착하면 (터널끝), 패킷 풀어서 해당 기기에 보내주는것 (즉 터널 밖으로 나오지 않는 이상 어디로 가는지 모름) Transport Mode: Host and Host (no forwarding) 다른 포맷으로 오직 IP payload만 암호화 한다 (라우터 합침을 통한 서브넷간의 통합이 아닌 두 호스트간의 LAN 같이 사용하는거) 이로 인해 트래픽이 어디서 어디로 가는지 경로가 유출됨 (최종 목족지) 문제는 해당 아이피가 NAT 에서 사용되는 경우 사실과 다를수 있기 때문에, 이를 위한 PSK를 통한 인증이 필요하다. 그렇기 떄문에 NAT challenge 내가 헷갈려한 것은, VPN 서버를 이용할 경우 (나라 장벽떄문에) 이게 어떻게 진행되냐는건데, VPN을 통해 나라 장벽을 우회하려면, 해당 VPN 서버에 대해 터널 모드를 만들어서, VPN 서버에 도착하면 내 원래 목적지 주소를 알려주고 거기에서 다시 목적지로 향하는것 (해당 VPN 서버에서는 무슨 모드이건 그건 이제 선택사항임). 장벽 우회같은 이유가 아니면, 그냥 공공망 바로 터널이던 전송이던 알아서 쓰면됨. AH 는 기밀성을 보장하지 않음, ESP는 다 보장함. ESP(Encapsulating Security Payload)새로운 데이터 IP Packet을 만들고 기존 IP Packet을 Data Payload에 넣어 감싸는 방식 AH (인증) 가 가진 무결성과, 인증도 제공하고 추가적으로 대칭키 암호화 (PSK) 를 통해 기밀성(Confidentiality) 제공 Tunnel Mode즉 위의 터널 모드는 애초의 목적지인 IP header 까지 암호화 시키니, 미아가 되지 않도록 터널링을 담당하는 장비 (라우터) 의 아이피를 적어서 보낸다. 즉 라우터간 (터널) 동안에 기밀성이 보장된다 (물론 이 라우터로 가고 있다는 트래픽 경로의 경우 유출이 되니 - 어느정도의 기밀성이 보장된다 가 알맞다). 따라서 해킹을 위해서는 A, B 혹은 라우터 장비의 물리적 회선망 (A나 B로 향하는)에서나 가능하다. 터널내에서는 esp가 존재하므로 암호화에 따라 해킹이 매우 힘들다 Transport Mode만약 해당 네트워크가 NAT를 이용하면, 수신자 측에서 검증시 인증에 실패 할 수 있기에, PSK를 사용하여 서로 인증을 해야함 (그래서 NAT Challenge ) 또한 전송 모드는 단대단 간의 연결 (TCP 처럼) 을 보호해주기에 Transport layer의 보안으로도 사용될수 있다. 터널 모드와 다르게 전송 모드는 패킷 페이로드만 보호해주며, 이로인해 경로 유출이 일어난다. 아까 위에서 말한 헷갈린점은 VPN 사설 서버를 이용하는 경우에 터널 모드를 사용하니 결국 어디로 가는지 모름 공용망 시점에선. VPN 주의점 이 종단 라우터 또한 반드시 해당 기기에 가장 가까운 라우터라는 법은 없음. 단지 그냥 터널링을 끝내는 라우터에 불과함 (즉 해당 라우터에서 해당 기기까지 가는데 다른 라우터를 지나갈수 있음) 따라서 end-point에서부터는 누가 누구에게 이야기 하는지 알수 있음 보통 아이피는 위치에 따라 지정된다 결국 터널링이 끝나는 순간 보호되지 않은 트래픽이 된다 → 여전히 보안의 위험성 존재 따라서 이러한 상황을 더 나아지게 하기 위해 더 많은 터널링을 하는식으로 보완한다. Onion routing = onion encryption 랜덤하게 세가지 노드를 선택한다 - 가드/미들/출구 클라이언트는 해당 세가지 노드에 대한 public keys를 가지고 각각에 대해 세션키를 만든다. 클라이언트를 각각의 세션키를 이용해 모든 패킷들을 암호화 한다 + 서버가 필요한것 포함 물론 이 방식은 세가지의 중간 노드만 정확히 지정해 둔거고, 이 노드를 방문하는 라우팅 알고리즘은 공용망에 맡긴다 (알아서 데려가줄텐데, 이 세 가드 미들 출구만 정확히 지나가면됨) 따라서 이는 MPLS (multi protocol label switching) 과는 다음과 같은 이유로 다르다 MPLS는 미리 모든 경로를 지정해둠 (onion 의 경우 세개만 지정) 패킷들은 토큰으로 레이블되어 있음 (onion은 세션키로) 경로중 하나만 죽어도 다 실패함 (onion은 맨끝만 죽으면 실패한다 - 주는사람 or 받는사람) Physical SecurityDevice Security 스위치와 라우터는 물리적이고 가상적인 인터페이스를 가지고 있음 원격 엑세스 SNMP agents (HTTP) OS (Telnet ssh) Port monitors and mirrors 다른 포트에 대한 트래픽을 반영하며, 바깥에서는 알수 없는 정보 물리적 엑세스 인터페이스 재정렬 (denial) 혹은 공격 케이블 절단, 방해 칩 레벨 스누핑 Copper Security여기서 말하는 보안은 이를 이용한 데이터 보안이 아닌, 말 그대로 코퍼에 대한 보안임 attenuation등이 원래 발생하는 라인이기에, 문제가 생겼는지 발견하기가 쉽지 않음 자르기도 편하며, 누군가 케이블 자체를 (라인이던 쉴드던) 건드리면 denial of service (noise, antenna, energy loss) 등이 발생함 Fiber Security코퍼에 비해서는 발견하기가 쉬운데 케이블 특성상 loss 가 발생하기 어렵기 때문 물론 선 절단이던 tapping (금가거나 등등) 은 코퍼와 마찬가지로 쉽게 발생한다. 그래서 NSA에서 해저 밑바닥에 깔아둠. Wireless Security 무선은 특성상 브로드케스트 이기때문에 좁은 beam 안테나와 짧은 wavelength 가 도움이 된다 빌런들이 듣고있으며, 적극적으로 intrude 할 수 있음 물론 access 에 관한 말이고, 해당 패킷이 암호화가 잘 되어있는거는 다른 이야기 802.11기기와 wifi 사이 (무선연결) 의 payload에 대한 암호화를 책임지고, 해당 데이터가 와이파이 라우터에 성공적으로 전달되면, 해당 암호화를 풀고 선 (물리적)을 이용해서 목적지로 전달한다 즉 무선 기기간의 암호를 책임지는 프로토콜임 Wifi Network KeysLayer 2 클라이언트가 AP에게 인증한다 클라이언트가 AP에게 요청하면 AP가 수락하고, 등록후에 더 많은 키를 나누어준다 각각 SSID password (pre shared key -PSK)로 부터 얻은 공유 세션키를 계산한다. 이 공유 세션키를 이용해서 PMK, GMK 를 생성하고 이 마스터 키들이 이후의 PTK, GTK 유도하기 위해 사용되는 보조키 역할을 한다. 여기서 만들어진 Pairwise Transient Key (PTK) 를 무선구간 암호화를 위해 사용한다 AP to Clients (broadcast/multicast) Group Temporal Key 를 이용하는데 마찬가지로 무선구간 암호화를 위해 사용한다. PTK와 다르게 브로드캐스트, 멀티캐스트용이다. 123456789구분 - 4-Way Handshake . Pairwise Key,Group Key 생성을 위함 - Group Key Handshake . 이전에 4-Way Handshake을 통해서, PTK 및 GTK를 확보한 STA에게, Multicast/Broadcast용 데이터 암호화를 위한 GTK를 분배하기 위한 2-Way Handshake 임 . 사실상, 위 4-Way Handshake에서 끝에 있는 2번의 메세지 교환 단계와 동일함 - PeerKey Handshake - TDLS PeerKey Handshake 원래는 Station - AP - Authentication server 로 이루어져야 한다. AP 가 클라이언트에게 제공 가능한 서비스들을 알려줌 먼저 서로 인증을 위해 EAP 를 이용해서 메세지를 전달한다. 클라이언트와 무선은 EAPOL을 통하고, 무선과 인증서버는 RADIUS라는 프로토콜을 이용해 인증한다. 이 과정중 마스터 세션 키를 생성한다 마스터 세션키는 클라이언트와 인증 서버만 가지고 있는데, 이를 이용하여 PMK를 만들고, 인증서버가 이를 AP 에게 보낸다. PMK를 이용하여 PTK를 생성한다. 802.11i [정보통신기술용어해설] Wifi EncryptionWEP: 64 bit, 128bit 등을 이용해서 암호화키를 생성해 보안을 유지하지만, 이 키값이 일정한 값을 유지해서 취약점이 노출되었음 WPA: Use of PSK (password) 더 나은 integrity 체크가 가능함 Temporal Key Integrity Protocol (TKIP) - 프레임별 키 WPS로 인해 뚫릴수 있음 Denial of Service Ping of death (3) Large ICMP packet, multiple fragments, modified headers. 메모리 오버 플로우 일으킬 수 있음 호스트에 대한 직접적 공격 SYN Flood (4) 서버에 TCP 연결 생성하고 해당 SYN/ACK 를 따르지 않고 마구잡이로 보냄 이로 인해 서버는 connection state를 유지해야함 (왜냐면 얘가 뭔지 모르니까 각각 하나씩 생성) 이 방식은 SYN 쿠키를 사용하면 피할수 있음 (즉 커넥션을 ACK이루어진 이후에만 생성하는것) Application layer messages: 복잡한 쿼리들 (complex regex or big database queries) 보내기 메모리 오버플로우 다른 버그들 Spoofing 다른 컴퓨터를 이용해서 공격하는 방법 예를 들어 공격자가, 나는 A이고 B야 메세지를 보내줘 하고 B에게 보내면 B는 A에게 메세지를 보내는 방식 Ingress filtering 은 중간에 이 공격자가 A인지 확인하는 절차를 넣는것이다. 물론 소스는 확인 불가능하고, 단지 해당 네트워크에서 보내진것인지 확인하는것 즉 내가 A (네트워크 1) 라고 주장하면서 해당 아이피가 네크워크2에서 오면?? 근데 아직 대중화는 안됨 Host multipliers: Zombie host 같은거 Packet multipliers: Small requests, big responses DNS: “I want the entire list of this” - 리스트 크기가 큼 HTTP/FTP/NFS… : “Send me 10GB file” Memcache servers: Database accelerators over UDP SMURF: 브로드캐스트 주소를 핑함 목표물의 아이피 주소를 자원으로 삼음 (spoof) 모든 사람들이 해당 아이피에 답변을 함 (many packets are back) 물론 이 방식은 prevent 하기 쉬움 Mitigation - DoS 피하는 방법 (매우 어려움) Content Distribution Networks : Dont be a single target Edge Routers/Attacker Detection: 효율적인 패킷 드롭, 좋은 필터링 셋팅 (한명이 담당/ 공격감지) Upstream provider support: 다른 방향으로 돌려버리기 (re-route) Ingress Filtering: 네트워크 레벨 확인 절차","link":"/2020/06/20/Network/Security%2093e2f37c02fb467cb265b5700879f36f/"},{"title":"Realtime","text":"Reference: Computer Networks, Fifth Edition by by Andrew S et al. The Australian National University CECS Real-time? 한 패킷 손실을 어느정도 감당할 수 있는가 한 지연된 패킷을 어느정도 감당할 수 있는가 한 지연을 얼마나 알아차릴 수 있는가 비디오컨퍼런스와 스트리밍, 비디오와 오디오의 싱크 TCP를 Contend Delivery Network (CDN)을 이용하여 스트리밍 이로 인해 지연의 심각성을 낮추고, 신뢰성을 얻을 수 있다. (빠르게, 그리고 확실하게 스트리밍) CDN은 ISP와 User 사이에 있으며, ISP에 서비스 비용을 지불하고, 유저로 부터 비용을 받는다. CDN은 유저의 트래픽을 받아서 저장하고, 시청자에게 같은 데이터를 보냄으로써, 유저의 부담을 덜하며, 다수의 유저에게 같은 데이터를 보내준다. 즉 트위치, 아프리카등의 플랫폼은 CDN을 이용한다고 봐야한다. UDP for two way (interactive), real-time UDP의 특성상 낮은 지연과 낮은 오버헤드를 가지고 있음. Why is it hard?인터넷은 best-effort (서킷을 가지고 있지 않는한) 의 형식을 띄고 있어서 패킷 손실, 지연 등을 100% 보장할 수 없다. 다양한 종류의 원인으로 인한 손실도 존재한다. Network Delays 송신자는 지속적인 흐름의 오디오/비디오 샘플들을 보낸다 (대역폭은 코덱에 따라 다르다) 물론 수신자는 지속적인 스트림을 받기를 기대한다 (끊김없이) 이를 위해 라우터의 경로, 대역폭, 용량 (capacity) 등을 모두 필요로 한다. 물론 종단까지의 모든 라우터와 경로가 송신자것이 아니니 불가능하다. 이상적으로 레이턴시 이후에 100%의 패킷을 받는게 좋지만 (constant delay and everything at once) 현실은 다양하게 변화한다. Jitter: 처리 시간 및 결과물의 도달 시간의 변동폭 등 (패킷 지연 변동폭) 즉 위의 패킷 전달 마찰은 밑의 그림과 같은 상황을 야기한다. 각 패킷에 대한 지터가 다르기때문에 보낸 순서와 상관없이 도착하는 패킷 순서및 타이밍이 다른것. 버퍼링 (TCP - lite)송신자는 당연히 지속적인 오디오/비디오 샘플 (패킷)을 보낸다. 당연하게도 수신자는 끊김없는 스트리밍을 받기를 원한다. 이와 같은 효과를 내기 위하여 수신자는 playout buffer을 만들어 지연등을 부드럽게 만든다 (보통 바이트 단위로 만들지만, 효과적이기 위해서는 시간 단위로 만들어야 한다) 지연 시간 (playout)을 일정 단위를 추가해서, 그 시간/단위 기간동안 패킷들을 더 기다린후, 유저에게 보여주는 형식이다. 내가 아는 하두리? 버퍼링은 바이트 단위의 버퍼링이다 (시간 관계없이 영상 바이트들을 어느정도 받고 나서야 시작이 됬으니까). 밑의 그림처럼, 어느 선까지 받고서 그 이후의 패킷들은 버린다. (물론 예상컨데 버퍼링 implementation 마다 다를것이다.) 물론 위와 같은 버퍼링은 trade-off가 존재한다. 큰 버퍼: 지연으로 인한 패킷 손실이 줄어든다. 이는 곧 지터/PDV (Packet Delay Variation) 에 대한 tolerant가 늘어난다. 다만 transmission 과 playout 간의 지연이 늘어난다. 즉 영상을 시작하면 부드럽게 진행되지만, 처음 시작하기까지 오래걸림. 작은 버퍼: transmission and playout 의 delay가 적다 여유 기간이 짧은 만큼 (큰 버퍼에 비해) 더 많은 패킷들이 지연으로 인해 손실된다. 지터/PDV에 대한 tolerant가 더 적음. 바라는 지연이 짧을수록 손실을 방지하기가 더 어려워진다 - 이로 인해 glitch 가 생성되는데. 흔한 예로는 비디오와 오디오 싱크가 안 맞는등.. Fixes? 재전송: 패킷 손실을 알아차리면, ARQ (TCP-like) 를 이용해서 재전송을 요청한다. 이로 인해 round-trip-time + latency + Queue 딜레이 만큼 더 걸린다 이는 곧 큰 수신 버퍼와 지연을 의미하며, 송신자 또한 버퍼 도구가 필요하다 (아마 원하는 패킷을 저장해두고 다시 보낼수 있어야 하니까). 멀티캐스트 (UDP) 방식에서는 반드시 송신자가 다시 보내는것은 아니다 아래와 같이 주위의 다른 수신자가 있으면 걔가 보내줌 탄력적 버퍼 (Elastic): 상황에 맞게 버퍼의 크기를 조정함 이를 위해 playout을 느리게 함 상황이 나아지면 버퍼의 크기를 다시 줄여서 (지연/손실이 줄어드니) 빠르게 진행한다 (실시간일 수록 좋으니까 상황이 괜찮으면). Error Correction: 패킷간의 보간법을 위한 미디어 인코드 - 보간법을 이용해 뭐를 놓쳤는지 알 수 있음 Forward Error Correction - 고장난게 있으면 직접 고칠수 있음. 신뢰성이 필요한곳이나 재전송이 비싼 경우에 사용되곤 한다. 병렬 전송 다양한 카피들을 같은 시간에 보내는것 - 동영상 화질에 종류가 있는것들. 즉 1080으로 보다가 멈추는것보단 360으로라도 끊김없이 보는게 나으니까. 즉 결국 내용을 볼 수 있다는것 자체로 신뢰성이 필요한곳에 사용될 수 있다. Realtime Transport Protocol (RTP)UDP, TCP냐에 따라 연결성이 달라짐. 다양한 미디어 인코딩을 지원하며, 다양한 자원들이 병합, 동기화, 선택 될 수 있다. (비디오 따로 오디오 따로 보내서 두게를 합치거나, 언어와 자막을 선택하는등의) 송신자는 여러가지들을 고려하여 RTP를 어떻게 보낼것인지 조정할 수 있다. 현재 스트리밍이 어떻게 되고 있는지 (비율, 인코딩, 에러 수정, 재전송 등등), 혹은 얼마나 많은 그리고 어느 종단들이 받고, 보내고 있는지 (멀티캐스트). RTP Control Proctocol (RTCP) 양방향, Out-of-Band 시그널링 (독립된 채널을 통해 시그널링 하는것) (RTP는 짝수 포트, RTCP는 홀수 포트) - 대역폭을 제한해야한다. 송수신자 모두 보고를 한다. (통계: 패킷의 수신/손실, 지연, 지연 변동폭등) 자원 설명, 송수신 시작/완료 (Hello Goodbye) 존재 알리기 (heartbeat pulse), 거리 (홉), 재전송 요청 채널 등등 다양하게 지원함 ALL together여러 사이트에 여러 미디어 스트림을 보내기. 다음과 같은것들을 필요로 한다. Establish a call: Session Initiation Protocol (SIP) - 세션 시작 Negotiate the details: Session Description Protocol (SDP) - 세션 정보 협상 (뭐로 할건지) Deliver the media: RTP and RTCP - 협의 바탕으로 결정한 프로토콜로 정보 교환 Playout as reliable and quickly as you can: (buffer) - 알아서 Session Initiation Protocol (SIP) Open with IETF protocol to establish and close the call with RFC. 어느 방식으로 전달 하던 상관없음. 이 세션 프로토콜은 스카이프, 메센저, 줌등에 사용되지 않음 라이벌로는 ITU H.323 이 존재함 Voice over IP (VOIP)에 주로 쓰임 프록시,registrars, redirectors, border controller, gateway 등등을 포함하하며 PSTN 연결이나, NATs등에 유용하다. Non-realtime realtime? 단 방향 미디어 전송: 스트리밍 less interactive, 지연에 덜 민감하며 (almost live), 대역폭이나 지터에 문제를 아직 가지고 있음. Sliding windows을 통한 playout buffer 관리 (나중에 다시 한번 읽을것) 수신자는 컨텐츠를 빼내고, 버퍼를 played out 된것처럼 채운다 Real Time streaming Protocol (RTSP) 스트리밍 세션을 만들고 미디어 전송을 협의한다 (프로토콜등) HTTP 와 SIP와 비슷하다 옵션 (무엇을 할 수 있는지) 설명 (무엇을 줄 수 있는지) 셋업 (스트림(들)을 프로토콜을 통해 수신할 준비 플레이 (play from time 1 to 2) RTP/RTCP 등을 통해 대역폭, 인코딩을 적용함 최후의 수단: HTTP 이용 방화벽을 통과 할 수 있으니까 다양한 extensions을 지원하니까 (어플리케이션, 전송 프로토콜등) Head Request를 통한 미디어와 옵션들 요구 Get with Range Get을 통한 요구 playout 버퍼를 위한 조각들을 다운, 서버에게 인코딩 부탁하기 HTML 5 has bulit in vidoe player. (to kill flash) 이득: 서버 state 필요없음, HTTP 프록시, 캐쉬, CDNs 등을 물려 받음 정리 완벽하고, 적은 지연, 실시간등은 best effort 네트워크에서 하기 정말 힘들다 Very application specific - 유통성이 없음 특별한 서킷을 이용해서 경로를 만드는게 아닌이상, 힘듬 오디오 비디오는 괜찮음 (기술의 발달로 화질이 올라감) - 괜찮음의 정의가 시대상을 따라감 기기 조종을 위한 실시간 트래픽이 늘어나는 추세임 인터넷이 최선의 선택은 아니더라도, 유일한 선택일지도 모름","link":"/2020/05/01/Network/Week%207%201%20Realtime/"},{"title":"IoT/MQTT Protocol","text":"MQTT Protocol Applications Use TransportUDP based Short messages, simple request/response trasactions Light server touch, ARQ suffices Real Time Protocol (RTP): Low delays, ARJ, short messages, weak client/server relationship TCP based Larger contents, longer, more complex sessions Reliaibility, Packaging and presentation important (as it is bytestream) HTTP: Strong client/server relationship, exchange messages. Internet of Things - Why different? Scale: 기기의 숫자 No limits on addresses and connections Limit messages to avoid network swamp - 숫자가 너무 많아서 메세지 크기를 줄여야함 Power: Minimal powers; solar, batteries, RF Reduce/turnoff transmission power Do the smart things somewhere (which consums powers alot) - 즉 IoT는 수집 모니터링 과 같은 역할만 수행하고 분석은 다른 컴퓨터에서 하는것 Networking: 저전력, 원격 위치, 넓게 분포 Limit transmission needs - 메세지 보내는것도 에너지/트래픽이 요구됨 Reduce bandwidth/distance/targets - 스스로 제한을 걸어서 통신횟수를 줄이던지; Get/give helps from the neighbours - 주위와 연계해서 전체적인 통신횟수를 줄이던지; 대신 이러면 항상 깨어 있어야함 Timeliness: 빠른 지시와 반응이 필요 할 수 있음 다음과 같은 사항을 고려하여 디자인 한다 Exceptions vs Regular Reports - 언제 리포트 하는지 Transmitter vs Receiver Req - 송수신기 필요성 Short msg, prioritised msg - 메세지 Reliability: 조그맣기에 어렵다 필요할떄만 의존성 사용, 최대한 가볍게 (ARQ push/pull 이라던지) Design - PubSub 데이터와 상태의 “announcement” 는 “consumption”과 분리되어 있다. 모든 종류, 숫자의 소비자들이 subscribe 할수 있어야 하고 모든 종류, 숫자의 소스들이 publish 될 수 있어야 한다 Avoid “connection” - 5번과 연계됨 위의 사항들을 만족하기 위해 “broker” (server) is needed 가볍고, 빠르고, 유연하며, open된 브로커 (당연히 웹서버는 이에 해당안됨) 각각의 기기들은 브로커에게 퍼블리시 할 뿐이고, 브로커가 소비자들의 요구를 감당한다. 이로 인해 각각의 기기들은 위의 조건들을 만족할 수 있는것. MQTT (브로커) Messeage Queuing Telemetry Transport: 많은 IOT기기들에 최적화된 가벼운 메세징 프로토콜. 낮은 전력 낮은 대역폭 낮은 성능의 환경에서도 사용이 가능하다. TCP와 높은 버전의 UDP 등등 여러 프로토콜에 의해 사용된다. 통신 과정 Publisher (센서 장치)가 데이터를 Topic을 정해서 브로커에게 전달. 이 Topic을 sub 하는 subscriber (출력, 처리 장치) 가 브로커에게서 데이터를 받아온다 만약 해당 토픽을 구독하고 있지 않으면, 데이터는 받지 못한다. 특징 Pub - any vaule type to a specific (key). Sub - subs to particual topic (which may not exist now, but in the future), or to a fitered set of topics (such as Pizza, instead of Hawaiian pizza) Broker - $sys/# - special topic Holds info about the broker itself 로드, 대역폭, 저장, 클라이언트 등등 하지만 브로커간에 정형화된 필드가 존재 하지 않음 (각 브로커마다 다름) 또한 resolution 이 다름 (즉 각 브로커마다 메세지 퍼블리시 텀이 다름) TCP 와 UDP (버전에 따라) 모두 사용가능하다 매우 비트단위인데, 압축된 메세지, 그리고 퍼블리셔와 네트워크의 부담을 줄이기 위해서이다. 메세지 16 Messages Types Connect and disconnect and ACK 채널과 서버 상태 확립, 그리고 스스로를 identify (lighweight security). Ping req and response - Server level; 어플리케이션 계층 (not ICMP - network layer) Pub, sub, unsub: 퍼블리시의 경우 양쪽 다 쓰임 소스 → 서버, 서버 → 구독자 다양한 Quality of Service Minimalism (main MQTT rule) 서버는 최대한 적은 amount of state를 유지하기를 원한다. 구독자: “잠시동안 불가능” “더이상 흥미없음” 등등? 서버는 메세지를 queue 하지 않음 - mostly 구독자들에게 메세지가 배포되면, 그 메세지는 삭제된다 구독자가 없는 메세지 또한 삭제된다 서버가 데이터베이스를 청소할 수 있는 기회를 제공한다 (최대한 가볍게 유지) QoS 어플리케이션 레벨에서 가지고 있는데 이는 몇 구독자의 경우에 “확정 - sure” 이 필요하고 모든 구독자는 어느때나 참여 할 수 있어야 하고 전원, 게이트, 버퍼 여유분 등등 여러 사항을 고려할 수 있어야 하기 때문 다음과 같이 세가지 레벨을 가지고 있다. 0: 메세지를 푸시하고 바로 삭제해 버림 (Fire and Forget) 1: 전달을 보장한다. 따라서 확인 절차가 필요하다 (At least once) 2: 전달을 보장하고, 4단계의 핸드셰이크를 이용한다 (Exactly once) 다음과 같은 상황도 가능하다. Last Known Good 드물게 보고하는 센서들 새 구독자에게 뭘 줘야함 (드물게 pub 되서 마지막이 어느 상태인지 알려줘야지) Retain: 메세지를 삭제할지 유지할지 정하는 플래그 서버에 저장되며, 리붓되어도 존재한다. 구독자에게서 처음으로 요청 받을때 보내진다. Last Will and Testament 어느 토픽이던 소스는 초기 메세지를 배포할수 있다 - retained 메세지, 바로 보내지는 않는다 만약 서버가 배포된 메세지를 keepalive 구간 후에 받지 못하거나 TCP 연결이 MQTT 종료 메세지 없이 끊기거나 한다면 연결을 잃었으며 Soruce는 실패했다고 판단한다. 이후 각 구독자에게 알린다 (현재 서비스 불가능 등등) Clean Session 연결시에 플래그 됨 Clean: Pretend Ima new one Not clean: Persistent Session - Ask server to remember you. Plain for the server: 너의 모든 구독된 토픽을 저장한다 모든 메세지들을 저장한다 (QoS 1 and 2) 재연결 되었을때 놓친 모든 메세지를 전달한다. MQTT의 경우 어느정도의 보안이 존재하나 IoT의 경우 없다고 봐도 무방하다 아이디 비번 페이로드 시그네쳐, 무결성 검사 암호화된 연결 등등","link":"/2020/05/26/Network/Week%207%202%20IoT%20MQTT%20Protocol%20e98c41771d4440b2ad0141c5037ae2ed/"},{"title":"Network Routing","text":"그래프 기본 용어 Fowarding vs Routing TableForwaring: 목적지까지 가장 빨리 도달할수 있는 다음 포트 (위치)를 알려주는 표 Routing: 출발지부터 목적지까지 경로를 적어둔 표. 라우팅 알고리즘으로 경로를 파악해서, 빠른 구간을 알려주는 포워딩 표를 만들 수가 있다. 가장 큰 차이점은, decisions in local or global 이라고 볼 수 있다. 포워드는 내 위치에서 목적지를 향하는 가장 가까운 다음것만 알려주니 Local. 라우팅의 경우 여러 경로를 알고 있으니 (의도적으로 다른 경로를 알려줘서 로드를 줄일수도 있음) Spanning Treesloop을 없애서 안전한 경로를 만들었음. 하지만 이로 인해 바로 옆에 있는 경로도 선택을 못하는등의 낭비가 발생함. 즉 만들어진 경로에 대한 퀄리티를 측정할 방법이 없음 Routing어느 경로로 일정 트래픽을 보냄으로써, 네트워크의 대역폭을 그 경로의 조건과 요구사항에 적응하며 형성. 라우팅은 이상적으로, 컨트롤러가 없으며, 모든 노드 (라우터)가 비슷하며 (같은 언어, 알고리즘 등등) 이웃과 소통을 하며 학습하고, 각종 링크/메세지 실패를 처리 해야한다. 라우팅에는 몇가지의 Expectiatons 들이 존재하는데 Correctness - A 로부터 B에 패킷이 전달되어야 한다. Efficiency - Use available bandwidth and other resources (CPU, energy) Fairness - Dont ignore capable network elements (적절한 네트워크 요소에 공평해야 한다) Convergence - Recover fast from disturbances Scalability - Copes (대응) with large and complex networks 최선의 경로란 무엇인가? 최선을 정의하는것에 다양한 요소들이 존재하는데 레이턴시 (distance delay), 대역폭, 코스트, 홉스 (forwarding delays) 고정된 위상을 사용할 경우, 링크 혼잡과 라우터 부담등을 전혀 고려하지 않는다 Shortest path routing가장 비용이 낮은 라우팅을 말하며, 양 종단간의 route간에 소요된 비용중 가장 낮은것을 선택함. 물론 해당 비용은 정의에 따라 다르다 (홉수, 속도, 지연, 가격 등등) Optimality Property: ABCDE 가 AE를 연결하는 가장 짧은 구간이라면, AB, CDE, BCD등의 sub 구간또한 가장 짧은 경로이다. Sink(source) Tree: 각 소스로부터 해당 node까지의 가장 가까운 경로들의 합. E의 sink trees = FE, DE, BE, ABCE등 물론 소스 트리의 경우 양방향을 고려하기도 해서 만약 비용이 비대칭적이라면 sink tree ≠ source tree. 어느 곳에서 시작을 하던, 결국 라우팅 결정은 목적지에 따라 결정된다. 어디서 시작되는지는 사실 중요하지 않음. 각 노드들은 해당 목적지까지의 가장 가까운 경로를 가진 다음 hop만 알고 있으면 됨 (포워딩 테이블) Dijkstra’s algorithm위상과 비용이 주어졌을때 각 소스에 대한 소스 트리를 만든다, 위에 명시된 Optimality property를 사용한다 https://namu.wiki/w/%EB%8B%A4%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%9D%BC%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98 소스로 부터 시작해서 모든 소스들에게 반복적으로 탐색을 시도한다 Leverages optimality property - 부분 구간을 이용하여 더 긴 가장-짧은 구간을 만든다 복잡한 네크워크에서는 스케일링 문제가 있다 - 한 부분이 바뀌면 다시 다 탐색해야함. Complete Topology을 필요로 한다 (각각의 노드/소스 로부터) Distance Vector Routing위상을 모를때, 가중치가 음일때도 사용가능하지만, 다익스트라보다 시간 복잡도가 높다 노드들은: 이웃까지의 비용밖에 모른다, 오직 이웃과 대화한다 모든 노드는 같은 알고리즘을 사용한다, 노드와 링크들은 메세지를 잃거나 실패할수 있다. 모든 노드들은 모든 종착지에 관한 거리와 다음 노트를 저장하고 있다 루트를 더하거나 삭제할때, 옆 이웃과 이야기가 안되면 업데이트 할때 서로 알려주면됨 어느 특정 네트워크가 사라질때 구간의 비용이 무제한이 될 수 있음 - 이에 대해 따로 알고리즘이 필요함 만약 ABCD 에서 A가 사라지면, B는 C 에게 C는 B에게 A에 대해 서로 물어보게됨 왜냐면 A-B 로 이어져 있어도 C-A연결이 가능할수도 있으니까 (평소에는 그냥 최단거리만 알고 있음) 이를 해결하기 위해 Poison reverse or split horizon을 이용한다 내가 루트를 배운 노드에게는 내 노드를 광고하지 않음 몇몇 상황에서는 well scale 하지 않음. Link State Routing더 많은 계산을 필요하지만, 더 나은 모습을 보여줌. 기업네트워크에서 스케일이 좋다 (글로벌은 아님) 예로는 Open Shortest Path First (OSPF), IS-IS 다른 알고리즘과 비슷하게 다음과 같은 요소들을 가지고 있음 이웃과 이야기하며, 그들만의 비용만 알고 있고 위상을 모르며 (초반에), 노드/링크/메세지 실패를 처리할수 있다. Simple Algorithms in 3 parts Flood the network Broadcast incoming message to all outbound - 이를 link state packet (LSP)라 칭한다 내가 받은 메세지를 모두에게 알려주는거. 놓치면 ARQ 이용해서 다시 알려달라함 돌고돌아 자신에게 도착했을때 반복하지 않도록만 알고 있으면 됨 (보통 증가하는 넘버를 사용함) Learn the topology LSP를 듣고, 위상을 파악함 Compute Tables with Dijkstra 아마 여태 받음 LSP들을 다 저장해서 각 노드에 개별적으로 계산하는듯 내부적으로 (스스로) 다익스트라를 실행함) 반복적이고, 많은 씨피유를 낭비하지만 효과적임 Repeat everytime whene there is a change. 만약 한 링크의 변화를 감지하면 업데이트된 LSP를 1번하고 3번을 모든 노드가 다시 함 다양한 실패들이 존재함 (flood, node flaps, seq# error 등등) LSP ageing and timeouts 를 이용해서 처리한다. Equal Cost Multiple Path라우팅 프로토콜/알고리즘은 아니고 그냥 extension임 소스와 목적기까지의 경로를 여러가지를 가지고 있음으로써, 로드 밸런스, capacity increase와 같은 성능 향상과 Greater redundancy (불필요한 반복) 를 가져온다. 이를 위해 Detect 와 foward traffic along with paths 가 요구된다 Detection: 같은 비용의 여러가지 경로가 존재 한다면 모두를 저장해둔다. ABE, ABCE, ABCDE 모두 비용 8 Not a tree, but a directed acyclic grapd Forward: Detection을 통해 이제 forward table 는 각 목적지에 여러 인터페이스를 가진다 각 패킷에게 다른 경로를 (무작위로) 제공한다. 이로 인해 로드밸런싱은 좋으나, jitter (패킷 딜레이 variation)은 안좋다 왜냐면 다른 경로를 통하니 서로 PDV 가 다르지 관계에 따라 경로를 제공한다 소스와 목적지의 아이피 주소를 이용한다. 같은 비용, 지속적인 성능을 제공한다 아이피 주소를 이용해서 이 아이피 주소는 이 경로만 이용하는거 흐름에 따라 제공 Use of flow identifiers (IPv6) 이러한 방법들은 불균형적이지만 좀더 예상 가능해 진다. Hierarchical Routing 스케일링 문제가 존재한다 라우팅 테이블, 계산, 포워딩 테이블의 크기가 점점 증가하기 때문이다 네트워크 aggregation - LAN prefix 가 이미 존재하기에 그것을 이용한다 한 서브넷안의 모든 호스트를 광고할 필요없다, 나 (라우터) 에게 결국 와야 하니까 한 서브넷의 집합을 큰 서브넷처럼 다룬다 - 모든 서브넷들이 붙어 있는건 아니다 Routing to a region 장점: 노드와 서브넷을 합쳐서 지역으로 간주한다. 이로 인해 그 안의 복잡함을 감추고, 테이블의 길이를 짧게 한다 또한 통신과 계산등을 줄일수 있다. 지역간을 담당하는 라우터를 지정하고, 각 지역마다 어떤 방식을 사용할지 결정도 가능하다. 즉 A는 B 쪽 라우터를 가려면 꼭 이 라우터를 통과해야 하는 담당 라우터를 말하는것 단점: 덜 효율적인 경로가 만들어질수 있다. Policy Routing 다양한 정치적인 기준점이 존재한다; 돈 정치, 보안, 종교 14. Routing in Internet - 인터넷에서의 라우팅 가장 짧은 경로는 결국 지역적 우선순위, ISP는 단지 부담을 최대한 줄이고 싶을뿐 Hot Potato Routing 이라고 한다 최단 경로가 아닌, 어느정도 짧은 경로 이용 비대칭적인 경로, 오고가는길이 다를수 있음 계층은 좋은 비지니스 이유로 수립되지 않음 Common Policy Transiting: ISP A 가 너의 인터넷 연결을 관리함 Peering: ISP A가 너에게 인터넷 트래픽을 주고 받고 제공하지만, A가 인터넷에 연결된게 아닌 ISP B로 부터 인터넷을 받아오는 형식 Border Gateway Protocol (BGP)다른 ISP간의 트래픽 전송을 방지하고 자신의 네트워크를 통해서는 트래픽 라우팅을 원하는 정책 오늘날 가장 흔한 정책이다 키 컨셉트: Autonomous System (AS) 즉 자치 시스템안에서의 노드들을 통합 이로 인해 확장성 문제를 해결화 한다. Border Router (Gateway) which run BGP 를 확정한다 외부 (네트워크) 와 지역 (자치 시스템) 사이를 담당한다. 이 게이트 웨이가 다른 라우터에게 자신이 담당하는 경로를 알릴지 말지 결정 가능하다 이 라우터에게 정보를 받지 못하면 이 네트워크 이용 불가능 하다 (뭐있는지 모르니까) 혹은 몇몇 경로만 필터링해서 알려줄수도 있다. 또한 이 게이트웨이는 다른 라우터로 부터 도착한 메세지의 목적지를 보고, 내가 제공하는 경로중 하나이면 다음 홉으로 패스해준다. (이 조건은 가격, 친구요청인지, 안전한지 등등 많다) 외부와 내부의 라우팅 프로토콜의 단절화 Intradomain 하나의 관리자가 제어하므로 정책 결정 무필요 성능에 초점 interdomain 각 네트워크 관리자 끼리 정책을 교환한다 정책에 초점 - 최소 비용이 더 중요하기 때문 BGP는 LS 보다는 DV에 해당한다 (DV 보단 Path vector에 더 가깝다). 루프의 존재를 감지와 함께 삭제할 수 있다. 위의 경고 광고는 다음을 포함한다 IP Prefix, next hop Path: list of AS’s to transit 이로 인해 루프의 존재 감지및 삭제를 가능하게 한다 거리 indication 은 없다. 정책 Implementation BGP 로 누구한테 “광고”를 할지 설정할 수 있다 Border Routers 들은 가능한 경로들을 광고 하는데 (얘네가 담당하니까 다른 Inter domain 연결을) 얘네가 사용 가능한 (허락해준) AS 에게만 혹은 얘네가 허락해주는 AS 에게만 혹은 알려주되 다른 경로들 (빠르거나 느리거나) 을 AS에 차별해서 나눠준다 (AS간 금전거래 이유등등) 와 같은 다양한 이유와 목적을 가지고 경로들을 알려줄 수 있다. 또한 Border Router 들은 다양한 announcements 들을 주위로부터 받는데 자신이 사용하고 싶은 광고만 골라서 네트워크 안으로 전파할 수 있다 (예를 들어 같은 목적지에 갈 수 있는데 싼 비용의 SA 광고만 전파한다던가 등등) 보통 peer 관계의 경우 [B, (AS3), borderRouter 3a] → B는 AS3 의 3a 라우터를 통해 도착할수 있습니다 알려주는것 transit의 경우 [B, (AS1, AS3), router 1b] → B는 AS1 을 통해 AS3 로 가서 도착할 수 있는데, 먼저 AS1의 1b 라우터를 통해 오십시오 같은것 결국 위의 A 손님은 B 로 갈수 있는 방법이 두가지인것. 보통 peering 이 무료다.","link":"/2020/06/20/Network/Week%209%20Routing%20a5df6418d68d46eda3b83a7c17f451a1/"},{"title":"Defender Frictions","text":"Reference : Network Attacks and Exploitation by Matthew Monte Mistakes:Fail Open: Fail to remove a user - leaving an avenue for unauthorised access. Fail Secure: Fail to add a user. For security, the trick is to minimize the number of potential systems and processes that fail open and to develop a response plan for those that remain. Flawed Software:Coming from mistakes, from the overall design structure, omission. Inertia:It requires force to change, where force is the resources and motivation to change and the knowledge that is necessary. The Security Community:In finding flaws and fixing them, the security community can make the Attacker’s job paradoxically easier. Patch released —&gt; analyze the patch —&gt; attakc before IT updates the systems. Complexity:Complex program, structure makes hard to fix, detect, analyze and implement. Users:Hard to deal with people who does not know about the IT Bad Luck:yeet","link":"/2020/03/15/OCSO/Ch%206%20Defender%20Frictions/"},{"title":"Offensive Strategy","text":"Reference : Network Attacks and Exploitation by Matthew Monte Crafting a successful strategy requires: A clearly defined goal; strategic collection, directed collection, non-kinetic CNA, strategic access and positional access. Embracing the fundamental truths of the space; three foundational principles: humanity, access, and econmoy. Determining and reducing the uncertainty of frictions while increasing the opponent’s. Determining and maximising advantageous asymmetries, while minimising the opponent’s. Principle 1: Knowledge Is the in-depth understanding of the tech aspects of architecture, OS, Network, and so on as well as psychological aspects of people and organisation. Is the target agnostic and acquired outside of any specific operation. Is essential to leverage all three principles: access, humanity, economy. Reduces frictions - helps reduce flawed attack tool. It costs time and money Has limits of incompleteness and inaccuracy. The best decisions are made by those that have a balance of knowledge of the thech, psychological, and social aspects of operations Principle 2: Awareness Is the careful mapping of the operational domain as well as the active detection and passive monitoring of events in near real time. Is gleaned from the target environment and is target specific. Seeks to counteract the Defender’s asymmetrical advantage of turf control. May allow the attacker to discern when the frictions of updates and upgrades are coming where they will be deployed. May tell the attacker the likelihood and consequences of being caught - as can see hows the security going by humans aspects. Leads to the more effective deployment of tactics - as aware of the ongoing situation. Requires greater exposure and risk - need expansion to collect awareness. Too much —&gt; may lead overconfidence or can be paralysing (too much worries). Buys time: to innovate, to put in redundancy, to collect data, and clean up and out. Principle 3: Innovation Is the ability to create new technology, leverage existing technologies in new ways, or develop and adapt operational methods. Requires creativity; essential for finding flaws by divining assumptions that engineers and administrators may have not realised they were breaking. Is creativity brought to scale through sound engineering. Can improve efficiencies and decrease frictions. Confers a tactical advantage. Principle 4: PrecautionConsider the effects of the Defender’s actions on the Attacker Is the minimisation of the effect of unwitting (자신도 모르는) actions on an operation. Is the strategic principle that fills the void left by the impossibility of obtaining total awareness. Redundancy: is establishing reasonable fail-safes, backups, and contingency methodes, network signatures.. - allows the operation lives Diversity: is leveraging a wide range of tools, technologies, development methods, network signatures… - prevent full operation failure. Redundancy - Points of acceess per seg = lg(number of devices) Diversity = 1 to 2 methods / platform. The best precaution will depend on the attacker’s level of awareness. Principle 5: Operational Security Consider the impact of the Attacker on the Defender. Is the minimization of adversarial exposure, recognition, and reaction to the existence of an operation. Is best defined as doing everything that prevents discovery. Is the twin of the principle of precaution; Precaution - the effects of the Defender’s actions on the Attacker, Operational Secu - the impact of the Attacker on the Defender. Minimizing Exposure Stealthness - more than active hiding; includes being a tree in a forest. Minimizing Recognition Has level of exposure to observations. Ensure that observable artifacts and actions are kept within an expected pattern. (behave the common pattern they do) Decoy - spread out anomalous actions in space and time to keep below the human thrushold of perceived cause. Controlling Reaction May leave decoys that misdirect Defenders into thinking they have rooted out the problem. MeasuringThe more awareness you have, the more secure you can be. But the act of acquiring that awareness is less operationally secure. Principle 6: Program Security Is the principle of containing damage caused during the compromise of an operation. You do not want to affect the other operation from the failure of one. Attacker Liabilities Anything that can be used to impede the Atttacker’s future operations. Defenders will do Battle Damage Assessment (BDA) - What What systems were compromised? What credit cards were exposed? What user accounts? What is the value? Defining who and how is intensive work. Categories are: Identity, Target Pollution, Attacker Infrastructure Technical Vulnerabilities, technical tools, Operational Methodologies. Program Security CostsAttacker Costs &lt; Defender Costs is ideal. Do following to increase the costs for defenders: AntiReverse Engineering - Prevent Static Analyze; Reverse Engineering - no control, but analyze and knows how does it work. AntiDebugging - Prevent Dynamic Analyze; Debugging - analyze with the control. Capability Diffusion: separate big into small segements so hard to define the links in between the programs. — Careless increase of Defender’s analysis cost may trigger the detection and lose the superiority; with potential of decreasing the costs for them + decrease program security Mitigation is the cost of preventing the attacker’s actions in the first place, or cleaning up after successful attack detection. - 예방및 공격감지후 보호/정리 비용 Distribution is the cost associated with either acquiring that knowledge or sharing with others : Computer Emergency Response Teams (CERTs)","link":"/2020/03/19/OCSO/Ch%207%20Offensive%20Strategy/"},{"title":"Defensive Strategy","text":"Reference : Network Attacks and Exploitation by Matthew Monte Failed TacticsAntivirus and Signature Based DetectionAntivirus: Attacker can buy and test against it. Don’t be on the bad list: if the program not on the antivirus list, theres no code signature. Can avoid doing bad behavioul: thhrough trial and error or reverse engineering. Be stealthy Signature Based Detection: it does not encounter any strategic principle Information of product Defender use can be obtained easily; by release of partnership companies, or through the access, posititon recruiting. Predictable schedule of updates sequenece (once a year…) Password PoliciesBoth ignore the foundational principle of humanity. Choos a strong password - humans are terrible at choosing random passwords (predictable) Avoid reusing passwords - no way to enforce and check among users. User TrainingUnless there are real consequnces to user mistakes, it wont work. Crafting a Defensive Strategy Avoid recreating the wheel - Start with following the guides Know yourself - what is truly essential. Develp data classification system - apply rist management mentality to what is important (determine value, how much worth to spend on it…) Prioritize the user base by the sensitivity of the a data they can access. Prioritize systems according to how they interact on the network. Application WhitelistingOnly allowed can play the party Network Segmentation and SegregationSegmentation : For attacker has two choices Treat as a single network: sucks resources of attacker as it takes great amount of work by treating each segment as a network. It also dramatically increase the exposure of attacker. Jump between segments: When cross the segements —&gt; creates perfect choke point. Constraints the ability to move and obstructs attackers ability to communicate. Counters Operational security. Log AnalysisQuestionable for preventing. And attacker will sacrifice one and collect the data. And able to do sidestepping. It is good for Defender after a compromise. Web Domain Whitelisting for All DomainsOnly allowed domain can be visited Limits the avenues of infiltration - less vulnerable. Limits Attaker’s option for communication after establish the access. It is against the foundational principle of humanity. Deny Direct Accees form WorkstationNeeds all outbound access through an authenticating choke point. Great for limiting attacker’s access without limiting uesrs much. It needs innovation, but once set it is good. It dircetly encounter attackers strategy on almost every level.","link":"/2020/03/15/OCSO/Ch%208%20Defensive%20Strategy/"},{"title":"OCSO - 1","text":"Reference : Network Attacks and Exploitation by Matthew Monte The Australian National University CECS Adavanced Persistent Threats Technology is the mediunm - it originates from people Focus upstream away from APT signatures to APT tradecraft - Understand APT decision and where to look (위 흐름으로 어디서 부터 시작할지) Know the complete picture from start to end. Greater understanding enablse better profiling — 즉 여태 있던 것들을 공부함 어디서 시작하는지 모델을 이해하기 Know networking protocols Understand OSI, TCP/IP Understand logical Network segment — 네트워크 기술에 대해 이해가 필요하다 Comfrotable with Command Line Interface (CLI) - OS Understand Components - file system, registry, services… — 소프트웨어에 대해 이해가 필요하다 Tradecraft Theory (스파이 활동에 필요한 지식의 이론) Targeting: to better plan our approach to the objective. Core tactics Leverage Pivot Proxy Tunnel Shovel Pillage Copy Query Capture Discover Research Harvest Mine Recon Scan Probe Assure Security Bootstrap Beacon Surveillance Static Dynamic Stealth Hide Clean Blend Blind Access Exploit Inject Spoof Overflow Script Payload In-Line Staged Kamikaze Vector Direct Intercept Redirect Cyber Tradeoff 4Ts Target: Establish a detailed model of the target space. Further analyse the existing target intelligence and derive target intelligence collection requirements. 목표정보 수집및 필요조건 수립 Initial research and reconnaissance against target. 초기조사 및 정찰 Construct five-level target model. Tactics: Design sub-tactic objectives for each target. 목표물에 따른 상세 작전수립 Introduce Discover/Access/Assure/Leverage and corresponding sub-tactics. Understand tactical goals and considerations - 작전 목표및 고려사항 이해하기 Learn tactical frameworks to structure activities - 작전 체계 배움으로써 실행 구조만들기 Techniques: Select best one to achieve the sub-tactic objective. 작전에 따른 기술 선택하기 Identify the range of technique to achieve the goal. - 사용가능 테크닉 찾기 Compare and contrast techniques. - 테크닉 비교 대조하기 Cosiderations in choosing one. - 테크닉 선택 고려하기 Tools: Select best one to achieve… Examine trade-offs between qualities of tools in flexibility and ease of use. Look at ways to systemize and automate activites (reduce potential error/efficiency…) Practice procedural use of tools. 연습하기 Case StudiesBlack Energy - https://blog.alyac.co.kr/547엑셀 메일첨부로, 엑셀내 메크로 실행으로 스크립트를 설치, 시스템32에 들어가 파일을 이용 exe파일을 설치및 바로가기 설정이후 스스로를 삭제. 바로가기 설정에 컴퓨터를 킬때마다 파일을 실행하는 스크립트가 시작됨 인터넷 익스프로어러 보안 셋팅을 바꾸고, 관련 웹사이트로 꾸준히 접속 연결을 시도 회사 네트워크와 발전소 네트워크는 방화벽으로 인해 들어갈수 없었음 몇달간동안 회사 네트워크를 스캔, 맵핑을 하고, 윈도우 도메인 컨트롤러에 접근권한을 얻는데 성공 윈도우 도메인 컨트롤러에서 정보를 수집후 이 정보로 방화벽 통과 (페이즈2) 공격시작 파워 서플라이 프로그램 재설정 성공 (전력 자동 재공급 무력화) 킬디스크 배포해 워크스테이션 고장 (부팅 안되게함) 직렬-이터넷 컨버터에 펌웨어 오버라이트 (원격 제어 불가능하게 함) 전화 시스템 무력화 (손님들에게 전화 안옴) 파워꺼버림. APT28 - 러시아 정부에 대한 집단만 타게팅함대부분의 공격을 이메일 피싱에 의존하고 있음. 메일에 첨부파일 방식 2. 단체에서 제작한 웹사이트 링크걸기 3. 관계자가 자주 사용하는곳들을 감염시켜 침투하는 방법. 메일에 진짜 첨부파일을 같이 보내서 의심을 줄임 (리스트 파일 원래 한개인데 두개 보내는등) 가짜 웹사이트를 만들어서 링크를 타고 온 사람이 로그인을 시도하면 페이지 오류인척, 새로고침 혹은 다시 시도하면 정상 사이트로 보내 아이디 비번 뺏기 가짜 웹사이트 티를 안내기 위해 주소이름이 비슷하게 지음 (폰트를 이용한 착시등) 마이크로소프트 오피스 취약점을 이용하여 (매크로) 침투 이와 같은 방법을 통해 타겟 시스템에 점차적으로 침투함 APT29; Hammertoss and Seaduke러시가 정부에 청부를 받음. 고위층 개인이나, 정부 조직, 미국및 유럽의 국제 정책및 개인 리서치를 목표 공식인정 받음 서비스들을 이용 (트위터등) 하여 보호자들이 찾기 힘들게 만듬 공식 계정을 생성 (트위터) - 커뮤니케이션 채널 수입 해머토스도 1번과 같이 계정을 만듬 해머토스는 1번계정으로부터 명령을 받음 (안에 방문해야할 링크, 복호화 코드등이 적혀있음) 링크를 타고 들어가서 트위터 사진을 다운받아, 안에 숨겨져 있는 데이터 추출 추출한 데이터의 명령어 수행 (다양한 공격 수행함: 파일삭제, 파일 깃헙업로드, 이메일 통해 빼돌리기, 중요 정보 모아두기등등) 클라우드 서비스로도 업로드 할 수 있었음 Network 이해하기TCP/IP will aid troubleshooting. 인프라의 논리적 구조와 컴퓨터간 통신을 설명한다 각 모델은 레이어들의 계급구조로 이루어져 있다 낮은 레이어는 윗 레이어를 보조한다 절차가 실패했을때, 낮은 레이어부터 위로 점검/고치기 시작한다 OSI도 좋지만 TCP/IP 가 좀더 우리의 목적에 부합하다 TCP/IP model describes how data is passed Sending data to applications needs the support of network, internet and transport layers. Domain Name: Title or role assigned to computer Host Name: Configurable name for computer Port: Logical address for application data 어플리케이션 상호 구분을 위해 사용 - 각 프로토컬에 맞게 따라감 IP 내에서 프로세스 구분을 위해 사용 80: HTTP, 22: SSH, 53:DNS 혹은 임시포트로 프로세스들에게 임의 사용 IP address: Logical address for NIC MAC: Physical network interface card (NIC) hard-coded ID 데이터 링크 계층의 일부 이더넷 기반 기기에 모두 하나씩 할당된 고유 아이디 앞 24비트는 제조사 코드 뒤 24비트는 기기 고유코드 Networks are segmented physically and logically. (pg 67) Subdomain/zone - controls user and system accessibility to one another. en.wiki.com 은 wiki.com의 서브 도메인이다. Subnet - A sub portion of IP address (부분망). bitwise and - create prefix. subnet host num = 2^(subnet mask - 24) VLAN: LAN에 흐르는 트래픽을 제한하여 불필요한 트래픽 차단 논리적인 LAN으로 주로 스위치에서 사용된다 한 장비내에서 브로드캐스트 도메인을 나누는 것 같은 가상랜 내의 노드들과 통신이 가능하다. 다른 가상랜은 트래픽을 공유하지 않는다. 네트워크 성능 효율성이 올라감 - 병목현상 줄이기. Each Layer purposeLayer 2 - Data Link: Can I get a past the switch? 스위치 통과 가능한가 (접근 주소 찾았나) Can I see ARP (Address Resolution Protocol) broadcasts (맥-아이피) from the target Am I in a vlan? Layer 3 - Network: Can I route to the target? 타겟까지 접근 가능한가 (패킷 교환) Is the target receiving my packets Is the target blocking my packets Layer 4 - Transport: Can I reach the target port? 타겟 포트 가능한가 (포트,프로토콜) Is the port blocked Is the protocol blocked Is the port being used","link":"/2020/03/05/OCSO/Lec%201%20OCSO/"},{"title":"OCSO - 2","text":"Reference : - Network Attacks and Exploitation by Matthew Monte - The Australian National University CECS TargetFive levels of target: Operation Scope —&gt; Networks —&gt; Subnet/VLAN —&gt; Systems —&gt; Software. Five influential elements: Launch Points: Where can this target point be engaged from? Cover: 누구로 위장? 네트워크를 뚫고 침입해서 정보를 뺴갈만한 사람이 누구인가? Obstacles: 목표를 향하는데 방해/고려 요소들. 방어 체계가 어떻게 되어있나 Key Terrain: 타겟에 접근하기 전에 해두어야 (이뤄두어야 할) 요소들 Gaps: 목표의 첫 진입로는 무엇인가 위 네가지 요소들은 시작전에도 필요하지만 작전이 진행되면서 계속해서 바뀌어간다. TacticsDiscovery has Two Modes: Passive: no negative effect on the target Active: Provoking a system to observe its response has Two Vectors: Indircet: Interacting with infrastructure not controlled by the target Direct: Engaging target infrastructure Research: 타겟에 대한 정보를 직접적인 건드림 없이 모으는 행위. 리서치의 목표는 정찰 활동에 집중하기 위해서 호스트 발견하기 위해서 작전 보안의 위험성을 낮추기 위해서 정보는 미완성이고 관련성과 최신성이 낮다 존재하는 정보들을 모으는 단계라고도 볼 수 있는데 두가지가 있음 Harvesting: 목표와 관계된 정보들을 최대한 모아서 그곳에서 목표 가능한 개체를 찾는것 웹사이트 컨텐츠나 서류에서 정보를 수확할 수 잇다 인터넷 인프라 - 지역 인터넷 이용자, DNS등 컨텐트와 메타데이터 로부터 얻는 이메일과 이름, 아이피 주소와 도메인등 Mining: 하나의 개체를 중심으로 정보를 더 깊게 파는행위 구글 크롤링이나 인덱스 제 3자 정보 모아주는 서비스 이용 (무료/유료) Google, Shodan, Maltego Reconnaissance: 리서치 단계로부터 얻는 결과에 대한 확인과 보완 작업 목표는 물리적 시스템과 소프트웨어 목표와 직접적으로 반하기 때문에 들킬 수 있다. 가장 최신화된 정보를 제공함 타겟에 대한 접근성을 테스트 함 좀더 현실성 있는 정보들을 흭득하는데 두가지 방법이 있음 Scanning: 사이버 레이더와 비슷함 호스트, 서비스, 버전등의 발견을 목표로함 Port scanning, Service enumeration, Ping. Trace Route, Firewalking, DNS zone transfer 등 Probing: 목표를 도발(건드림) 함으로써 반응을 살핀후, 치명적인 약점을 찾아내는것 훨씬 시끄럽고, IDS/IPS signatures 로 부터 수상한 움직임으로 발견될 수 있음 목표 시스템을 심문함으로써 취약점을 발견 Vulnerability scannig, fuzzing, brute forcing, stress testing. Password해쉬는 디스크 혹은 확인 절차중의 트래픽에서 수집된다 트래픽에서 하는 해쉬가 훨씬더 보호되고 풀기도 어렵다 해쉬를 크랙킹 하는것은 오프라인 공격에 해당된다 온라인 공격은 시스템이라 웹사이트 로그인 기능에 대한것이다 보통 브루트 포스와 딕셔너리 (해쉬 저장된)를 이용한다. Access보통 해킹이라 불리는 단계가 이 단계 Exploit: 소프트웨어 취약점을 목표로 한 코드. 목표 시스템에 들어가서 payload 를 실행함 두 시스템간의 신용 (trust)을 이용함 백엔드의 경우 프론트엔드를 믿고 받은 커맨드를 실행함. 따라서 프론트엔드의 실수가 백엔드로 이어지는것 (트위터 포스트에 코드 올려서 인풋이 실행된다던가 혹은 SQL Injection) 혹은 중간에 들어가서 클라이언트, 서버 역할을 해서 정보를 뺴낸다던가 Payload: 목표 시스템에서 해커에게 access 제공하는 코드 해커에게 문열어주기, 더 많은 페이로드 설치하기 (한번에 다 보내면 위험하니까), 셋팅 바꾸기 (그리고 사라짐) Vector: 시스템 공격부터 목표까지 도달하기 위한 위 두가지를 전달하기 위한 이벤트의 절차나 순서들 직접 (해커-목표), interception (정당한 다른 시스템-목표 평소 사용하던 광고 사이트에 광고 요구, 광고가 감염됨 (서버아님) — watering hole attack), redirection (목표를 위험한 사이트로 인도하는것 - 서버가 감염됨)) Assure (확실) 접근은 작전의 시작 부분이고, 이 확실 부분이 접근과 실행단계를 연결해주는 다리 역할 이 확실 단계가 가장 들키기 쉬운 단계로 다른 부분들에 비해 제일 위험하다 접근은 너를 문안으로 발자국을 딛게 해주고, 확실은 문 키를 주는것. 작전에 따라 확실 정도가 달라짐 작전 완료를 위한 시간 버는 중요한 단계 결과론적으로 확실단계는 작업 필요성과 타겟과의 마찰을 적절하게 유지하는 것. 접근과 마찬가지로 시스템, 네트워크 레벨 총 두단계로 나눠지는데 System Level Assurance: 특정한 시스템에 접근권한을 유지하는것 Network Level Assurance: 네트워크에 접근권한을 유지하는것. 네트워크 레벨 접근은 사실 시스템 접근성에 기반을 두고 있다. 접근의 경우 방어나, 혹은 자연적인 시스템에 의해 잃을수 있다. Access Losing action 은 사람이나, 기계의 방해에 따른 (방어나, 혹은 중립적인 시스템 이벤트에) 결과이다. Hostile: 너의 칩입을 겨냥한 반응 Neutral: 자연적인 시스템 사건에 의한 반응 Human: 사람의 선택에 따른 반응 (업데이트/업그레이드 혹은 설정 바꾸기등) Machine: 머신의 프로그래밍에 의한 반응 Assurance - Sub-componentsSecurity상대방의 행동으로 인한 접근권한 잃는것을 지켜준다. 접근 보안이 Assurance의 세 부분중 (보안, 감시, 잠행) 가장 먼저 지켜져야 한다 보안은 redundancy를 통해 (즉 백도어) 달성될 수 있다. 백도어의 중요한 원칙은 백도어간의 단절화가 지켜져야 한다. 백도어는 두가지 방법으로 설치가 가능한데 타겟 시스템에 새로운 소프트웨어를 설치하는법 타겟 시스템에 존재하는 소프트웨어를 수정하는법 Redundancy는 한 접근 방법을 잃을 때 다른 접근 방법이 남겨지는것이다. 접근 위험을 퍼트려야 한다 (하나 걸릴때 다른거 안걸리게) 첫번째 접근 했던 방법을 고려해서 이 방법에 영향 받지 않는 두번째 접근 방법을 고려해라. 복제 형식으로도 가능하지만, 이는 곳 signatrue를 강하게 남긴다는 뜻이다 완벽한 단절은 엄청난 시간과 투자를 요구한다. 보안의 목적은 수화물이 프로세스가 죽었을때 다시 켜지는것 공격 스테이션이 실행되고 있는 수화물에 접근 가능하게 하기 위해 (즉 프로그램 심어놓고, 그 프로그램에 대한 접근이 가능해야 뭘 하지) 보통 두가지를 사용하는데 Bootstrapping : 수화물을 운영체제에 연결하는법 윈도우의 경우, 시작폴더, 서비스, 레지스트리 들을 참조한다 스케쥴링은 어플리케이션 실행하는데 다른 방법이다. Beaconing: 타켓에서 공격자 인프라에 연결을 하게 하는것. 접근 세션 혹은 정보의 변경/추출 을 시도한다. 정기적으로 beacon에 의해 수화물이 설정변경 가능하다 (타겟이랑 연결되어 있으니 수화물 조정이 가능하지) 해당 시스템의 운영체제에 있는 어플리케이션이나, 새로 다운된 것들을 실행하도록 스케쥴링을 시킬수 있다. Surveillance위험성을 감지함으로써 적절한 반응 (responsive action)을 시간내에 가능하게 해준다 Is only an enabler to responsive action or investigation. May alert to threatening actions and allow you to take timely action. 접근을 잃으면 이 감시를 더 분석하고, 미래의 접근 방법을 조정하게 해준다 시스템/사람 모두로 인해 위협이 일어나니 모두 고려해야한다 감시 기간동안 걸리면 접근이 차단될 수 있다. (즉 감시 하다가 걸리면 당연히 뭘 하겠지 상대방이) 로컬 atcivity 들을 모니터링 함으로써 시스템의 위협을 감지 할 수 있다. 그 행동이 (activity) 가 중립적인지 적대적인지를 확인하는것이 시스템 위협 모니터링의 목적이다 보통 적대적 시스템 행동은 보안 기기나 보안 소프트웨어에 의한다 목표 기기가 알아차린것과 사람이 반응하는 시간 차이는 목표물의 보안 성숙도와 교양에 달려있다. 사람 위협의 감지는 기기와 인간이 만든 컨텐트들의 모니터링을 필요로 한다 사람 행동을 로컬 시스템 이벤트들로 감지 가능하다 사람이 만든 컨텐트는 잠재 위협 행동의 가장 좋은 지표이다 (사람이 뭘 만들었으면 시스템이 바뀔 예정이니 뭐가 어찌될지 예상/확인이 가능하다) 이러한 감시들은 관리자 워크스테이션에서 존재해야 가능 할 수 있다 (may) Assurance는 관리자 시스템에 접근하기 위함이 첫번째 이유이다. 모니터링에는 두가지 종류가 존재하는데 Static Monitoring: take a snap of target activity (processes, stats, logs). 커맨드를 사용해 파일로 만들고, 압축해서 보낸다. 부트스트래핑을 이용한 방법이다. Dynamic Monitoring (Real time): 특정 행동들을 감시하는것 저장하고, 쿼리로 만들고, 테스트를 하고, 필요한 정보가 있다 하면 보내는것 아니면 폐기. StealthAssure 단계에서 가장 마지막에 고려되며, 초기 접근과 Assurance 활동의 들킴을 방지한다 잠행은 공격적/방어적 인 방법이 있는데, 방어적은 은엄폐를 통해서, 공격적은 상대방의 센서능력의 하락을 통해서 이루어진다 방어적 장행 위장과 엄폐를 사용한다 엄폐는 감시 능력 밖에 위치하거나, 들킬만한 것들을 제외 함으로써 가능하고 위장은 들키더라고 안걸리고 넘어가는것 타켓 네트워크와 시스템이 자연적 위장을 가능하게 해준다 (즉 그 상황을 사용) 공격적 잠행 최후의 보루로, 높은 위험성을 내포하지만 같은 결과를 도출함 (즉 걸리지만 않으면 좋음) 상대방 감지 능력 감소를 야기함 감지를 직접적으로 공격하거나, 간접적으로 공격함 직접적인 방법은 disablement or reconfiguration 간접적인 방법은 chaff - deploying more observable to attract (즉 함정 쓰는거) 디코이 Assurance를 디자인 하는것인 작전 결정이며 목표와 키 위험성을 고려해야한다 다른 단계에 비해 가장 높은 위험성을 내포하고 있고 (위험 메니지먼트에 가장 크게 의존함) 두가지 성질에 의해 measure 가능하다 Operational Equities: Customer owned. Wider investment in operationaloutcomes. Affects stakeholders. Capability Equities: Internally owned. Investment in infrastructure, tools andtradecraft. 단계별 관계도 Resilence (복원력) 는 모니터링의 요구도를 줄일 수 있다. 하지만 모든 Resilence 메카니즘이 모니터되는건 아님 (즉 요구도를 줄이지만 없애지는 못함) 좋은 모니터링과 반응은 light resilence를 커버할 수 있다. 하지만 모니터링은 alert to resilence mechanisms 할수 있다 모니터링 행동은 잠행 기회들을 발견 할 수 있다, 하지만 모니터링은 타겟 시스템에서의 활동을 늘린다 잠행은 발견 확률과 모니터링 요구도를 줄일수 있다. 하지만 잠행을 늘리는것은 모니터링의 감소를 필요로 한다 (시간은 유하니까) 발견 안되면 지우지 못함 (내가 있는지 모르니까), 하지만 이러한 잠행 기술들은 표식을 남긴다 내 활동들이 중간에 방해되지 않으면, 잠행을 덜 필요로 한다. 하지만 resilence의 증가는 시스템 활동을 늘리고 잠행을 줄인다. Leverage : activities achieving operational objectives Pillage (약탈하다) 상대방의 시스템에 접속해 정보를 약탈하는게 우선순위. 다른 감염된 호스트들 (감염시킨) 을 통한 pivoting 을 하여 접근한다. 약탈을 하는 목적에는 두가지가 있는데 관련된 요구 지식을 충족하기 위해서 네트워크와 시스템 접근과 assurance를 가능하기 위해서. 네트워크는 보통 라우터에 의한 서브넷, 그리고 스위치에 의한 가상랜으로 나뉘어져있다. 그 네트워크의 단절성을 통과하기 위해 피벗팅이 필요 할 수 있다. 한 시스템은 여러 가상랜위에 존재 할 수 있다 (회사 백엔드, 혹은 관리자 시스템) - 즉 가상랜을 통해 시스템 접근가능 Pillage 복사: 보통 유저 라이브러리, 로그, 비밀번호 해쉬등을 복사하며, 이 정보를 빼내기 위한 exfiltration 방법은 FTP, SCP, Netcat등 세션에 달려있다. 쿼리: 호스트나 해당 네트워크에 관한 정보를 생성함. 시스템에 특정 질문을 해서 (command) 관련 정보를 빼내는방법. 보통 &gt; &gt;&gt; 같은 명령어로 txt 파일로 옴겨서 추출함 캡쳐링: 컴퓨터에 저장되지 않는 동적인 정보들을 캡쳐하는것. 서류 스크린샷, 키로깅, 네트워크 스니핑 (오고가는 데이터들 중간에 가로채는것 - 사이트/시스템 비밀번호 같은것들 포함) Pivot Proxy: 클라이언트와 서버 사이에서 데이터를 전달해 주는 서버. 프록시는 패킷을 전달 받고 목적지에 전달해준다. 즉 다른 네트워크로 가는 게이트웨이 역할. 여러 프록시들이 모여서 프록시 체인을 형성하기도 한다. Tunnel: 프록시보다 더 복잡하다. 특정한 어플리케이션 트래픽을 만들어 내기위한 고급 방법. 터널링은 복잡한 트래픽 흐름을 만들수 있도록 조정가능하다. 한 희생양을 이용해서 목표물에 접근하는 방법. Shovel: 다음 작전을 위해 감염시킨 타겟에 도구들을 옮기는것. 즉 1번 타겟을 공격해서 감염시키고, 1번타겟에 도구들을 올려서 타겟 2를 공격하는것. 즉 나는 명령어를 1에 내리면 1이 2를 공격하는것. 타겟에 도구를 옮겨야 하는만큼 들킬 가능성이 높다, 대신 연결 실패할 확률이 적음 (연결 실패 확률이 적은 컴퓨터를 감염시키겠지)","link":"/2020/04/03/OCSO/Lec%202%203%20OCSO/"},{"title":"Asymmetries","text":"Reference : Network Attacks and Exploitation by Matthew Monte False AsymmetriesCostCost alot for both of attackers and defenders. AttributionCyber Attribution is the process of tracking, identifying and laying blame on the perretrator of a cyber attack or other hacking exploit. Finding the target and catching the attacker is pretty much the same. And even penalties different via countries. True Asymmetries Advantage for attackerMotivation:Attacker: costs but there is a huge payoff potential and little risk. Gains are immediate and tangible Defender: Nothing to gain, only something to lose. Loss is often intangible from nothing to catastrophic. This diffrerence creates an imbalance in motivation even if the law comes in, monotony makes defender less motivated than attacker. Initiative:Is ability to make threats or take actions that require your opponent to react. Motivation : mental States. Initiative : measures ability. Attacker acts and Defender reacts —&gt; means that the Attakcer can stay one step ahead. Focus:Attacker: has a sigle mission and point of focus. Has a feedback coming from the accomplishments and failures Defender: Split focus between securing the network and running it. Lack positive feedback. Cannot prove a negative. Effect of failure:Preventing an attack may have no effect wthasoever on the attacker Honeypot is a computer network designed to entice attackers in to trick them into exposing a larger cadre of tools and methods in the hopes of inflitcing a cost; histrically been expensive. Attacker: loss almost non-existent; time and small amount of cost. May apply the failure to make the next step Defender: a lot. No idea how would be the next step be. Knowledge of Tech:Attacker : There are but a limited number of typical setups and the Attacker has seen them all. Full time spending studying offense and even defense. Urgency for defender is different. Defender: must learn defensive methods and tech to stay current and to maintain compliance. The gap comes from the motivation and eagerness on learning more stuff. Analysis of opponent:On general, Attackers can acquire, analyze, and test against solutions of security software before deploying their attack tools, Attacking tools cannot be purchased, but must be captured. Must detect and capture tool for analysis, but need to analyze it to detect and capture. Tailored Software:Attackers have an advantage in creating and deploying pointy-end software. The development cycle can be condensed and it is under their own control. However, this advantage is not inherent. The defensive security market is actively researching and developing defensive architectures that can bequickly tailored to specific environments under the buzzword adaptive defense. Results so far have been muted, but it is in the early stages. If and when a true adaptive defense is achieved, the Attackers’ advantage will dissipate. Rate of ChangeWhen software is updated, if new features are added, there’s a decent chance new vulnerabilities will be introduced. The rate of change and the resultant shaky foundation it creates offers a renewing stream of vulnerabilities that is to the Attacker’s advantage. True Asymmetries Advantage DefenderNetwork AwarenessDefender: has full access to every details such as switch, router, firewall… Attacker: cannot acquire the same level of detail with the same level of Defender’s effort Network Posturemicrosacle ig. Address Space layout Randomization (ASLR) Defender: has full right to construct the Network attributes from policy to technological. Attacker: harder to target the moving object. Advantage Indeterminate for bothTimeAttacker: time to do overall operation. However it may allow them to be exposed. It may help but hurt at the same time. Defender: Overall maintance, upgrade, RECON, … EfficiencyAttacker: Cost of Acquiring Information vs Value of Information Acquired Defender: Cost of Securing Information vs Value of Information Secured","link":"/2020/03/19/OCSO/OCSO_Asymmetries/"},{"title":"Attacker Frictions","text":"Reference : Network Attacks and Exploitation by Matthew Monte If you can forsee its coming, it is not a friction but obstacles MistakeNo matter the effort expended, mistakes will remain a source of friction. ComplexityThe complexity that makes a network harder to manage, also makes it harder to exploit. Implementing different systems in the network requires a diff set of tools and skills (Server: Linux. DB: Oracle. Router Huawei) Complexity requires more time, knowledge, and development to survey, understand, and circumvent. Because thelevel of complexity is diffi cult to predict and can severely impact the effi ciency of an operation, it is a friction. Flawed Attack Tools Best Flaw: Not function, but maintaining persistent access/command/control Loss of access: If not being noticed, it is recoverable if there is backup plan Worst Flaw: Noticeable Side Effect. ig. After the update, repeatedly crashed computer —&gt; drew the attention. Upgrades and UpdatesUpgrade: Introduces a new stuffs that replace an existing ones; may challenge the Attacker’s methods of persistence. Update: Improvement that leaves substantial portion of the original in place; consititute a substantial threat to maintaining access for the Attacker. Other AttackersOther attackers may ruin the operation. The Security Community Strengthening Defense: sudden intro of new detection tech - only short period of time. Weakening Offense: Google Project Zero - find and fix the vulnerabilities. Or publication of offensive methods Bad LuckUnnamed Frictions - anything that can be said unfortunate.","link":"/2020/03/15/OCSO/OCSO_Attacker%20Frictions/"},{"title":"Computer Network Exploitation","text":"Reference : Network Attacks and Exploitation by Matthew Monte Computer Network Exploitation - CNE Is computer espionage; stealing of information. Encompases gaining access and retriev data. It is directed. If the action was from no intent to gather information, it is not CNE. Comupter Network Attack - CNA Is akin to a traditional military attack or sabotage. Four Ds: disrupt, deny, degrade, destroy (회방, 방해, 효율 떨어트리기, 파괴) Actions and effects that range from the subtle to the catastrophic. Non-kinetic CNA Subset of CNA conducted virtually; 4Ds virtually. Not physically initiated acts. Computer Network Defense (CND) Protecting networks from being exploited or attacked. Computer Network Operation (CNO) Is umbrella term of CNE, CNA , and CND. Operational Objectives Strategic Collection Collecting information for strategic reasons. Collection of data over time. Requires substantial analytic capabilities for success due to the collected information size. The cost is huge, often limited to nation-states or well-funded criminals. Directed Collection Target the collection of information to meet an immediate objective. Initial intend of the operation is known from the beginning. It may start with short life expectancy, but successful operations will be extended over time. Non-Kinetic CNA Meant to Disrupt, Deny, Degrade, Destroy the operational capability of Computer Network. The information is leveraged to cause the damage rather than gathering information like the two aboves. Strategic Access Executed for the purpose of future flexibility Unlike strategic collection, it hopes one day the access becomes useful. It may be led to other operational categories, or do nothing; nothing defined yet. Positional Access target computers and network that are not the targets but useful to furthering a different objective. It may begin with a intent and expect short life, however may be extended like directed collection. If it is exetended, it carries the most risk as it may link other operations once detected. CNE FrameworkFirst PrinciplesHumanity Human Nature. Don’t forget it is the human who deals with. Access There is always someone with the access. It exists for someone who has the access of it Economy Priority, cost and benefit to every action and to every outcome — Money driven. Principles Knowledge Broad and deep understandingy of computers, network and behavioral and psychologicas characteristics of people and organization. Awareness Mapping of the operational domain, including active detection, monitoring of events in near time (updates…) Innovation Ability to create new technology, leveraging existing technologies, or develop and adapt operational methods to new circumstances. Precaution Minimization of the impact of unwitting actions on an operation. Operational Security Minimization of defender exposure, recognition, and reaction to the existence of an operation. Program Security Containment of damage caused by the compromise of an operation. ThemesDiversity Leveraging a wide range of tool, tech, development methods, network sig, infra, and operational methods… Stealth Leveraging tools, tech, and methods that are hidden from view or unlikely attract attention. Redundancy Reasonable fail-safes, backups, and contingency plans for foreseeable setbacks, and obstacles. Themes must be considered within the broader stretegic centext.","link":"/2020/03/03/OCSO/OCSO_CNE/"},{"title":"Attacker","text":"Reference : Network Attacks and Exploitation by Matthew Monte Life Cycle of an Operation - Principle of humanity Targeting (continual process - back up, seeking another way…) Identification of the target (which bank to rob) hard to be alerted (although the best defence is countersurveillance) Attack strategies and tactics to exploit the network (how to rob) make the tactic first and seek for the vulnerable network → Strategic Access Operation (look for unspecified target) At this time, objectivity is onset (as not know what will get) Any behaviour or information that are for the intrusion are considered as targeting process. eg. 어플리케이션 취약점 확인, 이를 사용하는 기업들을 찾아봄, 2009년에 서브웨이가 걸림 당한 당사자가 아니더라도, 이를 통해 취약점 확인, 보완 하는 방법으로 접근해야 한다. Initial Access - usually from user level (where it gets most monitored) Penetrating any defensive security. Gaining Initial Access Often the easiest and shortest stage focus of much of the security industry. Trends shows that there are constant supplies of this stage in the field. Persistence: turning initial access into reoccurring access that sustaining an operation possible. First defensive action of attacker → consolidation and securing of future access. As the vulnerabilities are 1) unknown for the duration 2) not always work. Backdoor (attacker’s own form of persistence) are for Normal usage; system restarts; reliable command and control channel. For elimination of breaking the system again (lower the risk) Expansion (to a target network) - area for defensive network to establish a persistence (initial access are most monitored access point) to locate and access wanted data. (as often initial access does not contain the worthy data) Exfiltration (몰래 빼오기) - retrieval of wanted data ultimate measure of success for strategic and directed collection operations. Hard for defender as it is subtle to differentiate between normal action and carefully managed malacious action. Detection - occurs when an operation is exposed to the target. Once the tactic is found, all the efforts made it into are gone. Principle of AccessThe approach the Attacker takes to gain initial access depends on the connectivity of the target network which are: Inbound Access (Can initiate a connection into the network from outside) Public Restricted know: password; VPN key; mouse movement etc. have: physical item - key, cell phone. The possession of the item (such as a random confirmation code via text) 인증서 같은거 virtual Location: allowed network address - 지정된 장소에서만 접속가능 — Above are impersonating “legitimate access” Illegitimate access - Circumvent the application (snapchat - collect other users information) Outbound Access (make user inside the network to do something) Email-attack Attachment Attack the email system (ideal attack) - only require user to preview or view the email. malicious links - 브라우저/플러그인 을 통한 방법. 현재 시스템들은 취약점이 많아 이 방법에 약하다 (하지만 눌러야 가능) Website Hijack Attacks (Positional Access Operation) Take over the website and implement some code for the users Cross-site-scripting (XSS) (https://ko.wikipedia.org/wiki/사이트간스크립팅) 웹페이지에 악성 스크립트 삽입 Domain name stealing Advertisement Filtering 파고들기 Circumventing Outbound Restirctions Software running on the host computer Software/hardware running on the network (difficult as the attacker must gain the access itself) —&gt; Even though the attacker has the access key and stuff, it does not mean the attacker has the access to it. Outbound access means the attacker needs to find a way to build the communication channel to access the internal network. Bidirectional Access - Some user group has access to the network No Outside Access - Physically separated from the outside (need the breach) Principle of Economy Time - the most important constraint Targeting Capabilities - 타켓에 대한 이해도 Exploitation Expertise - need for initial access, persistence, and expansion Networking Expertise - require through operation but most important during initial access, expansion, ande exfiltration. Software Development Expertise - to create robust attack, data collection, and analysis tool. The programs are Fault tolerant to the extreme - 문제생기면 재부팅 불가능 Highly efficient ane consume few computing resources or bandwidth Often explicitly breaks or circumvents OS and program norms Should work against its counter program Operational Expertise Operational Analysis Expertise Technical Resources Attacker Structure Targeting - 전체적 작전 지휘 간부진들 Door kicking Team - Initial Access 담당 들어가서 커뮤니케이션 설계 Rapid analysis team - 들어간 후 정보 분석 (빠르게 진행) Networking Team - 장기적 지속성을 위한 확장및 정보추출 (네트워크로 뺴내야 하니까) + 상쉬 보안 뚫기 Maintenance Team - 현재까지 만든것들 관리 Infrastructure Team - 이메일, 도메인 등의 정보 추출 통로 포인트 유지 관리","link":"/2020/03/19/OCSO/OCSO_The%20Attacker/"},{"title":"Defender","text":"Reference : Network Attacks and Exploitation by Matthew Monte Principle of HumanityThe Defender consists solely of the people actively or passively preventing the Attackter from completing any portion of the operational life cycle. Humanity And Network LayoutThe human inertia of “if it ain’t broke, don’t fix it” often prevents any reconsideration of security. Detailed network diagram shows how the organization grew. Because the influences in layout and technology of a network reflects stuff which are the influences of human in nature, the network itself will have an inherent humanity. Humanity And Security PolicyKeep things working well enough that no one complains; improve them when necessary and keep management happy. The humanity of convenience and habit will always trump security policy. Principle of AccessIt is attacker’s comfort, it is the Defender’s daily struggle; need to conduct all the jobs while keeping out the attacker. Principle of Least Privilege: limit access to documents, DB, and etc. —&gt; It requires seeking out feedback via the constant testing of security boundaries and the monitoring of access. Access denied —&gt; users notice —&gt; complains. Access mistakenly granted —&gt; not notice / no problem with it —&gt; no complaints —&gt; not able to fix within close dates unless reported. The Principle of Access gurantees the Defender will always be vulnerable. The Defensive Life CycleThe Offensive Life Cycel is : Start → Targeting → Inintial Access → Persistence/Access Expansion/Exfiltration → Detection The Defensive Life Cycle is: Start → Privacy → Prevntion → Prevention/Constraint/Obstruction → Detection →Response Privacy : the management of the publishing of information used for targeting (기업구조 차트, 파트너십 계약 등) ; marketing may want to tout this info. Difficult to manage but can be an important counter to targeting. Prevention: can stop the Attacker from gaining initial access or persistence. Firewalls, spam filters, browser security setting … Also exercised via less technical means such as creating a sane network architecture, consistent updates, or training users. Constraint: limiting of lateral movement within a network. Counters access persistence and expansion. can be thought as an insider mitigation, except the case attacker pretend being an insider. Requiring most users to use nonadmin accounts is a good one Obstruction: hard for attacker to get data back out of the network. called Data Exfiltration prevention or data loss prevention. Imposing bandwidth quota is a simple example of limiting attacker’s ability to move the data. Detection: catchcall for finding and recognizing the Attacker during any part of the operational life cycle. No fixed way to ensure detection. Response: Action the Defender takes once realize the compromise. Principle of EconomyDynamism : the economy of resources will affect the administrator base (the true defender who is directily responsible for security). The people are inevitably tasktd with upgrading hardware, …. overall IT stuff. Money may cost alot, but the benefits is not readily apparent untill after a robbery. Risk-based decision : one that should be based on actual risk and not legal requirements, but a decision nonetheless. This principle ensures that Defender will never devote as much time and attention to security as wanted. The helpful Defender Targeting: 이메일 주소의 형식화. 이로 유저 계정 유지에 도움이 되지만, 공격자 입장에서도 도움이 됨 Access : Ensuring compatibility and reliability while postpone the software update makes it vulnerable for a longer period of the time. Persistence: Upgrading on a fixed schedule. 유저와 공격자 모두 대비 가능 Expansion: Centralizing administrative authority to a few users → may help lock down insider access, 이 계정이 뚫리면 엑세스 다 허용됨 Exfiltration: 사람들에게 인터넷 접근 허용은 생산성 증가, 공격자와의 통신채널을 줄 수 있음.","link":"/2020/03/19/OCSO/OCSO_The%20Defender/"},{"title":"embParallel","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al The Australian National University CECS Embarrassingly Parallel Problems 계산은 각각의 프로세서들에 의한 완전하게 독립전인 실행 부분으로 나뉘어질수 있다 각각의 어플리케이션은 처치 곤란 병렬적이다 데이터의 분포와 모음이 중요 이슈이다 - 비용이 많이 들거나, 중요하다 대부분 마스터/슬레이브 접근방식을 사용한다 (p-1 speedup) 처치 곤란 병렬 망델브로 집합 Static Task AssignmentEach process needs to execute the procedure after being given the coordinates of the pixels to compute. Slave sends results back in groups which reduces the number of communication stratup times (for each message). — Note that master receives messages in any order. Dynamic Task AssignmentIdeally, all processes must be busy; but we do not know the speed of each. Dynamic load-balancing can be achieved by a work-pool which get the works supplied when the process is idle. Each processors request a job when it finished its. Summary tasks do not need to communicate non-tirvial but. providing input, aseemble the results, load-balance, scheduling, costing… Static (low communication) vs dynamic + overdecomp (better load balance) Monte carlo or ensumble simulations are a big use of computational power. grid computing arose to solve this issue.","link":"/2020/03/15/Parallel/Parallel_embParallel/"},{"title":"Architect","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al Why parallel is hard? Writing (correct &amp; efficient) : hard to debug Getting (ideal) speed up: communication shared data Synchronization (barriers and locks) need for redundant computations (balancing load evenly) Parallel approach is not always right. Design of diff processor type:Single Processor Design Same Language many happens within a single processor Potential issues for hardware side Multiple Processor Design Architectural Classifications Shared/Distributed memory hierarchical/flat memory dynamic/static processor connectivity Evaluating static networks Adding two double precision (8) = 8*8 = 64 bits Determine largest exponent (가장 큰 제곱수 - 지수) Normalize significand (밑수) of small exponent to the larger - 지수 밑수로 식 바꾸는거 Add significand (같은 지수의 밑수들 끼리 더해주기) 재정립 (올림내림 등등) — Each taking 1 tick → Total 4 ticks per addition (FLOP) Instruction Pipelining (https://namu.wiki/w/파이프라인(CPU))break an instruction into k stages ⇒ ≤ k-way || ism (instruction mix) FI = Fetch Instrn (불러오기) DI = Decode Instrn (해석하기) FO = Fetch Operand (함수 불러오기) EX = Execute Instrn (실행하기) WB = Write Back (값 적기) Conditional Branch - wrong guess may result flushing succeeding instructions from the pipeline. More breakdown stages → Increase in startup latency. Pipelining: Dependent Instrn.Principle = CPU must ensure result is the same as if no pipelining (or ||ism) 위 상기한 것중 EX의 실행하기 단계가 여러개의 사이클을 필요로 한다면 (3 사이클), EX1, EX2 처럼 연속적으로 늘어난다 (같은 카테고리에 속해있기에 dependent 하다). SuperScala (https://namu.wiki/w/슈퍼스칼라) 파이프라인 기업을 통한 CPU 속도 향상위한 컴퓨터 구조 설계 방식 SMT (Simultaneous multi-threading) 는 쓰레드 레벨에서의 병렬화, 슈퍼스칼라는 명령어 레벨에서의 병렬화다. 명령어 레벨 병렬화는 명령어간의 종속성을 최소화 해야하는데, 이로 인해 복잡한 명령어 스케쥴링이 필요하다. 이용해서 하나의 코어 파이프라인에 여러 쓰레드에 포함된 명령어를 섞어서 집어넣으면 스케줄링의 복잡성을 억제하면서도 효율적인 파이프라인 활용이 가능해진다. problem: amplifies dependencies and other problems of pipelining by a factor of w! 구현방식 In Order Execution : 해저드 방지를 위해 순서를 기다려야 해서 처리 속도에서 손해 Out of order Execution : Implement Reorder Buffer - 버퍼 안에 배열을 해 두고 순차 관계 없이 바로 처리하는것. If branch prediction failure, need to empty the buffer and fetch the instrn fast. The bottle neck happens. 이때 명령어를 한번에 읽어오는 구조를 슈퍼스칼라 라고 한다. MemoryTypically a processor can only issue one load or store instrn Memory latency and bandwidth are critical performance issues Main memory : large cheap memory with large latency and small bandwidth Cache: Opposite of main memory To reduce the time of fetching, try to ensure data is in cache (or as close to the CPU as possible) Cache memory is effective because algorithms often use data that:● was recently accessed from memory (temporal locality) - 최근에 사용된 메모리● was close to other recently accessed data (spatial locality) - 최근에 사용된 메모리에서 가까운것 메인 메모리의 경우 블락들이 각각의 캐쉬에 맵핑이 되어있음 (직접적이든 간접적으로든). 캐쉬는 보통 16-128 바이트 사이 Entire cache line is fetched from memory, not just one element (why?)■ try to structure code to use an entire cache line of data (한번에 복사되니까 모두 쓰게끔)■ best to have unit stride (어레이 처럼 사이에 공간 없이 연속적인 유닛)■ pointer chasing is very bad! (large address ‘strides’ guaranteed!) (이리저리 메모리 주소를 돌아다녀서) Memory bandwidth (전자기적 영역) can be improved by having multiple parallel paths to/from memory, organized in b banks - Unit Stirde 일때 효율적이며, 벡터 프로세싱에 좋고, bank-conflicts 일어나면 한가지 뱅크만 사용될 수도 있다. 당연하게도 필연적으로 프로세서는 클럭 속도에 따라 퍼포먼스가 제한된다 아무리 클럭 속도를 올리더라도 물리학상 빛의 속도 이하로 제한된다 ILP는 여러 명령을 한번에 실행가능 하지만 제한이 있다. 하드웨어 문제: Architecture Classification (Flynn’s Taxonomy) SISD: 1 CPU MISD: Pipelined? SIMD: Array/Vector Processor Data Parallel / Array Processor and Vector (in some extent) CPUs are controlled by one global control unit MIMD: Multiple Processor Most Successful parallel Each CPU is dealt by each control unit. Hence, processors are not synchronised → harder to program 스케쥴링 - 프로세서들에게 효율적인 일 분배 싱크 - 같은 데이터 동시 접근 방지 연결 디자인 - 프로세서/메모리 혹 프로세서/프로세서 연결 미리보기 - 자원 문제등 방지 위한 어느정도의 overhead 파티셔닝 - 동시 처리 스트림을 이용할 수있는 알고리즘에서 병렬 처리를 식별하는 것은 쉽지 않습니다. Address Space OrganizationMessage Passing (Distributed Parallel Computers) Each processor has local/private memory (메모리 공유가 아니기에) Interact solely by MP. (메세지 패싱으로만 서로) 프로세서 수에 따라 대역폭이 결정됨 Shared Address Space Interact by modifying data objects in a shared address space (공유 메모리) All the processors in the UMA model share the physical memory uniformly. In an UMA architecture, access time to a memory location is independent of which processor makes the request or which memory chip contains the transferred data (모두 공유하기 때문에 메모리 엑세스 시간이 프로세서나 메모리 위치에 따라 변하거나 하지는 않는다) 메모리 대역폭이나 프로세서간 커뮤니케이션의 확장성에 문제가 있다. Non-Uniform Memory Access (NUMA) 메모리간의 서열이 존재한다 모든 메모리에 접근 가능하지만, 위치에 따라 엑세스 시간이 달라진다 (머니까) 이에 따라서 중간에 캐쉬를 넣어 놓음 (fetching speed 빠르니까) Shared Address Space AccessParallel Random Access Machine (PRAM) : any shared memory machine Exclusive-read, exclusive-write (EREW PRAM) Concurrent-read, exclusive-write (CREW PRAM) Exclusive-read, concurrent-write (ERCW PRAM) Concurrent-read, concurrent-write (CRCW PRAM) Concurrent Write 다음과 같이 관리한다: Common : 값이 같으면 가능 Arbitrary : 아무 한 프로세서만 가능하고 나머지는 거절 Priority : 프로세서간 우선순위 설정 Sum : 모든 결과값 더하기 (즉 더하기 였으면 합쳐서 더해도 같으니까) Dynamic Processor ConnectivitySwitch is a mapping from the input to the output ports (# of switches = degree of switch) switches: internal buffering (출력 포트가 사용중일때), routing (네트워크 혼잡을 완화하기 위해), multi-cast (여러 포트에 동일 출력) 을 지원할 수 있다. 밑의 메커니즘 = mapping between input &amp; output. 매핑 하드웨어는 스위치 개수의 제곱, 주변 하드웨어와는 선형, 패키비지용은 핀의 개수와 선형으로 증가. Crossbar (프로세서가 많을 때 좋음) - 비용면에서 확장성이 뛰어나지 않음 (성능 확장 가능) non-blocking network : 프로세서의 통신이 다른 프로세서간을 방해하지 않음 network comp = Omega(p^2) - 스위치 복잡성으로 인해 높은 데이터 속도 실현 어렵 각 프로세서간 연결에서 로컬 메모리와 함께 연결도 가능하다. 다양한 메모리 뱅크를 가진 프로세서간 연결도 가능하다. 비용 theta(p^2) Multi-staged Networks (네트워크를 통하니 프로세서가 적당할때) - 성능비용 1,3 사이에 위치 O(lg p), 네트워크 비용은 theta(p lg p) 해당 메모리 뱅크를 사용할 때 다른 프로세서간의 연결 (그 메모리 뱅크 사용)을 차단함 route if MSB of s and t are the same; if not crossover. 010 (s) - 100 (so out through 101) - 011 (so 011) - 110 (cross to 111) - 111 한 스위칭 네트워크를 지나면 비트를 쉬프트 한다 (010 에서 0,1,0 순서로 비교) BUS (프로세서가 적을때) - 브로드캐스트에 적합 (성능 확장 불가, 비용면에서 확장 가능) 메모리 접근을 위해 버스를 통하는데, 버스는 독점적인 접근만 허용한다 (한명만) 따라서 버스의 퍼포먼스는 확장성이 제한된다 - 보통 12개 정도 까지 cost for expansion = p and the distance bet two nodes are O(1) - directly connected Network Topology Completely Connected - crossbar (non block communication) + static (directily point to point) Star Conncted - One processor acts as a central processor (bottleneck) → bus-based network K-D Mesh - 병렬 컴퓨터 보통 3차원 문제 다룸 ⇒ 3D 큐브를 보통 사용함 (Linear array) Hypercube - 대응 노드에 따른 연결 (3차원은 2차원 두개, 4차원은 3차원 두개 식으로 증가) Hamming Distance : xor 로 인한 거리 구하기 (블록 코드의 일종) 하이퍼 큐브에서 해밍 거리는 두 프로세서간 가장 짧은 거리의 값이다. Tree Based - only one path between any pair of nodes. 선형/스타 형식은 트리 네트워크의 일종. 프로세서가 메세지를 하위 루트 (송수신 노드 모두 포함) 까지 위로 보내고 거기서 내려주는 형식 다이나믹 트리: 리프들이 프로세서, 그 위는 스위칭 노드 트리 네트워크는 상위 레벨에서 병목현상이 심함 - 통신 링크 증가, 노드를 루트에 다 가깝게 전환 해서 다이나믹 트리에서 완화 할 수 있다. 이진트리는 루트를 통해 오는만큼 병목 현상이 심하나, 이를 고안한 뚱뚱한 상호 접속 나무가 있다 (fat tree interconnect) 리프노드만 프로세서를 가지고 있고, 성능을 저하시키지 않으며 파티션이 가능한데 이는 슈퍼컴퓨터에게 굉장히 유용하다. Static Interconnection NetworkDiameter : 두 프로세서간 네트워크상 최단 경로상 가장 먼 거리 Connectivity : 두 프로세서간 가능한 루트 (많을 수록 강한 연결을 뜻하니 좋다 - minimize fault-tolerance) 이 연결성은 비연결 네트워크 두개를 만들기 위해 제거 해야하는 아크의 최소 숫자로 구분짓는다 Channel Width : 두 프로세서간의 링크에서 동시교환 가능한 비트의 수 (= 두 노드간 연결된 물리 링크 갯수와 같다) Bisection width : 네트워크를 정확히 이등분 하기 위해 지워야 하는 링크 숫자 (단절시키기 위해) Bisection bandwidth : 같은 수의 프로세서를 가진 네트워크의 이등분을 위한 최소 커뮤니케이션 볼륨 (그래야 제일 비슷하게 나뉘어진거니까) - 이 값은 전체 시스템의 진실된 대역폭이며 병목 대역폭을 의미하기도 하기 때문에 중요하다. = bisection width * channel bandwidth (= channel rate * channel width) = cross-section bandwidth, can also be used as a measure of its cost. It provides a lower bound on the area. Dynamic Interconnection Network Diameter : max disatance between two nodes (indicative of max latency) Connectivity: node connectivity : min num of nodes that must fail to fragment the network into two. cosidering all nodes gives a good approximation to the paths (=arc connectivity in a similar usage) - althogh we only should consider switch nodes. Bisection Width: consider any possible partitioning of the p processing nodes into two equal parts. - 파티션을 가로지르는 엣지 수가 최소인 파티셔닝을 선택한다 이 최소 엣지수가 이분 폭 Cache Coherence : 캐쉬값을 일관성있게 유지하기 무효화 프로토콜 : p0의 값이 1에서 3으로 변경됬을때 p1값 (1)과 비교후 같지 않으면 모두 무효처리 캐시 라인 다른 부분을 업데이트 하면 알아차리지 못함 (false sharing) 이로 인해 일부를 업데이트 하면 다른 프로세서의 값이 무효화 됨 이 값을 제대로 가지기 위해선 해당 라인을 따로 원격 프로세서에서 가져와야 함 업데이트 프로토콜: 한 프로세서에서 캐쉬값이 바뀌면 p1값을 3으로 업데이트 후 메모리도 3으로 바꿈 p0가 값을 읽고 사용을 안하면, p1 에서 소스 대기시간 + 네트워크 대역폭 오버헤드 이 발생함 False-sharing 에서 업데이트 프로토컬은 모든 값을 업데이트 하므로 무효화 프로토콜 보다 낫다. 이 두 프로토콜은 communication overhead (updates) 와 idling (stalling in invalidates) 에서 절충해야 한다. 현재 추세는 무효화 프로토콜을 쓰므로 나머지 멀티프로세서 캐쉬 시스템은 무효화 프토콜로 가정한다. Invalidate Protocols 를 이용한 Cache Coherence 유지 메모리에 있을때는 공유상태, 한 프로세서 p0가 변수를 로드 하면, 이 변수는 더티 혹은 수정 상태로 표시됨 (flag) 이 상황에서 p1이 변수를 받고 싶다하면, p0이 값을 보내주고 메모리에 새로운 값을 업데이트 함. 이후에 변수는 맨 처음과 같이 공유 상태로 됨. 무효 상태의 값을 프로세서가 읽으면, 이 무효 블록은 값을 내려받고 공유상태로 돌아감. 비슷하게 프로세서가 공유 블록에 값을 적으면 무효 블록에 값을 줌. 이러면 다른 공유 블록들 모두 무효 블록이 되어버림. MESI protocol","link":"/2020/03/08/Parallel/Week%201%202%20Architect/"},{"title":"Message Passing","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al Message Passing Cost Startup Time (t_s): prepare the message (header, trailer, error correction information), execute the routing algorithm, establish an interface betw local node ane the router. —&gt; Delay is incurred only once for a single msg Per-hop Time (t_h): after a msg leaves a node, takes a finite amount of time to reach the next node (=node latency). 어느 채널, 아웃풋 버퍼로 보내야 하는지 라우팅 스위치가 판단하는 동안 대기하는 시간과 직결된다. Per-word Transfer Time (t_w): if channel bandwidth is r words per second, t_w = 1 / r to traverse the link. Store and Forward Routing - 전체 메세지 수신후 저장, 다음 노드로 전송msg sizeof m, l links, t_h for header, t_w speed. Total time = t_s + (t_h + t_w * m ) * l = t_s + mlt_w as t_h is comparatively small. Packet Routing - Modification of SF.Adv : 통신 자원 활용, 패킷 손실 (오류)로 인한 오버 헤드 감소, 다른 경로 선택 확률, 더 나은 오류 수정 기능. 이로 인해 장거리 네트워크 (인터넷 - 오류율, 홉 수, 그리고 네트워크 상태 변화 변수) 에 쓰임 Total Time = t_s + t_h * l + t_w * m where t_w = t_w1 + t_w2 * (1 + s/r) 각각의 패킷들이 다른 루트를 통해 전송 될수 있고, 잃어버린 패킷들의 재전송 때문에 지역/글로벌 네트워크에 많이 쓰임. Cut Through Routing 모든 패킷이 같은 경로를 사용하도록 해서 라우팅 정보 오버 헤드를 제거 시퀀스 내 전달을 강제함으로 시퀀스 정보 제거 메세지 레벨 오류 정보 (패킷 레벨 말고)를 연관함으로 오류 검출 및 정정 오버 헤드 감소 병렬 시스템 오류율이 낮기 때문에, 값 비싼 오류 수정 체제대신 싼 오류 잠지 메커니즘 사용 가능 메세지를 flow control digits or filts 라는 고정 단위로 나눔 이는 패킷 오버 헤드를 미포함 하기에 패킷보다 작을수 있음 Tracer 가 목적지 노드에 먼저 도착후, 연결을 설정, 플릿이 차례대로 전송 (모두 동일한 경로, 중간에 기다림 없음 따라서 버퍼 미필요) 이 와 같은 특성으로 중간 노드에서 더 적은 memory and memory bandwidth and faster Total Time = t_s + l * t_h + t_w * m ** 메세지가 작거나, 거리가 가까운 경우, 저장후전송과 컷쓰루 방식의 통신시간은 비슷하다. 제어 회로의 속도는 플릿 속도로 작동해야 하는데, 플릿 크기가 작으면 제어 회로 속도가 빨라지는데, 이는 라우터 설계에 상당한 어려움을 줌 플릿 크기가 크면, 내부 버퍼 크기가 증가하므로, 메세지 전송 대기 시간 (첫 시작노드) 이 늘어남. 요즘 플릿 크기는 4-32 바이트. Total Time = t_s + l * t_h + t_w * m - 컷 쓰루 라우팅 공식 메세지 전송 비용 최적화를 위해 Communication in Bulk: 조그만 메세지에 각각 t_s를 주느니, 큰 메세지 하나에 한번 주는것. 왜냐하면 클러스터/메세지 전달 시스템 같은 일반 플랫폼에서 t_s가 t_w 보다 훨씬 커서 데이터 볼륨 최소화: t_w로 인한 오버헤드 최소화를 위해, 통신되는 데이터 양을 줄이기 데이터 거리 최소화: 메세지가 통과해야 하는 홉 수를 최소화. 첫 1,2번의 경우 쉬우나 통신 노드 거리를 줄이는 (3)은 알고리즘 설계자에게 불필요한 부담을 줌. 왜냐하면 MPI 에서 프로그래머가 물리적 프로세서에 프로세서들을 맵핑하는것에 권한이 조금 밖에 없음. 가까운 이웃간에 통신은 괜찮을 수 있으나, 전체적인 매핑에 손상을 줄 수 있기 때문 대부분의 아키텍처가 2단계 랜덤 라우팅을 이용하는데 (처음 한번 중간 한번). 이는 네트워크의 핫스팟과 부담감 (contention)을 줄여줌. 무작위 라우팅의 홉을 최소화 하면 이득이 없음 홉당 시간은 t_s 와 t_w * m 에 비하면 굉장히 작아, 홉당 시간을 무시해도 된다. 따라서 Total Time = t_s + t_w * m 으로 정리될 수 있다. —&gt; 이 식은 혼잡하지 않은 네트워크에만 유효하다. 위 식은 런타임 예측 정확성과 독립적 알고리즘 설계에 중요한 영향을 미친다. 위의 식은 모든 노드간 통신에 같은 시간이 걸림으로, 완전히 연결된 네트워크에 해당함. 따라서 각 아키텍처 알고리즘 설계 하는 대신 비용을 생각한 알고리즘을 병렬 컴퓨터에 설계할 수 있게 한다. 물론 간소화된 공식으로 알고리즘을 설계 하면, 예측 정확도 손실이 발생하나, 홉당 시간이 굉장히 작다는 가정만 따른다면, 그 손실액은 미미하다. For communication patterns that do not congest the network, the effective bandwidth is identical to the link bandwidth. However, for communication operations that congest the network, the effective bandwidth is the link bandwidth scaled down by the degree of congestion on the most congested link. 네트워크 정체 시키지 않는 대역폭은 링크대역폭. 네트워크 정체 시키는 통신의 경우 유효 대역폭은 가장 정체된 링크의 정체 정도에 따라 축소된 링크 대역폭. 이 값은 구하기 어려울 떄가 있음. 따라서 우리는 하한선을 이용하는데, link bandwidth = p/b (b = bisection width) Communication Costs in Shared-Address-Space MachinesCache Coherence에서 비용줄이기가 더 어려운 이유 메모리 레이아웃은 보통 시스템에 의해 결정된다. 프로그래머는 특정 데이터 아이템의 위치와, 순열 데이터 구조 최적화에 권한이 적음. 이는 이 공유 주소 공간 아키텍처에서 중요한데 로컬 및 원격 엑세스를 식별하기 어렵기 떄문. 로컬 과 원격 엑세스의 시간이 차이가 나면, 통신 비용은 데이터 레이아웃에 의해 크게 달라지기 때문. 유한 캐시 크기로 인한 캐시 스래싱 발생 가능. 사용 가능한 캐쉬보다 필요한 데이터가 클 경우, 특정부분이 덮어 쓰기 되어 여러번 엑세스 될 수 있음. 이 오버헤드로 인한 프로그램 성능이 크게 저하됨. 이 문제를 피하기 위해서는 작업 세트 크기를 최소화 한 실행 스케쥴이 필요. 멀티 프로세서의 경우 페널티가 심각해지는데, 이는 프로세서간 통신과 coherence 작업이 연관되기 때문. 무효화 프로토콜과 업데이트 작업은 수량화 하기 어렵다. 업데이트시 발생하는 트래픽의 경우 프로세서마다의 작업에 따라 확연히 달라지는데, 이 동시화된 데이터 갯수와 스케쥴은 프로그래머 권한 밖인 경우가 대부분. 공간적 지역성 (Spatial locality) 는 모델링 하기 어렵다. 캐쉬라인은 보통 한 단어(데이터)보다 길기에 여러개를 부르는데, 이에 따른 접근 시간이 단어마다 다르다. 이전에 불려진 데이터가 불려지는 경우 (다른것은 새거) 등은 프로그래머가 최소한의 제어를 가지기 떄문에, 프로그래머가 할 수 있는것은 순열 데이터 구조를 극대화 시켜 공간적 지역성을 최대화 하는것 밖에 없다. prefetching 은 데이터 엑세스와 관련된 오버헤드를 줄이는데 중요함. 컴파일러는 미리 로드를 진행할 수 있으며, 만약 자원이 충분할 경우 이에대한 오버헤드를 숨길수 있다 (현재 진행하는 작업을 느리게 하지 않으니, 몰래 미리 스윽 해놓기 때문에 오버헤드가 없는것) 이 와 관련된 사항은, 컴파일러, 레지스터, 캐쉬의 기능이므로 정확한 모델링이 어렵다. False Sharing 은 두 프로세서가 각각 사용하는 두 단어가 동일 캐쉬 라인에 있을수 있음 (공유하지 않아도) 이때 일관성 작업과 통신 오버헤드가 발생할수 있는데, 프로그래머는 이를 최소화 하기 위해 데이터 구조를 채우는 수밖에 없다. Contention in shared access 는 공유 주소 공간 기계에서 오버헤드를 발생시키는 주요 이유중 하나. 하지만 이는 실행 스케쥴의 기능이므로, 정확한 모델링이 어렵다 (스케줄링 알고리즘 문제가 아니니까). 계산해서 점근 추정값은 가능하나, 이 수치는 의미가 없다. 공유 주소 공간 머신의 모든 비용 모델은 이러한 오버 헤드를 고려해야 함. Total Time = t_s + t_w * m 유한 캐쉬에서 발생하는 영향은 각 시스템마다의 다양한 캐쉬 사이즈로 인해 다르므로 무시됨 공간적 지역성의 최대화 (캐시 라인 효과)는 명시적으로 미포함 거짓 공유는 데이터 레이아웃과 같이 명령 스케줄의 기능 비용 모델은 공유 데이터 구조가 잘 채워져 있다고 가정하기에, 잘못된 비용 미포함 중복된 통신 및 계산을 설명하지 않음","link":"/2020/03/15/Parallel/Week%202%202%20MP/"},{"title":"Routing","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al Routing and Communication CostsRouting Mechanism - path msg takes minimal: shortest path, Non-minimal: not shortest, for avoid network congestion. Deterministic Routing: Unique path determined solely on the source and destination processor - ignore the state of the network. Adaptive Routing : use information on the state of the network. Review of SF and CTStore and Forward (SF) Common on early parallel Forwards msg after the entire msg has been received and stored. t_h is substantially less. $$t_c = t_s + (m * t_w + t_h) * l \\approx t_s * mt_w * l$$ Cut-Through Routing msg is sent in fixed-length segments called flow-control digits or flits Wormhole routing pipelines the flits through the network. Uses less memory at the intermediate processor msg header = l * t_h to arrive. $$t_c = t_s + l * t_h * tw$$ cost is O(m+l) while O(m*l) for SF. One-To-All Broadcast (OTAB) All-To-One Reduction (ATOR)Ring or Linear ArrayRecursive Doubling = 한곳으로 보내고 2명 2명이 2명에게 4명 4명이 4명에게…. Hence msg cab be broadcast in lg(p) The destination node to each step to be sent must be carefully chosen to utilise the resources (avoid congestion on the network). Reduction can be performed by reversing the direction and the sequence of communication —&gt; will lead to the beginning node 0. Mesh Can regard each row and col of a square mesh of p nodes as a linear array or sqrt(p) nodes. Perform like linear array on rows first, and do the same thing on the cols. Hence 16 nodes (4*4) will be sqrt(16) = 4 phases in one-to-all broadcast. In 3D —&gt; p^(1/3) Reduction = same as linear array. HyperCube 2^d hypercube = d-dimension mesh with two nodes in each d. Steps: d steps. 8 nodes (222) —&gt; 3 steps. The dimension is identified by the MSB, while the order of visiting dimension does not affect the communication —&gt; Means no congestion. Balanced Binary Tree Hypercube OTA broadcast maps naturally onto it. All-to-All Broadcast (ATAB) and Reduction (ATAR) Used in matrix operations. can be performed by p * OTAB or can be concatenated into one large message while traversing the network. Linear Array and Ring Each node = initial node. Use one way and pass it to the neighbour. First send urs then start to send the latest msg u got from the neighbour. Hence takes p-1 steps (need to receive 7 info in 8 nodes) Mesh Same as linear. Perform linear ATAB for rows and do cols. Hypercube hypercube = extension of mesh to log(p) dimensions. takes log (p) steps.","link":"/2020/03/15/Parallel/Week%202%204%20Routing/"},{"title":"Perfectly Parallel Models","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al The Australian National University CECS Granularity Granularity: size of the tasks Coarse grain: large tasks/many instructions Fine grain: small tasks/few instructions Metric = t_compute / t_communication It may depend on number of processors. Speedup the relative performance between single and multiple processors ⇒ S(n) = exe time on single / exe time on p = t_seq / t_par t_seq should be the fastest known sequential algo; best parallel algo may be differernt S_operation(p) = operation count rate with p / operation count rate on single Linear speedup = max possible S(n) = p if S(P) &gt; P then May imply the algo is not the best one, go and check the seq algo May arise due to the unique feature of architecture. Parallel Overhead Factors that limit parallel scalability: periods that not all p works + time when one p is active on seq parts load imbalance extra computations not in the seq code —&gt; seq code in one p might be faster some cases communication times Efficiency and Cost Efficiency: How well using the processors $$E = t_{seq} / t_{par} / p = S(p)/p * 100%$$ Cost: parallel execution time * total num of p Cost optimal = cost has same asymptotic growth as a func of input size as the fastest seq algo on a single processor $$cost = t_{par} * p = (t_{seq}*p)/S(p) = t_{seq} / E$$ Adding n num on n processorsAdding n in a single core = n; adding n in n processor = lg(n). Therefore speedup = O(n/lg(n)) cost = number of p * time of execution = n * lg(n) = O(n lg(n)) Hence it is not cost-optimal ScalabilityImprecise measure: hardware: 하드웨어를 늘리면 퍼포먼스가 좋아지나? 링, 크로스바, 하이퍼큐브 위상을 고려하고 프로세서에 무슨 변화를 줘야 하는지 고려 Algorithm: 사용하고 있는 알고리즘이 더 많은 프로세서와 accomodate 가능 한가? Combined: 문제 크기 증가를 프로세서를 증가함으로써 accomodate 가능 한가? 계산 사이즈를 배로 늘렸을때의 변화를 고려 N*N 매트릭스의 N사이즈를 두배로 늘리면, 더하기 계산의 비용은 4배지만 곱하기 비용은 8배로 늘어난다","link":"/2020/03/25/Parallel/Week%202%206%20PerfModels/"},{"title":"Message Passing Interface","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al Basic Requirement#1 Process CreationRequire a method for creating separate processes for execution on diff CPUs Options Static: num of processor is fixed during execution Dynamic: num of processor fluctuates during execution Both needs unique identification of each process. // dynamic spawning number of processor by runtiem environmentmpirun -np 4 ./mpi_job //spawn 4 processors// identify the num and the rank (unique identifier within the groupint MPI_Comm_size(MPI_Comm comm, int *size) //given by runtime env 4 in this caseint MPI_Comm_rank(MPI_Comm comm, int *rank) //identifier within the communicator (comm - handler) MPI_Comm_size #2 Data TransmissionRequire a method for sending/receiving messages between processes. MPI_Send MPI: blocking vs non-blocking 12345//data - usually a pointer and number of bytes// - Non-contiguous data must be packed.// - Heterogeneous systems may require type conversion (endianess)MPI_Datatype matCol;MPI_Type_vector (m /*count*/, 1 /*size*/, n /*stride*/, MPI_DOUBLE, *matCol); Unix command fork - spawns an identical task to parent ssh - starts process on a remote machine exec - overwrites a process with a new process Socket - provides communication between machines shmget - provides communication within shared memory. xdr - provides data conversion between machines. Message TransferTwo buffers 1. Send,Receive buffer 2. System (local) buffer owned by MPI Lib among ranks) Blocking meanst that the buffer is available for reuse. To reuse buffer, MPI can copy it to system buffer and empty so that it can be reused ( =MPI_Send() returns) A blocking send can complete as soon as the msg is buffered (system) without having recv(). However, in some cases, buffering msg is expensive hence better to directly copy the data into receive buffer. That is why there are 4 modes. Send Modes Standard Mode: If MPI decides to buffer, Send() can returns immediately without having corresponding Receive(). But if decided not for performace issue or lack of buffer size, it will stall (not return) until it has Receive(). Hence this mode is non-local as it may need receive() in case of not buffering the msg. MPI_Send() Buffered Mode: Same as standard mode except it will be buffered if no Receive(). Buffer allocation is user defined and if it is overflow —&gt; error comes. MPI_Bsend() Synchronous Mode: Send() returns if Receive() posted and started to receive the msg. Hence the return states the Send() buffer is ready to be re-used and Receive() started taking the msg. If either blocking then it stalls. MPI_Ssend() Ready Mode: Can be started only if matching Receive() invoked. It does not tell if send buffer is ready nor receive(). However since it can be started if Receive(), correct implementation of this mode can be replaced by Standard and Sync mode without losing performance. MPI_Rsend. Receive Modes Blocking Mode: receive returns only after it contains the data in its buffer —&gt; does not imply whether or not it can complete before the matching send completes. Computation hasted untill the blocked buffer is freed —&gt; waste resources as CPU remain Idle. Non-Blocking Creats a request for communication for send/receive. Gets back a handle and terminates. It guaratees that the process is executed. For Sender: allows overlapping computation with communication For Receiver: allows overlapping a part of the communication overhead; copying the msg dircetly into the receiving address space in the application. Synchronous: the send returns only when msg has been received. Request to send, receive the OK to send, send msg Blocking: the send returns when it is safe to re-use the sending buffer (MPI is normally blocking method) Locally blocking: returns after MPI copies the msg into a local buffer Globally Blocking: returns when receiver has collected the msg (and hence has posted its receive call) The receiver returns when msg has been received. Non-blocking: the send returns immediately even though the data may still be in the original buffer Another func call can check if the buffer is free to use again (if the communication is finished by wait() or test(). Can be good for Isend() and do works and wait() —&gt; improved performance. The receive returns immediately; another call is to check for arrival. Message SelectionThe sending process calls a programmer defined msg tag can be used to create classes of msgs. The receiver process calls buffer must be long enough for incoming message Both have blocking semantics (send is either local or global) ComunicatorDefinition: a group that processes can join. It prevents conflict between msgs that are internal to a lib and those used by application program Collective OperationsFrom simple send() and receive() Synchronization: barrier to inhibit further execution. Use simple pingpong between two processes. Broadcast: send same msg to many Must define processors in the group (that specified by communicator) Mush define who sends and receive May or may not sync processors (depends on the implementation) Scatter: 1 process sends unique data to every other in group Gather: 1 process receives … Reduction: Gather and combine with an operation (either to one or all)","link":"/2020/03/15/Parallel/Week%202%205%20MPI/"},{"title":"Partition","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al Partitioning Strategies Replicated Data Approach (No partitioning) Each has the entire data but does a subset of computation. Partition to different process (Most Common) Domain Decomposition Divide and Conquer Partition of program func (Less Common) Functional Decomposition Partition to Diff ProcessUse MPI_Scatter and MPI_reduce for Vector Addition Root sends data to all processes (including itself) MPI_Scatterv() —&gt; scatters variable lengths. MPI_Allreduce() —&gt; returns result to all processors Domain Decomp via Divide-and-Conquer For problems that can be recursively divided into smaller probs of the same type; such as summation. The analysis for simple binary tree is as following The Reduce and Scan Abstractions 이미 프로세서들에게 파티션된 벡터들의 합이 이에 해당한다. Reduce: Combines a set of val to produce a single value; mapping a binary tree communication pattern between processors. Scan: performs a seq opreation in parts and carries along the intermediate results. Scans Replacs each element with the cumulative sum of all preceding elements (inclusive or exclusive) Parallel random-access machine 123456789101112131415X = [0,1,2,3,4,5,6,7]Inc_Scan = [0,1,3,6,10,15,21,28]Exc_Scan = [0,0,1,3,6,10,15,21]//EX #1 - 8 val on 8 nodes.for (d=1; d &lt; N; d ∗= 2) FORALL (k=0; k &lt; N; k ++) IN PARALLEL if (k &gt;= d) X[k] = X[k−d] + X[k];/***Ex #2 - Bucket Sort1. Assign one bucket to each processors2. Assign p small buckets to each processors --&gt; can ues MPI_Alltoall()Ex #3 - Integraton (SPMD model using static distribution)--&gt; Uneven workload, terminating point for small division is an issue. The analysis for parallel bucket sort. The worst case scenario: data is chunked at certain value —&gt; same as the bucket sort problem? Barnes Hut Algorithm Algorithm —&gt; It creates oct-tree Divide one cube into 8 Delete if no needed sub-cube with more than 1 divided into 8 again. Continue untill each one has only one particle. Scaling is O(n lg n) Load balancing is likely be an issue for parallel code.","link":"/2020/03/24/Parallel/Week%204%208%20Partition/"},{"title":"Pipelining","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al Pipelinig There are three types of pipelining; Adding numbers (type 1) Insertion Sort (type 2) Linear System back substitution (type 3) Prblems that can be divided into a series of seq tasks that can be completed one after another. Typical Scenario 독립된 문제가 한 개 이상 계산 될 예정일때 (Instruction) 각각 여러 계산을 필요로 하는 연결된 데이터들을 계산되어야 할때 (Graphics) 다른 계산에 필요한 작업이 그 계산이 필요로 하기전에 작업을 마칠수 있을때 (Software) Type 1 - Adding number Single Intance: Multiple Instance: Type 2 - Insertion Sort Type 3 - Linear EquationsBack substitution —&gt; passes calculated value to solve the other ones (like fibonacci). Process i performs i sends and receives, i multiply/adds, one division/subtract and one final send t_comm = (2i + 1) * (t_s +t_w) and t_comp = 2i + 2","link":"/2020/03/24/Parallel/Week%204%209%20Pipelining/"},{"title":"Message Passing Interface 2","text":"MPI-1 Fixed process model point-to-point communications collective operations. communicators for safe library writing utility routines MPI-2 Dynamic process management. one-sided communications cooperative I/O Dynamic Process Management MPI - 1 had a static or fixed number of processes Cannot add nor delete processes The cost of having idle processes may be large. Some applications favour dynamic spawning run-time assessment of environment serial applications with parallel modules scavenger applications. CAUTION: process initiation is expensive, hence requires careful thought. MPI-2 Process Management Parents spawn children Existing MPI applications can connect Formerly independent sub-applications can tear down communications and become independent. Task Spawning - MPI_spawn(); It is a collective operation over the parent process’ communicator. info parameter: how to start the new processes (host, architecture, work dir, path). intercomm and errcodes are returned values. Communicators MPI processes are identified by (group, rank) pairs. Communicators are either infra group, or inter group : ranks refer to processes in the remote group. Processes in the parent and childern group each have thier own MPI_COMM_WORLD Send and Recv have a destination and a inter/infra communicator. Possible to merge processes or free parents from children by MPI_Intercomm_merge() and MPI_Comm_free(). One-sided CommunicationsFor traditional MP, there is an implicit synchronisation - it may be delayed by asynchronous message passing. In One-sided Communications, One process specifies all communication parameters. Data transfer and synchronisation are separate. Typical operations are put, get, accumulate. MPI_put() MPI-2 Remote Memory Access (RMA) Processes assign a portion (or window) of their address space that explicitly expose to RMA operations. MPI_Win() Two types of targets Active target RMA: requires all processors that created the window to call MPI_Win_fence() before any RMA operations is guaranteed to complete. One-sided communication: no process is req to post a recv. Cooperative in that all processes must synchronize before any of them are guaranteed to have got/put data. Passive target RMA: only requirment is that originating process places MPI_Win_Lock() and MPI_Win_Unlock() before and after the data transfer. Transfer is guranteed to have completed on return from unlock. Known as one-sided communication. Potential unsync can be avoided by locks or mutexes. MPI-2 File Operations Positioning: explicit offset, shared pointer/ individual pointers Synch: blocking/non-blocking (async) Coordination: collective / non-collective File types: is a datatype made up of elementary types; MPI_Int() allows to specify non-contiguous accesses. can be tiled. s.t. process writes to block of the file. MPI-IO Usage 각 프로세서는 자신의 데이터를 따로 파일에 쓸수 있다 프로세서들은 하나의 파일로 데이터를 추가 할 수 있다. (로그파일 형식) - 한 파일 포인터 사용 프로세서들은 협력해서 하나의 큰 매트릭스를 파일에 쓸수 있다 파일을 타일 하기 위한 파일타입 생성 각가의 포인터를 이용 모음 명령어를 이용하여 데이터 셔플링 가능케 함 병렬 파일 시스템이 사용될수 있지만 그냥 평범한 파일 시스템으로 보일 수 있음 Simple MPI I/O각 개인 포인터를 이용한 협력 파일 명령어. 각각의 프로세서의 메모리가 할당된 파일 타일에 데이터를 넣는 형식 MPI_File_Open() 을 이용하여 커뮤니케이터와, 각 개인 포인터와 공유 파일 포인터를 생성함 Info parameter 는 성능 조절, 특이 케이스 핸들링등에 대해 파일에 공유 각각의 읽기 쓰기는 포지셔닝을 필요로 하는데 이는 MPI_File_Seek; …Read() —&gt; 개인 파일 포인터 이용 MPI_File_Read_at; —&gt; 해당 오프셋에서 직접적으로 읽기 MPI_File_seek_shared; … read_shared() —&gt; 공유 파일 포인터 이용. Seek_shared is collective. 읽기 쓰기로 버퍼, 카운트, 데이터 형식을 specify 한다 (보통 send/recev 처럼) MPI_File_close() is also collective. MPI-2 and Beyond MPI-2 는 많은 기능을 넣었는데 1의 기능보다 훨씬 느려졌고, 해당 사용 회사들의 기능들은 오랫동안 미완성이었음 MPI-3는 단방향 통신과 non-blocking collective 를 향상 시킴","link":"/2020/03/30/Parallel/Week%205%202%20Message%20Passing%20Interface%202/"},{"title":"Synchronous Computations","text":"Reference: Barry Wilkinson, Michael Allen - Parallel Programming_ Techniques and Applications Using Networked Workstations and Parallel Computers (2nd Edition) -Prentice Hall (2004) Barrier A particular reference point for processors which no one can proceed until every processors (or stated number) get to the point. Commonly when processes need to exchange data and then continue. Once the last one has arrived, inactive processes are awakened. Apply both shared memory, and message-passing systemss Barrier - MPI MPI_Barrier(MPI_Comm comm) is called by each process and return once everyone arrives. Naturally synchronus, and message tags are not used. Counter ImplementationCalled a linear barrier as well. Counting the number of processes is handled by a single counter. Implementations must handle possible time delays for eg. two barriers in quick succession. There are two phases: Arrival Phase : Send msg to master and stay inactive or idle as not all are arrived. Departure Phase : Receive from master and released. — Remember Send() is not the blocking (depend on the buffer size), but Receive() always do the blocking. Cost = O(p) for time and computation complexity Tree-Based Implementation Use of decentralized tree construction. Arrival and Depature order is reversal as it supposed to be. Since it is up and down, O(2 lg p) = O(lg p) for communication time. Note: broadcast does not ensure synch in terms of a global time Butterfly (Omega) BarrierPairs of processes sync at each stage as following 01 23 45 67 (4 has 4,5) 02 13 46 57 (4 has 4,5,6,7) 04 15 26 37 (4 has 0,1,2,3,4,5,6,7) After the stages, every processes are synchronized and can continue. O(2 lg p) = O(lg p) for communication time. Local SynchronizationIt can be formulated for only essential synchronization among few processes, instead of being “wastefully” idle — In a mesh or a pipeline and only neighbours sync. Not using barriers, but ues Receive to communicate and idle certian processes to exchange its data. DeadLockIt will occur using synchronous routines (or blocking routines without sufficient buffering) if both performs the send first to each other. In general, assign even-numbere in send first, odd-numbered in rece first coule bo a good solution. MPI_Sendrecv() and MIP_Sendrecv_replace() —&gt; deadlock prevent commands. Data Parallel Computations ease of programming ease of increase to larger problems.123456789forall (i = 0; i&lt; n; i++){ a[i] = a[i] + k;}// In SIMD, those particularly designed for these, implicitly has barrier itself// If MP computer using library routines, generally explicit barrier is required.// Following is an examplei = myrank; // myrank is a process rank between 0 and n-1a[i] = a[i] + k; /* body */barrier(mygroup) // consider the barrier overheads as it may longer than its body Synchronous Iteration Parallel started at the beginning of the iteartion, yet each processes cannot proceed to the next iteration unless all the assigined tasks in the iteration is completed. Jacobi Iteration: all x are updated together. guess X, and iterate while hope it converges. In converges if tha matrix is diagonally dominant. Terminates whin convergence is achieved (subtract of two is within the error tolerance) 야코비 방법 123456789101112131415161718192021222324252627// Sequential for (i=0; i &lt; n; i++){ x[i] = b[i]; //b[] holding the constants}for (iteration = 0; interation &lt; limit; iteration++){ for (i = 0; i &lt; n; i++){ // n number of rows and cols. sum = -a[i][i] * x[d] // Jacobi method excludes itself. for (j = 0; j &lt; n; j++){ // each row summation iteration sum = sum + a[i][j] * x[j] // summation of one row } new_x[i] = (b[i] - sum) / a[i][i] //a[i][i] cannot be zero } for (i=0; i&lt;n; i++} x[i] = new_x[i] //data move}// Paralleli = process_id;x[i] = b[i]; // assign each process array for (iteration = 0; interation &lt; limit; iteration++){for (i = 0; i &lt; n; i++){ // n number of rows and cols. sum = -a[i][i] * x[j] // Jacobi method excludes itself. for (j = 0; j &lt; n; j++){ // each row summation iteration sum = sum + a[i][j] * x[j] // summation of one row } new_x[i] = (b[i] - sum) / a[i][i] //a[i][i] cannot be zero broadcast_gather (&amp;new_x[i], new_x); //spread and gather data over processes global_barrier(); for (i=0; i&lt;n; i++} x[i] = new_x[i] //data move} Broadcast_gather expect all the processes to have matching routines. Hence further implementation must be made to avoid deadlocks whet each prcoss can stop once it met its tolerance (so each has diff num of iterations). It can be easily replaced with send and recv(). Analysis Heat Equation12345678910111213141516171819202122// Sequential Codefor (iter = 0; iter &lt; limit; iter++){ for (i = 1; i &lt; n; i++){ for (j = 1; j &lt; n; j++){ q[i][j] = 0.25 * (h[i-1][j]+....); } } for (i =1; i &lt; n; i++){ for (j = 1; j &lt; n; j++){ h[i][j] = g[i][j]; } }} // Parallel Codefor (iter =0; iter &lt; max_iter; iter++){ g = 0.25 * (w + x + y + z+); send(&amp;g, ...) ... ... ... recv (&amp;z, ...)} Block Partitioning: Each process generates and receives 4 messages each —&gt; hence total of 8. Strpi Partitioning: Two edges where data points are exchanged. Each edge generates and receives 2 messages —&gt; hence total of 4. In general, strip partition is best for a large startup time, and a block partition is best for a small start up. For p ≥ 9, if above equation is fulfilled, the block partition has a larger communication time. Safety &amp; Deadlock As it is unreliable to assume the internal buffer will be enough, there are two methods. Switching send and recv in different order as mentioned couple of times so far. Implement Asynchronus communication using ghost points. Assign extra receive buffers for edges where data is exchanged. It is typically translated as extra rows and columns in each process’ local array (known as halo). In this buffer, asynchronus calls such as MPI_Isend() can be used.","link":"/2020/03/29/Parallel/Week5%201%20SynchComp/"},{"title":"Shared Memory Address","text":"Reference : Introduction to Parallel Computing, Edition Second by Vipin Kumar et al The Australian National University CECS Shared Memory HardwareUniform Memory Acccess Shared Address Space with cache: 보통 UMA와 같지만 로컬 캐시를 가지고 있음 NUMA with cache: 보통 NUMA와 비슷함. 프로세서, 캐시, 메모리 한그룹이 묶여있고 이 그룹이 Interconnection Network을 통해서 연결되어 있음. Shared Address Space Systems 만약 로컬 메모리에 대한 접근이 원격 접근보다 가격이 싸다면 (즉 NUMA) 보다 싸다면 Shared Address Space Systems가 알고리즘에 포함되어야 함. 어떻게, 운영체제가 호환되는지는 다른 문제임 보통 공유 주소 공간을 가지고 있는게 프로그래밍 하기 쉬운이유가, 읽기 전용의 시스템은 그냥 순차적 프로그램 짜듯이 짜면됨. 다란 읽기/쓰기 같은경우, 병행적 접근때문에 MUTEX 가 필요함. 주요 프로그래밍 모델들은 쓰레드와 directive based (컴파일러에 해당 인풋을 어떻게 처리할지 지시하는 언어적 구조) 이다. (Pthreads and OpenMP) 동기화는 락과 관련된 메카니즘을 사용한다. SASS with Shared memory computers 공유 메모리는 전통적으로 메모리가 물질적으로 여러 프로세서들에게 연결되고, 모든 프로세서가 해당 메모리에 동일한 접근 권한을 가진곳에 사용되어 왔다. 해당 방식은 UMA 라고 한다. SMP는 원래 Symmetric Multi-Processor라 하여 모든 CPU들이 동일한 운영체제 성능을 (인터럽트나 다른 시스템콜 등) 가진것을 칭했는데, 요즘은 Shared Memory Processor의 축약어이다. 분산 메모리 컴퓨터는 각 메모리의 다른 부분이 물질적으로 다른 프로세서와 연결되어 있음에 차이점이 존재한다. 이 distributed momory shared address space computer를 NUMA 시스템이라 한다. 멀티프로세서에서의 캐시여러장의 데이터들이 여러 프로세서들에 의해 값이 변화된다. 시스템 안의 각각의 물리적인 메모리 워드를 찾아낼 수 있는 주소변환 메카니즘, 그리고 여러 데이터들의 병행적 수행들이 잘 정의된 세만틱들을 가지고 있어야 한다. 여러 프로세서들의 접근에 의한 캐시값의 일관성유지가 필요함. 몇 기기들은 공유 주소 공간 메커니즘까지만 관여하고 일관성은 시스템이나 유저레벨의 소프트웨어에 일임한다. Cache/memory Coherency 매모리 시스템은 다음 사항들을 지키면 일관적이다 실행된 순서대로 (Ordered as Issued) : 즉 한 프로세서가 읽고 수정하는동안, 다른 프로세서가 해당 값은 수정하지 않을때 (읽기는 가능) 쓰기 전달 (Write Propagation): p1 reads, p2 writes, then p1 should have value of p2. Write Serialization: 다른 프로세서들이 볼때 두 프로세서가 두 쓰기를 실행한 순서를 정확히 알고 있다면. Cache Coherency Proctocol캐시 일관성(Cache Coherence) Invalidate Protocol: P0 P1이 같은 값을 읽었는데 P0가 값을 바꾸면, 해당 메모리와 이 값을 읽은 P1에게 이 값은 Invalidate되었음을 알려주는 방식 (이 값 쓰지마라) - 보통 이 방식을 사용 Update Protocol: P0 P1이 같은 값을 읽었는데 P0가 값을 바꾸면, 메모리와 P1이 가지고 있는 해당값을 업데이트 해줌. 비교: 업데이트 프로토콜의 경우 같은 단어에 대한 여러 쓰기는 (거의 동시 읽기) 여러 쓰기 브로드캐스트s 를 필요로 한다. 이에 비해 Invalidate는 단 하나의 initial invalidation을 필요로 함. 업데이트 프로토콜의 경우 여러 복수단어들의 캐시 블록들에게 각각의 캐시 블록 (라인)에 쓰여진 각각의 값들은 브로드캐스트 되어야 한다. 즉 한 블록에 한 단어만 보낼수 있음 (즉 여러 n 값들은 n번 보내져야 함). 반대로 invalidate only require one line. 업데이트 프로토콜의 경우 한 프로세서가 한 값을 쓰고, 이 쓰여진 값이 다른곳에서 읽혀지는데 걸리는 지연시간이 더 적다. (즉 invalidate에 비해 값이 쓰여지고 읽혀지는 지연이 짧다는말) False Sharing두 프로세서는 같은 캐쉬라인에서 다른 부분을 수정함. Invalidate의 경우 핑퐁된 캐시 라인들을 이용한다. Update의 경우 로컬로 읽지만, 프로세서간의 업데이트 트래픽을 많이 발생시킨다. 다음 사항들을 병력 프로그래밍이나 시스템을 디자인 할때 항상 염두해야한다 캐시라인 사이즈, 길수록 좋다 캐시 라인 사이즈를 고려한 데이터 구조의 alignment Implementation of Cache Coherency 조그만 스케일의 버스 기반 기기들의 경우 한 프로세서는 반드시 쓰기 invalidation을 브로드캐스트 할 수 있도록 버스에 대한 접근 할 수 있어야 한다. 경쟁하는 두 프로세서들의 경우, 먼저 버스에 접근을 얻는 프로세서가 해당 데이터를 invalidate 한다 (즉 먼저 오는 프로세서의 값을 사용하는것) 캐시 미스의 경우 데이터의 최신 카피를 위치해야 한다. write-through cache 의 경우 쉬움 Write-back cache의 경우, 각 프로세서들의 캐시는 버스를 감시하며 데이터의 최신 카피가 있다면 반응한다 (snoop - 감시) 읽기의 경우 다른 카피들이 해당 블록을 캐시했는지 알고싶어한다 (즉 해당 블록이 사용중인지) write-back cache가 버스에 detail을 넣을지 말지 결정하기 위해서라던지 태그를 이용해서 공유 status를 통해 관리한다 프로세서 멈춤을 최소화하기 태그들의 복사나, 혹은 inclusive cache 를 여러개 갖던지 하는 방식으로 위 그래프와 아래 값들의 변화를 주의해서 살펴본다. 스누피 캐시 시스템 모든 캐시들은 모든 변화를 브로드캐스트 한다 버스나 링 위상의 interconnects에 쉽게 적합할수 있다 (implement) 그러나 확장성이 재한되어 있다 (8개 이하). 모든 프로세서들의 캐시들은 interconnect port의 변화를 감지한다 (관심있는 부분만) 관련 프로토콜의 상태 다이어그램을 통해 태그들이 업데이트 된다. 하드웨어 감시는 읽기가 한 더러운 카피를 가지고 있는 캐시블록에 대해 읽기가 실행되었으며, 이 행위가 버스 컨트롤에서 데이터를 빼내고, 관련 태그를 S로 바꾸었음을 알아차릴 수 있다. (예를 들어) Directory Cache-Based Systems디렉터리 기반 일관성 구조는 캐시 블록의 공유 상태, 노드 등을 기록하는 저장 공간인 디렉터리를 이용하여 관리하는 구조이다 - presence bitmap을 전역 메모리와 함깨 이용하여 각각의 메모리 블락이 어느 캐시에 위치하고 있는지를 디렉터리에 저장하는 방식. 이에 반해 디렉터리 기반 구조는 어떤 노드에서 해당 캐시 블록의 복사본을 가지고 있는지를 알고 있기 때문에 특정 노드에만 요청을 하게 된다. 따라서 브로드캐스트가 불필요하게 되어 대역폭이 상대적으로 작아도 된다. 이 때문에 64개 이상의 프로세서를 가지는 대규모 시스템에서는 디렉터리 기반의 캐시 일관성 프로토콜을 사용하는 경우가 많다. 이 디렉터리는 메모리와 붙어 있는데 공유 메모리의 경우 디렉터리가 따로, 로컬 메모리를 이용하는 경우 각각의 로컬 디렉터리를 사용한다. 쉬운 프로토콜은 다음과 같을것이다 shared: 프로세서들은 블락 캐시를 가지고 있고, 메모리 값은 최신화를 유지한다 Uncached: 어느 프로세서도 카피를 가지고 있지 않는다 (즉 뺴서 저장하고 하지 않음) Exclusive: 오직 한 프로세서만 (주인) 카피를 가지고 있고, 메모리에 있는 값은 옛날 값이다. 공유되고 깨끗한 캐시 블록에대해 쓰기/읽기 미스와 쓰기는 다음과 같은 사항을 반드시 지켜야 한다 이 블록에 대한 현 상태를 체크하기 위해 디렉터리 주소를 처음에 참조해야한다 (즉 directory entry를 먼저 refernce해서 상태 체크 해야함) 그후에 entry의 상태와 presence bitmap을 업데이트한다 presence bitmap에 있는 해당 프로세서들에게 적절한 상태 업데이트 소식을 전달한다. 디렉터리 기반 시스템의 문제점디렉터리 저장의 메모리 요구량 특정 데이터 접근 방법에 따른 퍼포먼스 차이 presence bitmap을 어떻게 관리할것인지 (복사? 꼭?) 어떻게 presence bitmap에 존재하는 모든 프로세서들에게 invalidation을 보낼것인지 MESI 프로토콜 출처 캐시 메모리의 일관성을 유지하기 위해서 별도의 플래그(flag)를 할당한 후 플래그의 상태를 통해 데이터의 유효성 여부를 판단하는 프로토콜이다. 데이터 캐시는 태그 당 두 개의 상태 비트를 포함한다. 멀티프로세서 시스템에서 캐시 메모리의 일관성을 유지하기 위해 메모리가 가질 수 있는 4가지 상태를 정의한다. Modified(수정) 상태 : 데이터가 수정된 상태 Exclusive(배타) 상태 : 유일한 복사복이며, 주기억장치의 내용과 동일한 상태 Shared(공유) 상태 : 데이터가 두 개 이상의 프로세서 캐쉬에 적재되어 있는 상태 Invalid(무효) 상태 : 데이터가 다른 프로세스에 의해 수정되어 무효화된 상태 Coherency Wall - 캐시 일관성의 한계및 단점 인터커넥트는 로직 서킷들에 비해 50배나 넘는 에너지를 소모함 각각의 invalidation을 위해 브로드캐스트 메세지를 필요로 하는 프로토콜의 경우 에너지 소비는 O(p), overall cost = O(P^2) 네트워크의 지연을 일으키기도 하다 디렉터리 기반 프로토콜은 같은 데이터를 들고 있는 곳에만 메세지를 보낸다 훨씬 확장성이 높으며 가벼운 데이터 공유를 가진다 (가진 애들끼리만 대화 하니까) 이외는 모두 안좋다 잘못된 direction으로 인한 오버헤드도 발생함 한 캐시 라인당, 비트 벡터의 길이가 a 라 하면 O(a^2) 의 공간 소모 false sharing은 어느 경우라고 트래픽을 낭비하는 모습을 보여줌 Atomic instructions 메모리 시스템의 동기화를 LLC (Last level cache) 까지 낮추는데 비용이 각각 O(p) 정리 캐시 일관성은 실행 순서, 쓰기 전달, 쓰기 순차 세개의 요소를 가지고 있다 두가지 방식을 가지고 있는데 브로드캐스트/스눕: 중소 규모의 인트라 칩, 그리고 작은 인터 소켓시스템에 적합 디렉터리 기반: 대중 규모의 인터 소켓 시스템에 적합 False sharing: 잠재적인 퍼포먼스 문제가 있음 (특히 캐시 라인이 길어질수록) 대규모의 인트라 칩 시스템의 경우 일관성은 보통 운영체제나, Message Passing 프로그래밍 모델을 이용한다.","link":"/2020/05/01/Parallel/Week%206%20SMP%20Hardware/"},{"title":"Parallel - Lab 2","text":"Reference: The Australian National University CECS Timer Overhead vs Timer ResolutionDiffrences: Timer overhead is the length of time it takes to call the timer function. The total time to run your program will be increased by this value multiplied by the number of times you call the timer. Timer resolution is the period of time below which the timer will sometimes report a value of zero. It represents the smallest period that can accurately be measured by the timer. Assess timer by calling it twice.For timers that operate like clocks (real time or CPU time), the differences represent the change in the value of the clock between each call. The overhead is the average of the consecutively reported differences. The lowest measured values will be integer multiples of the resolution. If the overhead is less (or finer) than the resolution, then the measured overhead may be zero. The above used gettimeofday() The smallest non-zero is 1, hence the resoultion of the timer is 1us. There are several zero valuse, hence the overhead or the timer is &lt;1us. The above used MPI_Wtime() MPI_Wtick gives the resolution of 1e-09 which appears to agree the MPI_Wtime() hand calculation. Blocking BehaviorThe code fails because we have both processes wishing to send at the same time. If the message is small we see non-blocking behaviour since the message can be packed into the initial buffer (internal local system) —&gt; Hence can store and move on to the next line of execution. For larger sizes it fails because we see a transition from a non-blocking send to a blocking send when the message becomes too large. It stalls to find the receive() from the destination while the destination stalls and waits receive() as well. Startup Time Once the size reaches certian point, possibility of L3 Cache missing the data may cause decrease in the Bw; bw = 2.0 * length of words * sizeof(int) / time / 1e9 = GB/S From the above results:Latency = 4.42e-07s / 2 = 0.22 us ⇒ Ping Pong of empty messages average time.Peak bandwidth ~= 1 GB/s","link":"/2020/03/19/Parallel/lab%202/"}],"tags":[{"name":"CPP","slug":"CPP","link":"/tags/CPP/"},{"name":"Keyboard","slug":"Keyboard","link":"/tags/Keyboard/"},{"name":"Layer","slug":"Layer","link":"/tags/Layer/"},{"name":"Summary","slug":"Summary","link":"/tags/Summary/"},{"name":"Theory","slug":"Theory","link":"/tags/Theory/"}],"categories":[{"name":"CPP","slug":"CPP","link":"/categories/CPP/"},{"name":"Life","slug":"Life","link":"/categories/Life/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Network","slug":"Network","link":"/categories/Network/"},{"name":"Lab","slug":"Network/Lab","link":"/categories/Network/Lab/"},{"name":"OCSO","slug":"OCSO","link":"/categories/OCSO/"},{"name":"Parallel Computing","slug":"Parallel-Computing","link":"/categories/Parallel-Computing/"}]}